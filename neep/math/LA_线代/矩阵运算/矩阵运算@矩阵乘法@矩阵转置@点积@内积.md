

[toc]



- C@python#矩阵乘法#numpy中的乘法#矩阵运算@矩阵乘法@矩阵转置@点积@内积

## 矩阵乘法@矩阵标准乘积🎈



- 给定$m\times{l}$矩阵$A=(a_{ij})_{m\times{l}}$和$l\times{n}$矩阵$B=(b_{ij})_{l\times{n}}$

- 记A,B的乘积为$C=AB=(c_{ij})_{m\times{n}}$,C中的元素$c_{ij}$计算公式如下

  - $$
    c_{ij}=\sum\limits_{k=1}^{l}a_{ik}b_{kj}
    $$

  - A,B的规格保证了A的列数等于B的行数,<u>A的**行向量**中包含的元素数和B的**列向量**包含的元素都是$l$个</u>

  - 矩阵乘积的结果是一个矩阵,且规格(行数和列数)分别由第一个矩阵的行数和第二个矩阵的列数决定

- 特别地:

  - 如果是两个同n维向量(行向量乘以相同维数的列向量),结果是一个仅包含一个元素的矩阵,这种情况下可以视结果为一个标量)
  - 如果两个同n维向量(列向量乘以行向量),结果是一个n阶方阵



## Hadamard 乘积

- [Hadamard product (matrices) - Wikipedia](https://en.wikipedia.org/wiki/Hadamard_product_(matrices))

- 需要注意的是，两个矩阵的**标准乘积**不是指两个矩阵中对应元素的乘积。

- 不过，那样的矩阵操作确实是存在的，被称为 **元素对应乘积**（element-wise product）或者 Hadamard 乘积（Hadamard product），记为 $A\odot B$,其结果是一个与连个因子同型的矩阵。

  - $$
    c_{ij}=a_{ij}b_{ij}
    $$

    

## 向量点积@内积🎈

### 点积(内积)

- 两个同维数(规格)的n维<u>列向量</u>**向量** a 和 b 的 **点积**（dot product）可看作是矩阵乘积 $a^Tb$。

  - 有时也成为**内积**
  - 此处,维数指向量包含的元素个数

- $$
  {\displaystyle \mathbf {\color {red}a} \cdot \mathbf {\color {blue}b}
  =\sum _{i=1}^{n}{\color {red}a}_{i}{\color {blue}b}_{i}
  ={\color {red}a}_{1}{\color {blue}b}_{1}+{\color {red}a}_{2}{\color {blue}b}_{2}+\cdots +{\color {red}a}_{n}{\color {blue}b}_{n}}
  \\
  内积还常记为(a,b),即(a,b)=a\cdot{b}
  $$

  - 或$a\cdot{b}=\sum\limits_{i=1}^{n}(a\odot{b})_{i}$
    - $a\odot{b}$是向量a,b的hadamard积(向量)

- 向量点积的结果是一个**标量**

#### 性质

- 点积满足交换律(而一般的矩阵乘法是不满足交换律的)

- $(\alpha,\beta)=(\beta,\alpha)$

- $(k\alpha,{\beta})=(\alpha,k\beta)=k(\alpha,\beta)$

  - $$
    \sum_ik\alpha_i\beta_i
    =\sum_{i}\alpha_ik\beta_i
    =k\sum_{i}\alpha_{i}\beta_i
    $$

- $(\alpha+\beta,\gamma)=(\alpha,\gamma)+(\beta,\gamma)$

  - $$
    \sum_{i}(\alpha+\beta)_i\delta_i
    =\sum_{i}(\alpha_i\delta_i+\beta_i\delta_i)
    =\sum_{i}\alpha_i\delta_i+\sum_{i}\beta_i\delta_i
    \\
    $$

- $(\sum\alpha_i,\beta)=\sum(\alpha_i,\beta)$

  - 是上一条结论的tui'gua
    $$
    \sum_{i}\left((\sum_{j}\alpha_j)\delta_i\right)
    =\sum_{i}(\sum_{j}\alpha_j\delta_i)
    $$
    

- $(\alpha,\alpha)\geqslant 0$当且仅当$\alpha=0$时,$(\alpha,\alpha)=0$

  - $$
    \sum_{i}(\alpha_i)^2\geqslant{0}
    $$

    



### 矩阵乘积和向量点积的关系

- 我们可以把矩阵乘积 C = AB 中计算 $c_{ij}=\sum\limits_{k=1}^{l}a_{ik}b_{kj}$ 的步骤看作是 A 的第 i 行和 B 的第 j 列之间的点积。

### 内积补充

- 内积是一个数学概念，也叫标量积、点积或数量积。它是一种将两个向量映射为一个实数的运算。它可以用来计算向量的夹角和长度。在英语中，内积叫做inner product.
  - by chatgpt
- **内积空间**（英语：Inner product space）是[数学](https://zh.wikipedia.org/wiki/数学)中的[线性代数](https://zh.wikipedia.org/wiki/线性代数)里的基本概念，是增添了一个额外的结构的[向量空间](https://zh.wikipedia.org/wiki/向量空间)。这个额外的结构叫做**[内积](https://zh.wikipedia.org/wiki/内积)**或[标量积](https://zh.wikipedia.org/wiki/标量积)。
- 内积将一对[向量](https://zh.wikipedia.org/wiki/向量)与一个标量连接起来，允许我们严格地谈论[向量](https://zh.wikipedia.org/wiki/向量)的“[夹角](https://zh.wikipedia.org/wiki/角)”和“[长度](https://zh.wikipedia.org/wiki/长度)”，并进一步谈论向量的[正交性](https://zh.wikipedia.org/wiki/正交)。
- 内积空间由[欧几里得空间](https://zh.wikipedia.org/wiki/欧几里得空间)抽象而来（内积是点积的抽象）

- 内积空间有时也叫做**准希尔伯特空间**（pre-Hilbert space）

## 矩阵乘法各种形式小结👺

- 矩阵乘法运算具有相当的重要性

- 从向量的角度再描述它

- 设矩阵A为$m\times{n}$的

  - $$
    A=\begin{pmatrix}
    	a_{11}  &a_{12}  &\cdots  &a_{1n}  	\\
    	a_{21}  &a_{22}  &\cdots  &a_{2n}  	\\
    	\vdots  &\vdots  &        &\vdots  	\\
    	a_{m1}  &a_{m2}  &\cdots  &a_{mn}  	\\
    \end{pmatrix}
    \\记列向量\alpha_j
    =\begin{pmatrix}
    	a_{1j}  	\\
    	a_{2j}  	\\
    	\vdots		\\
    	a_{mj}  	\\
    \end{pmatrix},j=1,2,\cdots,n
    \\记行向量\beta_i=(a_{i1},a_{i2},\cdots,a_{in}),i=1,2,\cdots,m
    $$
    
  - 注意$\alpha_i$和$\beta_i$不是转置关系

- 将矩阵写作行向量组和列向量组的分块矩阵形式:

  - $$
    A=
    \begin{pmatrix}
    	\alpha_{1}&\alpha_{2}&\cdots&\alpha_{n}	\\
    \end{pmatrix}
    =\begin{pmatrix}
    	\beta_{1}	\\
    	\beta_{2}	\\
    	\vdots		\\
    	\beta_{m}	\\
    \end{pmatrix}
    $$

- 类似的,设矩阵B为$n\times{s}$的矩阵,$\delta_j,j=1,2,\cdots,s$为列向量,$\theta_i,i=1,2,\cdots,n$为行向量

  - $$
    B=\begin{pmatrix}
    	b_{11}  &b_{12}  &\cdots  &b_{1s}  	\\
    	b_{21}  &b_{22}  &\cdots  &b_{2s}  	\\
    	\vdots  &\vdots  &        &\vdots  	\\
    	b_{n1}  &b_{n2}  &\cdots  &b_{ns}  	\\
    \end{pmatrix}
    \\
    B=(\delta_1,\delta_2,\cdots,\delta_s)
    =\begin{pmatrix}
    	\theta_{1}\\
    	\theta_{2}\\
    	\vdots		\\
    	\theta_{n}	\\
    \end{pmatrix}
    \\\\
    $$

    


### 基础形式

- $$
  C_{m\times{s}}=A_{m\times{n}}B_{n\times{s}},
  \\
  c_{ij}=\sum\limits_{k=1}^{n}a_{ik}b_{kj},(i=1,2,\cdots,m;j=1,2,\cdots,s)
  \\矩阵C记为C=(c_{ij})_{m\times{s}}
  $$

  - ```python
    for i in range_inclusive(1,m):
    	for j in range_inclusive(1,s):
            c_ij=0
            for k in range(l):
                c_ij+=A[i][k]*B[k][j]
            print("%s\t"%c_ij,end=" ")
            
    #其中range_inclusive(a,b)表示生成[a,b]范围内的整数(包括边界在内)
    def range_inclusive(a,b)
    	return range(a,b+1)
    ```

### 向量形式

- 行向量乘列向量(手工计算的基础操作)

- $$
  C=AB=
  \begin{pmatrix}
  	\beta_{1}\\
  	\beta_{2}\\
  	\vdots		\\
  	\beta_{m}	\\
  \end{pmatrix}
  (\delta_1,\delta_2,\cdots,\delta_s)
  =\begin{pmatrix}
  \beta_1\delta_1&\beta_1\delta_2&\cdots&\beta_1\delta_s	\\
  \beta_2\delta_1&\beta_2\delta_2&\cdots&\beta_2\delta_s	\\
  \vdots&\vdots&&\vdots\\
  \beta_m\delta_1&\beta_m\delta_2&\cdots&\beta_m\delta_s	\\
  \end{pmatrix}_{m\times{s}}
  \\
  \\矩阵C的元素:c_{ij}
  =\beta_{i}\delta_j
  =\sum\limits_{k=1}^{n}a_{ik}b_{kj},(i=1,2,\cdots,m;j=1,2,\cdots,s)
  \\\beta_{i}和\delta_j分别是1\times{n},n\times{1}的矩阵(向量),
  \\
  \beta_{i}\delta_j是一个仅含有一个数值元素的矩阵,视为标量
  $$

- 列向量乘行向量

- $$
  C=AB=\begin{pmatrix}
  	\alpha_{1}&\alpha_{2}&\cdots&\alpha_{n}	\\
  \end{pmatrix}
  \begin{pmatrix}
  	\theta_{1}\\
  	\theta_{2}\\
  	\vdots		\\
  	\theta_{n}	\\
  \end{pmatrix}
  =\sum\limits_{i=1}^{n}\alpha_i\theta_i
  \\C,h_i=\alpha_i\theta_i都是m\times{s}的矩阵;
  \\执行n个m\times{s}的矩阵叠加
  $$


### 半矩阵半向量形式

- 矩阵乘以行向量分块

- 设$A\in\mathbb{R}^{m\times{n}}$,按行分块为:

  - $$
    A=\begin{pmatrix}
        A_1\\
        A_2\\
        \vdots\\
        A_m
    \end{pmatrix}
    $$

  

- $$
  C_{m\times{n}}=BA
  =\begin{pmatrix}
  	b_{11}  &b_{12}  &\cdots  &b_{1m}  	\\
  	b_{21}  &b_{22}  &\cdots  &b_{2m}  	\\
  	\vdots  &\vdots  &		  &\vdots  	\\
  	b_{m1}  &b_{m2}  &\cdots  &b_{mm}  	\\
  \end{pmatrix}
  \begin{pmatrix}
      A_1\\
      A_2\\
      \vdots\\
      A_m
  \end{pmatrix}
  =\begin{pmatrix}
  	\sum\limits_{k=1}^{m}b_{1k}A_{k}  	\\
  	\sum\limits_{k=1}^{m}b_{2k}A_{k}   	\\
  	\vdots  	\\
  	\sum\limits_{k=1}^{m}b_{mk}A_{k}   	\\
  \end{pmatrix}
  $$

- 其中$\sum\limits_{k=1}^{m}b_{ik}A_{k}$和$A_k$都是$1\times{n}$的矩阵(行向量)$i=1,2,\cdots,m$

- $$
  \\
  \begin{aligned}
  \sum\limits_{k=1}^{m}b_{ik}A_{k}
      &=\sum_{k=1}^{m}b_{ik}(a_{k1},a_{k2},\cdots,a_{kn})
      \\
      &=\sum_{k=1}^{m}(b_{ik}a_{k1},b_{ik}a_{k2},\cdots,b_{ik}a_{kn})
      \\
      &=(\sum_{k=1}^{m}b_{ik}a_{k1},
      \sum_{k=1}^{m}b_{ik}a_{k2},
      \cdots,
      \sum_{k=1}^{m}b_{ik}a_{kn})
      \\
      &=(c_{i1},c_{i2},\cdots,c_{in})
  \end{aligned}
  \quad i=1,2,\cdots,m
  $$

### 分块形式

- 设$A\in\mathbb{R}^{m\times{n}}$,$B\in\mathbb{R}^{n\times{s}}$

- 对B按列分块:$B=(B_1,B_2,\cdots,B_s)$则:

  - $$
    AB=A(B_1,\cdots,B_s)=(AB_1,\cdots,AB_s)
    $$

  - 这里A一整个矩阵被视为一个子块(将整个A视为作为一个元素),则$A(B_1,\cdots,B_s)$该操作类似于向量的数乘

  - 这种划分是允许的,因为$A$的列数和$B_i,(i=1,2,\cdots,s)$的行数相等

  - $AB_i\in{\mathbb{R}^{n\times{1}}}$

  - 类似与线性方程组的形式$A\boldsymbol{x}=\boldsymbol{b}$

- $$
  A=(\theta_{1},\cdots,\theta_{n})
  \\
  C=(\delta_{1},\cdots,\delta_{s})
  \\
  B=\begin{pmatrix}
     b_{11}&  b_{12}&  \cdots&b_{1s} \\
      b_{21}&  b_{22}&  \cdots&b_{2s} \\
      \vdots&  \vdots&  &\vdots \\
      b_{n1}&  b_{n2}&  \cdots&b_{ns} \\
  \end{pmatrix}
  \\
  AB=C
  \\
  (\theta_{1},\cdots,\theta_{n})
  \begin{pmatrix}
     b_{11}&  b_{12}&  \cdots&b_{1s} \\
      b_{21}&  b_{22}&  \cdots&b_{2s} \\
      \vdots&  \vdots&  &\vdots \\
      b_{n1}&  b_{n2}&  \cdots&b_{ns} \\
  \end{pmatrix}
  =(\delta_{1},\cdots,\delta_{s})
  \\
  \delta_{j}=\sum_{k=1}^{n}\theta_{k}b_{kj}
  =\sum_{k=1}^{n}b_{kj}\theta_{k}
  $$

  - 类似线性表出的形式$\delta_j$被$\theta_1,\cdots,\theta_n$线性表出,表出系数为$b_{1j},\cdots,b_{nj}$

### 点积形式

- 在掌握点积和矩阵-向量积的知识后，那么**矩阵-矩阵乘法**（matrix-matrix multiplication）应该很简单。


- 假设有两个矩阵$\mathbf{A} \in \mathbb{R}^{n \times k}$和$\mathbf{B} \in \mathbb{R}^{k \times m}$：

  - $$
    \mathbf{A}=\begin{bmatrix}
     a_{11} & a_{12} & \cdots & a_{1k} \\
     a_{21} & a_{22} & \cdots & a_{2k} \\
    \vdots & \vdots & \ddots & \vdots \\
     a_{n1} & a_{n2} & \cdots & a_{nk} \\
    \end{bmatrix},\quad
    \mathbf{B}=\begin{bmatrix}
     b_{11} & b_{12} & \cdots & b_{1m} \\
     b_{21} & b_{22} & \cdots & b_{2m} \\
    \vdots & \vdots & \ddots & \vdots \\
     b_{k1} & b_{k2} & \cdots & b_{km} \\
    \end{bmatrix}.
    $$

    

- 用行向量$\mathbf{a}^\top_{i} \in \mathbb{R}^k$表示矩阵$\mathbf{A}$的第$i$行，并让列向量$\mathbf{b}_{j} \in \mathbb{R}^k$作为矩阵$\mathbf{B}$的第$j$列。要生成矩阵积$\mathbf{C} = \mathbf{A}\mathbf{B}$，最简单的方法是考虑$\mathbf{A}$的行向量和$\mathbf{B}$的列向量:

  - $$
    \mathbf{A}=
    \begin{bmatrix}
    \mathbf{a}^\top_{1} \\
    \mathbf{a}^\top_{2} \\
    \vdots \\
    \mathbf{a}^\top_n \\
    \end{bmatrix},
    \quad \mathbf{B}=\begin{bmatrix}
     \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m} \\
    \end{bmatrix}
    $$

    

- 当我们简单地将每个元素$c_{ij}$计算为点积$\mathbf{a}^\top_i \mathbf{b}_j$:
  $$
  \mathbf{C} = \mathbf{AB} = \begin{bmatrix}
  \mathbf{a}^\top_{1} \\
  \mathbf{a}^\top_{2} \\
  \vdots \\
  \mathbf{a}^\top_n \\
  \end{bmatrix}
  \begin{bmatrix}
   \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m} \\
  \end{bmatrix}
  = \begin{bmatrix}
  \mathbf{a}^\top_{1} \mathbf{b}_1 & \mathbf{a}^\top_{1}\mathbf{b}_2& \cdots & \mathbf{a}^\top_{1} \mathbf{b}_m \\
   \mathbf{a}^\top_{2}\mathbf{b}_1 & \mathbf{a}^\top_{2} \mathbf{b}_2 & \cdots & \mathbf{a}^\top_{2} \mathbf{b}_m \\
   \vdots & \vdots & \ddots &\vdots\\
  \mathbf{a}^\top_{n} \mathbf{b}_1 & \mathbf{a}^\top_{n}\mathbf{b}_2& \cdots& \mathbf{a}^\top_{n} \mathbf{b}_m
  \end{bmatrix}.
  $$

- [**我们可以将矩阵-矩阵乘法$\mathbf{AB}$看作简单地执行$m$次矩阵-向量积，并将结果拼接在一起，形成一个$n \times m$矩阵**]。

### 对角阵的乘积🎈

#### 一般对角阵的情况

- 设矩阵P按列分块为:$P=(\alpha_1,\cdots,\alpha_n)$

- $n$阶对角阵$A=\Lambda=\rm{diag}(\lambda_1,\cdots,\lambda_n)$

- $$
  A=
  \begin{pmatrix}
     {{a _{11}}} & {} & {} & {}  \cr 
     {} & {{a _{22}}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a _{nn}}}  \cr 
  \end{pmatrix}=
  \begin{pmatrix}
     {{\lambda _1}} & {} & {} & {}  \cr 
     {} & {{\lambda _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{\lambda _n}}  \cr 
  \end{pmatrix}
  \\
  B_{n\times{s}}=  
  \begin{pmatrix}  
    b_{11}& b_{12}& \cdots  & b_{1s} \\  
    b_{21}& b_{22}& \cdots  & b_{2s} \\  
    \vdots & \vdots & \ddots & \vdots \\  
    b_{n1}& b_{n2}& \cdots  & b_{ns}  
  \end{pmatrix}
  $$

- 

  - $$
    c_{ij}=\begin{cases}
    0&i\neq{j}\\
    a_{kk}=\lambda_{k}&i=j=k
    \end{cases}
    \\
    C=AB
    \\
    c_{ij}=\sum_{i=1}^n
    a_{ik}b_{kj}=a_{ii}b_{ij}=\lambda_{i}b_{ij},(k=i)
    \\
    可见,对角矩阵\Lambda(\lambda_{1},\cdots,\lambda_{2})
    左乘B相当于对B的第i行乘以\lambda_{i}
    \\
    $$


#### 更一般的情况@每行不超过一个非0元素

- 假设矩阵$A$是$m\times{n}$的,其中每一行中的非零元素不超过1个(或者假设每行就有一个非0元素)

- 将该矩阵中每行的非0元素所在的列记为$j_1,\cdots,j_m$,即每行的非零元素表示为:$\large{a_{i,j_{i}}}=\xi_{i}$,其中$i=1,2,\cdots,m$;$j或j_{i}=1,2,\cdots,n$

- 我们可以将此时的矩阵A记为$A=\eta(\xi_1,\cdots,\xi_m)$

- 
  $$
  a_{ij}=
  \begin{cases}
  0&j\neq j_i\\
  \xi_i&j=j_{i}
  \end{cases}
  \\
  c_{ij}
  =\sum_{k=1}^{n}a_{ik}b_{kj}
  =a_{i,j_i}b_{j_i,j}=\xi_ib_{j_i,j}
  $$
  
  $$
  \begin{aligned}
  C
      &=AB\\
      &=\eta(\xi_1,\cdots,\xi_m)
      \begin{pmatrix}  
        b_{11}& b_{12}& \cdots  & b_{1s} \\  
        b_{21}& b_{22}& \cdots  & b_{2s} \\  
        \vdots & \vdots & \ddots & \vdots \\  
        b_{n1}& b_{n2}& \cdots  & b_{ns}  
      \end{pmatrix}
      \\
      &=\begin{pmatrix}
      \xi_1b_{j_1,1}&\xi_1b_{j_1,2}&\cdots&\xi_1b_{j_1,s}\\
      \xi_2b_{j_2,1}&\xi_2b_{j_2,2}&\cdots&\xi_2b_{j_2,s}\\
      \vdots&&&\vdots\\
      \xi_mb_{j_m,1}&\xi_mb_{j_m,2}&\cdots&\xi_mb_{j_m,s}
      \end{pmatrix}
  \end{aligned}
  $$
  
  
  
- 观察可以发现,C的第$i$行是通过对B中的第$j_i$行乘以一个系数$\xi_{i}$得到

- 因此,可以对矩阵B左乘$A$来间接调整B中的行的效果(将系数都设为1)

- 此外,当$j_p=j_q,\xi_{p}=\xi_{q},p\neq{q}$时,$C=AB$中第p行和第q行会是相等的

- 基于上述基本结论,如果我们将A设定为某个初等矩阵,也就是第i行和第j行交互位置,那么$C=AB$等价于对矩阵B的第i,j行对调

- #### 使用分块矩阵来描述

  

- $$
  \Lambda{P}
  =\begin{pmatrix}
     {{\lambda _1}} & {} & {} & {}  \cr 
     {} & {{\lambda _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{\lambda _n}}  \cr 
  \end{pmatrix}
  \begin{pmatrix}
    \beta_{1}\\
    \beta_{2}\\
    \vdots    \\
    \beta_{n}  \\
  \end{pmatrix}
  =\begin{pmatrix}
    \lambda_1\beta_{1}\\
    \lambda_2\beta_{2}\\
    \vdots    \\
    \lambda_n\beta_{n} \\
  \end{pmatrix}
  $$

  
  $$
  \Lambda
  =(\alpha_1,\cdots,\alpha_n)
  \begin{pmatrix}
     {{\lambda _1}} & {} & {} & {}  \cr 
     {} & {{\lambda _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{\lambda _n}}  \cr 
  \end{pmatrix}
  =(\lambda_{1}\alpha_1,\cdots,\lambda_n\alpha_n)
  $$
  
- $$
  \begin{pmatrix}
     {{a _1}} & {} & {} & {}  \cr 
     {} & {{a _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a _n}}  \cr 
  \end{pmatrix}
  \begin{pmatrix}
     {{b_1}} & {} & {} & {}  \cr 
     {} & {{b _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{b _n}}  \cr 
  \end{pmatrix}
  =\begin{pmatrix}
     {{a_1b _1}} & {} & {} & {}  \cr 
     {} & {{a_2b _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a_nb _n}}  \cr 
  \end{pmatrix}
  $$

  - 也就是说,两个同型对角阵的矩阵乘法和hadamard运算结果一致$\Lambda_1\Lambda_2=\Lambda\odot\Lambda_2$

- $$
  \begin{pmatrix}
     {{a _{11}}} & {} & {} & {}  \cr 
     {} & {{a _{22}}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a _{nn}}}  \cr 
  \end{pmatrix}
  \begin{pmatrix}
     {{b_{11}}} & {} & {} & {}  \cr 
     {} & {{b _{22}}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{b _{nn}}}  \cr 
  \end{pmatrix}
  =\begin{pmatrix}
     {{a_{11}b _{11}}} & {} & {} & {}  \cr 
     {} & {{a_{22}b _{22}}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a_{nn}b _{nn}}}  \cr 
  \end{pmatrix}
  $$

  - $c_{ij}=\sum_{k=1}^{j}a_{ik}b_{kj}$

    - $a_{ik}=\delta{(i,k)}a_{ik}$

    - $b_{kj}=\delta(k,j)b_{kj}$

    - $a_{ik}b_{kj}=\delta(i,k)a_{ik}\delta(k,j)b_{kj}$

      - 可见,$c_{ij}=0,i\neq{j}$
      - 当$i=j=k$,$c_{kk}=\delta(k,k)a_{kk}\delta(k,k)b_{kk}=a_{kk}b_{kk}$

    - 其他写法:

      - $$
        a_{ij}=
        \begin{cases}
        a_{ij}&i=j\\
        0&i\neq{j}
        \end{cases}
        \\
        b_{ij}=
        \begin{cases}
        b_{ij}&i=j\\
        0&i\neq{j}
        \end{cases}
        \\
        c_{ij}=\sum_{i=1}^{n}a_{ik}b_{kj}
        =\begin{cases}
        0&i\neq{j}
        \\
        a_{kk}b_{kk}&i=j=k
        \end{cases}
        $$

### 分块乘法

- $$
  P=(\alpha_1,\cdots,\alpha_n)
  \\
  A\in{\mathbb{R}^{n\times{n}}},P\in\mathbb{R}^{n\times{n}}
  ,AP\in\mathbb{R}^{n\times{n}},
  A\alpha_i\in\mathbb{R}^{n\times{1}}
  \\根据矩阵分块乘法:
  \\
  AP=A(\alpha_1,\cdots,\alpha_n)=(A\alpha_1,\cdots,A\alpha_n)
  $$

  

### 互为转置的矩阵乘积

- $$
  \\
  A=\begin{pmatrix}
  \alpha_1&\alpha_2&\cdots &\alpha_{n}
  \end{pmatrix}
  \\
  A^T=\begin{pmatrix}
  \alpha_1^T\\
  \alpha_2^T\\
  \vdots  \\
  \alpha_{n}^T
  \end{pmatrix}
  \\
  A^TA=\begin{pmatrix}
  \alpha_{1}^T\alpha_1&\alpha_{1}^T\alpha_2&\cdots&\alpha_{1}^T\alpha_n\\
  \alpha_{2}^T\alpha_1&\alpha_{2}^T\alpha_2&\cdots&\alpha_{n}^T\alpha_n\\
  \vdots&\vdots&&\vdots\\
  \alpha_{n}^T\alpha_1&\alpha_{n}^T\alpha_2&\cdots&\alpha_{n}^T\alpha_n\\
  \end{pmatrix}
  $$

  

- $c_{ij}=\alpha_{i}^T\alpha_{j}$

- $c_{ji}=\alpha_{j}^T\alpha_{i}$

- 可以看出$c_{ij}=c_{ji}$,即$A^TA$是一个对称阵

- 或者通过计算$(A^TA)^T=A^TA$可知,$A^TA$是对称阵

  

  

## 方阵行列式和特征值

- 行列式，记作 det(A)，是一个将方阵 A 映射到实数的函数。
- 行列式等于**方阵特征值的乘积**。$|A|=\prod_{i=1}{\lambda_i}$
- 行列式的**绝对值**可以用来衡量<u>矩阵参与矩阵乘法后</u>空间扩大或者缩小了多少。
  - 如果行列式是 0，那么空间至少沿着某一维完全收缩了，使其失去了所有的体积。
  - 如果行列式是 1，那么这个转换保持空间体积不变。

## 附:矩阵乘法代码实现

### C语言版

```
有2×3的矩阵a和3×2的矩阵b，求这两个矩阵相乘后的2×2矩阵c，并打印。

要求用函数实现   Multi(int a[][3],int b[][2],int c[][2])
矩阵a，b的值在主函数中输入。


输入
2×3的矩阵a和3×2的矩阵b

输出
这两个矩阵相乘后的2×2矩阵c，并打印。

样例输入
1 2 3
3 2 1

1 2
3 1
2 3
样例输出
13 13
11 11
 
```

```c
#include <stdio.h>
#include <string.h>
#include <math.h>
#include <stdlib.h>
//在此下方插入自定义函数的声明:
void Multi(int a[][3], int b[][2], int c[][2]);
//主函数main
int main()
{

    int a[2][3], b[3][2], c[2][2];
    /* 两个二重循环读入数据 */
    for (int i = 0; i < 2; i++)
    {
        for (int j = 0; j < 3; j++)
        {
            scanf("%d", &a[i][j]);
        }
    }
    for (int i = 0; i < 3; i++)
    {
        for (int j = 0; j < 2; j++)
        {
            scanf("%d", &b[i][j]);
        }
    }
/* 调用执行矩阵计算的函数 */
    Multi(a, b, c);
    /* 将处理结果打印出来 */
    for (int i = 0; i < 2; i++)
    {
        for (int j = 0; j < 2; j++)
        {
            /* 该行的最后一个元素索引是2,那就是在2之前的元素可以跟一个空格 */
            printf("%d", c[i][j]);
            if (j < 1)
            {
                printf(" ");
            }
        }
        //printf("%d\n");//发生了趣事:打印旧值
        printf("\n");
    }

    return 0;
}
//主函数结束.
//在下方编写自定义函数:
void Multi(int a[][3], int b[][2], int c[][2])
{

    /* mxk , kxn ;结果矩阵因该是mxn*/
    int m = 2; /* 矩阵A的行数 */
    int n = 2; /* 矩阵B的列数 */

    int p = 3; /* 矩阵A的列数必须和矩阵B的行数相同,该数值记为k */
    /* 结果矩阵的每一个元素值是一个k项式的和 */

    /* 记得用c中的元素累计值之前初始化c  */
    /* 由结果矩阵C的规格m*n可知,应该用连个循环来填充矩阵C而且行和列分别是m,n */
    for (int i = 0; i < m; i++) /* 控制行遍历(矩阵A的) */
    {
        for (int j = 0; j < n; j++) /* 控制列遍历(矩阵B的列) */
        {
            c[i][j] = 0;                //初始化累加计数器
            for (int k = 0; k < p; k++) /* k作为遍历元素的驱动器(为两个矩阵所共用(具体是,矩阵A横向遍历,矩阵B纵向遍历)) */
            {
                c[i][j] += a[i][k] * b[k][j]; //后者是b 矩阵
            }
        }
    }
}
```



### python 实现

- 对A逐行遍历

  - A的每一行都要对B逐列遍历

  - ```python
    ##
    import numpy as np
    rng = np.random.default_rng()
    m,l,n=3,4,5
    m,l,n=3,1,4
    A=rng.integers(1,10,size=(m,l))
    B=rng.integers(1,10,size=(l,n))
    #使用.dot()方法计算矩阵乘法(内积)
    ##
    C=A.dot(B)
    # 对于二维数组（矩阵）还可以用下列方式计算
    # np.matmul(A,B)
    # A@B
    A,B,C
    ##
    for i in range(m):
        for j in range(n):
            c_ij=0
            for k in range(l):
                # for p in range()
                c_ij+=A[i,k]*B[k,j]
            print("%s\t"%c_ij,end=" ")
        print()
    ##
    for i in range(m):
        for j in range(n):
            c_ij=A[i]*B[:,j]
            print("%s\t"%c_ij[0],end=" ")
            # print("%s\t"%c_ij,end=" ")
        print()
            
    ```

  - 矩阵乘法的三种计算方式的内容都是相同的



### numpy中的乘法

- [numpy.dot — NumPy v1.24 Manual](https://numpy.org/doc/stable/reference/generated/numpy.dot.html)

  - 多用途乘法(根据参数类型有不同的行为)
  - Dot product of two arrays. Specifically,
    - 低维数组和标量的行为:
      - If both *a* and *b* are 1-D arrays, it is inner product of vectors (without complex conjugation).
      - If both *a* and *b* are 2-D arrays, it is matrix multiplication, but using [`matmul`](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html#numpy.matmul) or `a @ b` is preferred.
      - If either *a* or *b* is 0-D (scalar)标量乘法, it is equivalent to [`multiply`](https://numpy.org/doc/stable/reference/generated/numpy.multiply.html#numpy.multiply) and using `numpy.multiply(a, b)` or `a * b` is preferred.
    - 高维数组行为:
      - If *a* is an N-D array and *b* is a 1-D array, it is a sum product over the last axis of *a* and *b*.
      - If *a* is an N-D array and *b* is an M-D array (where `M>=2`), it is a sum product over the last axis of *a* and the second-to-last axis of *b*:

- [numpy.matmul — NumPy  Manual](https://numpy.org/doc/stable/reference/generated/numpy.matmul.html#numpy.matmul)

  - 矩阵乘法
  - 多维数组乘法

- [numpy.multiply — NumPy  Manual](https://numpy.org/doc/stable/reference/generated/numpy.multiply.html#numpy.multiply)

  - Multiply arguments element-wise.逐元素将参数相乘,参数可以是array_like

  - Parameters:

    - **x1, x2**array_like
    - Input arrays to be multiplied. If `x1.shape != x2.shape`, they must be broadcastable to a common shape (which becomes the shape of the output).它们必须可扩展到一个共同的形状（即输出的形状）

  - 按元素相乘参数。

  - ```python
    import numpy as np
    rng = np.random.default_rng()
    
    x1 = np.arange(9.0).reshape((3, 3))
    x2 = np.arange(3.0)
    x3=np.array([x2,x2,x2])
    x1, x2, np.multiply(x1, x2),np.multiply(x1, x3)
    ##
    y1=(10*rng.random((3,4))).round(1)
    y2=(10*rng.random(4,)).round(1)
    y1,y2,np.multiply(y1, y2)
    ##np.multiply可以用*号简写
    print("x1*x2=\n%s,\ny1*y2=\n%s"%(x1*x2,y1*y2))
    ```

  - ```bash
    (array([[0., 1., 2.],
            [3., 4., 5.],
            [6., 7., 8.]]),
     array([0., 1., 2.]),
     array([[ 0.,  1.,  4.],
            [ 0.,  4., 10.],
            [ 0.,  7., 16.]]),
     array([[ 0.,  1.,  4.],
            [ 0.,  4., 10.],
            [ 0.,  7., 16.]]))
            
    (array([[4.8, 0.6, 8.4, 1.5],
            [8.6, 6.6, 8.8, 6.1],
            [7.9, 6.7, 2.2, 2.1]]),
     array([4. , 0.5, 4.8, 8.6]),
     array([[19.2 ,  0.3 , 40.32, 12.9 ],
            [34.4 ,  3.3 , 42.24, 52.46],
            [31.6 ,  3.35, 10.56, 18.06]]))
    x1*x2=
    [[ 0.  1.  4.]
     [ 0.  4. 10.]
     [ 0.  7. 16.]],
    y1*y2=
    [[12.6  14.7  32.68 53.94]
     [38.43  0.63 11.18 64.38]
     [27.09 15.54 39.56 55.68]]
    ```

### broadcasting

- 在深度学习中，我们也使用一些不那么常规的符号。我们允许矩阵和向量相加，产生另一个矩阵：$C = A + b$，其中 $C_{i,j} = A_{i,j} + b_j$。换言之，向量 b 和矩阵A 的每一行相加。
  - 这个简写方法使我们无需在加法操作前定义一个将向量 b 复制到每一行而生成的矩阵。
  - 这种隐式地复制向量 b 到很多位置的方式，被称为 广播（broadcasting）。

- 相乘的两个矩阵可以是相同规格的,或者其中一个规格较小,但可以通过broadcasting操作得到可以相乘的规格[Broadcasting — NumPy v1.24 Manual](https://numpy.org/doc/stable/user/basics.broadcasting.html)
  - [General Broadcasting Rules](https://numpy.org/doc/stable/user/basics.broadcasting.html#general-broadcasting-rules)
  - [Broadcastable arrays](https://numpy.org/doc/stable/user/basics.broadcasting.html#broadcastable-arrays)
  - [A Practical Example: Vector Quantization](https://numpy.org/doc/stable/user/basics.broadcasting.html#a-practical-example-vector-quantization)
- The term broadcasting describes how NumPy treats arrays with different shapes during arithmetic operations. Subject to certain constraints, <u>the smaller array is “broadcast” across the larger array so that they have compatible shapes.</u>
- Broadcasting provides a means of vectorizing array operations so that looping occurs in C instead of Python. 
- It does this without making needless copies of data and usually leads to efficient algorithm implementations. There are, however, cases where broadcasting is a bad idea because it leads to inefficient use of memory that slows computation.

#### 示例代码(矩阵内积)

- 内积,即2个矩阵(广播之后),执行对应元素乘法

- ```python
  ##
  import numpy as np
  rng = np.random.default_rng()
  m=3
  n=4
  A=rng.integers(1,9,size=(m,1))
  B=rng.integers(1,9,size=(1,n))
  print("%s@A;\n%s@B;\n%s@A*B;\n"%(A,B,A*B))
  
  ## matrix broadcasting (m,1)&(1,n)->(m,n)
  Amn=np.array([[A[l][0] for c in range(n)] for l in range(m)])
  Bmn=np.array([[B[0][c] for c in range(n)] for l in range(m)])
  # Bmn=np.array([B[0] for i in range(m)])
  print("%s@Amn\n%s@Bmn\n%s@Amn*Bmn\n"%(Amn,Bmn,Amn*Bmn))
  ```

- ```
  [[8]
   [4]
   [6]]@A;
  [[1 5 4 2]]@B;
  [[ 8 40 32 16]
   [ 4 20 16  8]
   [ 6 30 24 12]]@A*B;
  
  [[8 8 8 8]
   [4 4 4 4]
   [6 6 6 6]]@Amn
  [[1 5 4 2]
   [1 5 4 2]
   [1 5 4 2]]@Bmn
  [[ 8 40 32 16]
   [ 4 20 16  8]
   [ 6 30 24 12]]@Amn*Bmn
  ```



### pytorch中的乘法

- [torch.mm — PyTorch  documentation](https://pytorch.org/docs/stable/generated/torch.mm.html)

