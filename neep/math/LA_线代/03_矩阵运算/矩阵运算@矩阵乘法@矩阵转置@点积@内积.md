

[toc]



## 矩阵乘法@矩阵标准乘积🎈



- 给定$m\times{l}$矩阵$A=(a_{ij})_{m\times{l}}$和$l\times{n}$矩阵$B=(b_{ij})_{l\times{n}}$

- 记A,B的乘积为$C=AB=(c_{ij})_{m\times{n}}$,C中的元素$c_{ij}$计算公式如下

  - $$
    c_{ij}=\sum\limits_{k=1}^{l}a_{ik}b_{kj}
    $$

  - A,B的规格保证了A的列数等于B的行数,<u>A的**行向量**中包含的元素数和B的**列向量**包含的元素都是$l$个</u>

  - 矩阵乘积的结果是一个矩阵,且规格(行数和列数)分别由第一个矩阵的行数和第二个矩阵的列数决定

- 特别地:

  - 如果是两个同n维向量(行向量乘以相同维数的列向量),结果是一个仅包含一个元素的矩阵,这种情况下可以视结果为一个标量)
  - 如果两个同n维向量(列向量乘以行向量),结果是一个n阶方阵

### 矩阵乘法和线性变换

- 利用矩阵乘法可以方便的计算线性变换乘法(嵌套)



## Hadamard 乘积

- [Hadamard product (matrices) - Wikipedia](https://en.wikipedia.org/wiki/Hadamard_product_(matrices))

- Hadamard乘积必矩阵运算更容易执行,只需要执行$n\times m$次乘法运算即可

- 需要注意的是，两个矩阵的**标准乘积**不是指两个矩阵中对应元素的乘积。

- 不过，那样的矩阵操作确实是存在的，被称为 **元素对应乘积**（element-wise product）或者 Hadamard 乘积（Hadamard product），记为 $A\odot B$,其结果是一个与连个因子同型的矩阵。

  - $$
    c_{ij}=a_{ij}b_{ij}
    $$

    -

## 向量点积@内积🎈

### 点积(内积)

- 两个同维数(规格)的n维<u>列向量</u>**向量** a 和 b 的 **点积**（dot product）可看作是矩阵乘积 $a^Tb$。

  - 有时也成为**内积**
  - 此处,维数指向量包含的元素个数

- $$
  {\displaystyle \mathbf {\color {red}a} \cdot \mathbf {\color {blue}b}
  =\sum _{i=1}^{n}{\color {red}a}_{i}{\color {blue}b}_{i}
  ={\color {red}a}_{1}{\color {blue}b}_{1}+{\color {red}a}_{2}{\color {blue}b}_{2}+\cdots +{\color {red}a}_{n}{\color {blue}b}_{n}}
  \\
  内积还常记为(a,b),即(a,b)=a\cdot{b}
  $$

  - 或$a\cdot{b}=\sum\limits_{i=1}^{n}(a\odot{b})_{i}$
    - $a\odot{b}$是向量a,b的hadamard积(向量)

- 向量点积的结果是一个**标量**

#### 性质

- 点积满足交换律(而一般的矩阵乘法是不满足交换律的)

- $(\alpha,\beta)=(\beta,\alpha)$

- $(k\alpha,{\beta})=(\alpha,k\beta)=k(\alpha,\beta)$

  - $$
    \sum_ik\alpha_i\beta_i
    =\sum_{i}\alpha_ik\beta_i
    =k\sum_{i}\alpha_{i}\beta_i
    $$

- $(\alpha+\beta,\gamma)=(\alpha,\gamma)+(\beta,\gamma)$

  - $$
    \sum_{i}(\alpha+\beta)_i\delta_i
    =\sum_{i}(\alpha_i\delta_i+\beta_i\delta_i)
    =\sum_{i}\alpha_i\delta_i+\sum_{i}\beta_i\delta_i
    \\
    $$

- $(\sum\alpha_i,\beta)=\sum(\alpha_i,\beta)$

  - 是上一条结论的tui'gua
    $$
    \sum_{i}\left((\sum_{j}\alpha_j)\delta_i\right)
    =\sum_{i}(\sum_{j}\alpha_j\delta_i)
    $$
    

- $(\alpha,\alpha)\geqslant 0$当且仅当$\alpha=0$时,$(\alpha,\alpha)=0$

  - $$
    \sum_{i}(\alpha_i)^2\geqslant{0}
    $$

    



### 矩阵乘积和向量点积的关系

- 我们可以把矩阵乘积 C = AB 中计算 $c_{ij}=\sum\limits_{k=1}^{l}a_{ik}b_{kj}$ 的步骤看作是 A 的第 i 行和 B 的第 j 列之间的点积。

### 内积补充

- 内积是一个数学概念，也叫标量积、点积或数量积。它是一种将两个向量映射为一个实数的运算。它可以用来计算向量的夹角和长度。在英语中，内积叫做inner product.
  - by chatgpt
- **内积空间**（英语：Inner product space）是[数学](https://zh.wikipedia.org/wiki/数学)中的[线性代数](https://zh.wikipedia.org/wiki/线性代数)里的基本概念，是增添了一个额外的结构的[向量空间](https://zh.wikipedia.org/wiki/向量空间)。这个额外的结构叫做**[内积](https://zh.wikipedia.org/wiki/内积)**或[标量积](https://zh.wikipedia.org/wiki/标量积)。
- 内积将一对[向量](https://zh.wikipedia.org/wiki/向量)与一个标量连接起来，允许我们严格地谈论[向量](https://zh.wikipedia.org/wiki/向量)的“[夹角](https://zh.wikipedia.org/wiki/角)”和“[长度](https://zh.wikipedia.org/wiki/长度)”，并进一步谈论向量的[正交性](https://zh.wikipedia.org/wiki/正交)。
- 内积空间由[欧几里得空间](https://zh.wikipedia.org/wiki/欧几里得空间)抽象而来（内积是点积的抽象）

- 内积空间有时也叫做**准希尔伯特空间**（pre-Hilbert space）

## 矩阵乘法各种形式小结👺

- 矩阵乘法运算具有相当的重要性

- 从向量的角度再描述它

- 设矩阵A为$m\times{n}$的

  - $$
    A=\begin{pmatrix}
    	a_{11}  &a_{12}  &\cdots  &a_{1n}  	\\
    	a_{21}  &a_{22}  &\cdots  &a_{2n}  	\\
    	\vdots  &\vdots  &        &\vdots  	\\
    	a_{m1}  &a_{m2}  &\cdots  &a_{mn}  	\\
    \end{pmatrix}
    \\记列向量\alpha_j
    =\begin{pmatrix}
    	a_{1j}  	\\
    	a_{2j}  	\\
    	\vdots		\\
    	a_{mj}  	\\
    \end{pmatrix},j=1,2,\cdots,n
    \\记行向量\beta_i=(a_{i1},a_{i2},\cdots,a_{in}),i=1,2,\cdots,m
    $$
    
  - 注意$\alpha_i$和$\beta_i$不是转置关系

- 将矩阵写作行向量组和列向量组的分块矩阵形式:

  - $$
    A=
    \begin{pmatrix}
    	\alpha_{1}&\alpha_{2}&\cdots&\alpha_{n}	\\
    \end{pmatrix}
    =\begin{pmatrix}
    	\beta_{1}	\\
    	\beta_{2}	\\
    	\vdots		\\
    	\beta_{m}	\\
    \end{pmatrix}
    $$

- 类似的,设矩阵B为$n\times{s}$的矩阵,$\delta_j,j=1,2,\cdots,s$为列向量,$\theta_i,i=1,2,\cdots,n$为行向量

  - $$
    B=\begin{pmatrix}
    	b_{11}  &b_{12}  &\cdots  &b_{1s}  	\\
    	b_{21}  &b_{22}  &\cdots  &b_{2s}  	\\
    	\vdots  &\vdots  &        &\vdots  	\\
    	b_{n1}  &b_{n2}  &\cdots  &b_{ns}  	\\
    \end{pmatrix}
    \\
    B=(\delta_1,\delta_2,\cdots,\delta_s)
    =\begin{pmatrix}
    	\theta_{1}\\
    	\theta_{2}\\
    	\vdots		\\
    	\theta_{n}	\\
    \end{pmatrix}
    \\\\
    $$

    


### 基础形式

- $$
  C_{m\times{s}}=A_{m\times{n}}B_{n\times{s}},
  \\
  c_{ij}=\sum\limits_{k=1}^{n}a_{ik}b_{kj},(i=1,2,\cdots,m;j=1,2,\cdots,s)
  \\矩阵C记为C=(c_{ij})_{m\times{s}}
  $$

  - ```python
    for i in range_inclusive(1,m):
    	for j in range_inclusive(1,s):
            c_ij=0
            for k in range(l):
                c_ij+=A[i][k]*B[k][j]
            print("%s\t"%c_ij,end=" ")
            
    #其中range_inclusive(a,b)表示生成[a,b]范围内的整数(包括边界在内)
    def range_inclusive(a,b)
    	return range(a,b+1)
    ```

### 向量形式

- 行向量乘列向量(手工计算的基础操作)

- $$
  C=AB=
  \begin{pmatrix}
  	\beta_{1}\\
  	\beta_{2}\\
  	\vdots		\\
  	\beta_{m}	\\
  \end{pmatrix}
  (\delta_1,\delta_2,\cdots,\delta_s)
  =\begin{pmatrix}
  \beta_1\delta_1&\beta_1\delta_2&\cdots&\beta_1\delta_s	\\
  \beta_2\delta_1&\beta_2\delta_2&\cdots&\beta_2\delta_s	\\
  \vdots&\vdots&&\vdots\\
  \beta_m\delta_1&\beta_m\delta_2&\cdots&\beta_m\delta_s	\\
  \end{pmatrix}_{m\times{s}}
  \\
  \\矩阵C的元素:c_{ij}
  =\beta_{i}\delta_j
  =\sum\limits_{k=1}^{n}a_{ik}b_{kj},(i=1,2,\cdots,m;j=1,2,\cdots,s)
  \\\beta_{i}和\delta_j分别是1\times{n},n\times{1}的矩阵(向量),
  \\
  \beta_{i}\delta_j是一个仅含有一个数值元素的矩阵,视为标量
  $$

- 列向量乘行向量

- $$
  C=AB=\begin{pmatrix}
  	\alpha_{1}&\alpha_{2}&\cdots&\alpha_{n}	\\
  \end{pmatrix}
  \begin{pmatrix}
  	\theta_{1}\\
  	\theta_{2}\\
  	\vdots		\\
  	\theta_{n}	\\
  \end{pmatrix}
  =\sum\limits_{i=1}^{n}\alpha_i\theta_i
  \\C,h_i=\alpha_i\theta_i都是m\times{s}的矩阵;
  \\执行n个m\times{s}的矩阵叠加
  $$


### 半矩阵半向量形式

- 矩阵乘以行向量分块

- 设$A\in\mathbb{R}^{m\times{n}}$,按行分块为:

  - $$
    A=\begin{pmatrix}
        A_1\\
        A_2\\
        \vdots\\
        A_m
    \end{pmatrix}
    $$

  

- $$
  C_{m\times{n}}=BA
  =\begin{pmatrix}
  	b_{11}  &b_{12}  &\cdots  &b_{1m}  	\\
  	b_{21}  &b_{22}  &\cdots  &b_{2m}  	\\
  	\vdots  &\vdots  &		  &\vdots  	\\
  	b_{m1}  &b_{m2}  &\cdots  &b_{mm}  	\\
  \end{pmatrix}
  \begin{pmatrix}
      A_1\\
      A_2\\
      \vdots\\
      A_m
  \end{pmatrix}
  =\begin{pmatrix}
  	\sum\limits_{k=1}^{m}b_{1k}A_{k}  	\\
  	\sum\limits_{k=1}^{m}b_{2k}A_{k}   	\\
  	\vdots  	\\
  	\sum\limits_{k=1}^{m}b_{mk}A_{k}   	\\
  \end{pmatrix}
  $$

- 其中$\sum\limits_{k=1}^{m}b_{ik}A_{k}$和$A_k$都是$1\times{n}$的矩阵(行向量)$i=1,2,\cdots,m$

- $$
  \\
  \begin{aligned}
  \sum\limits_{k=1}^{m}b_{ik}A_{k}
      &=\sum_{k=1}^{m}b_{ik}(a_{k1},a_{k2},\cdots,a_{kn})
      \\
      &=\sum_{k=1}^{m}(b_{ik}a_{k1},b_{ik}a_{k2},\cdots,b_{ik}a_{kn})
      \\
      &=(\sum_{k=1}^{m}b_{ik}a_{k1},
      \sum_{k=1}^{m}b_{ik}a_{k2},
      \cdots,
      \sum_{k=1}^{m}b_{ik}a_{kn})
      \\
      &=(c_{i1},c_{i2},\cdots,c_{in})
  \end{aligned}
  \quad i=1,2,\cdots,m
  $$

### 分块形式

- 设$A\in\mathbb{R}^{m\times{n}}$,$B\in\mathbb{R}^{n\times{s}}$

- 对B按列分块:$B=(B_1,B_2,\cdots,B_s)$则:

  - $$
    AB=A(B_1,\cdots,B_s)=(AB_1,\cdots,AB_s)
    $$

  - 这里A一整个矩阵被视为一个子块(将整个A视为作为一个元素),则$A(B_1,\cdots,B_s)$该操作类似于向量的数乘

  - 这种划分是允许的,因为$A$的列数和$B_i,(i=1,2,\cdots,s)$的行数相等

  - $AB_i\in{\mathbb{R}^{n\times{1}}}$

  - 类似与线性方程组的形式$A\boldsymbol{x}=\boldsymbol{b}$

- $$
  A=(\theta_{1},\cdots,\theta_{n})
  \\
  C=(\delta_{1},\cdots,\delta_{s})
  \\
  B=\begin{pmatrix}
     b_{11}&  b_{12}&  \cdots&b_{1s} \\
      b_{21}&  b_{22}&  \cdots&b_{2s} \\
      \vdots&  \vdots&  &\vdots \\
      b_{n1}&  b_{n2}&  \cdots&b_{ns} \\
  \end{pmatrix}
  \\
  AB=C
  \\
  (\theta_{1},\cdots,\theta_{n})
  \begin{pmatrix}
     b_{11}&  b_{12}&  \cdots&b_{1s} \\
      b_{21}&  b_{22}&  \cdots&b_{2s} \\
      \vdots&  \vdots&  &\vdots \\
      b_{n1}&  b_{n2}&  \cdots&b_{ns} \\
  \end{pmatrix}
  =(\delta_{1},\cdots,\delta_{s})
  \\
  \delta_{j}=\sum_{k=1}^{n}\theta_{k}b_{kj}
  =\sum_{k=1}^{n}b_{kj}\theta_{k}
  $$

  - 类似线性表出的形式$\delta_j$被$\theta_1,\cdots,\theta_n$线性表出,表出系数为$b_{1j},\cdots,b_{nj}$

### 点积形式

- 在掌握点积和矩阵-向量积的知识后，那么**矩阵-矩阵乘法**（matrix-matrix multiplication）应该很简单。


- 假设有两个矩阵$\mathbf{A} \in \mathbb{R}^{n \times k}$和$\mathbf{B} \in \mathbb{R}^{k \times m}$：

  - $$
    \mathbf{A}=\begin{bmatrix}
     a_{11} & a_{12} & \cdots & a_{1k} \\
     a_{21} & a_{22} & \cdots & a_{2k} \\
    \vdots & \vdots & \ddots & \vdots \\
     a_{n1} & a_{n2} & \cdots & a_{nk} \\
    \end{bmatrix},\quad
    \mathbf{B}=\begin{bmatrix}
     b_{11} & b_{12} & \cdots & b_{1m} \\
     b_{21} & b_{22} & \cdots & b_{2m} \\
    \vdots & \vdots & \ddots & \vdots \\
     b_{k1} & b_{k2} & \cdots & b_{km} \\
    \end{bmatrix}.
    $$

    

- 用行向量$\mathbf{a}^\top_{i} \in \mathbb{R}^k$表示矩阵$\mathbf{A}$的第$i$行，并让列向量$\mathbf{b}_{j} \in \mathbb{R}^k$作为矩阵$\mathbf{B}$的第$j$列。要生成矩阵积$\mathbf{C} = \mathbf{A}\mathbf{B}$，最简单的方法是考虑$\mathbf{A}$的行向量和$\mathbf{B}$的列向量:

  - $$
    \mathbf{A}=
    \begin{bmatrix}
    \mathbf{a}^\top_{1} \\
    \mathbf{a}^\top_{2} \\
    \vdots \\
    \mathbf{a}^\top_n \\
    \end{bmatrix},
    \quad \mathbf{B}=\begin{bmatrix}
     \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m} \\
    \end{bmatrix}
    $$

    

- 当我们简单地将每个元素$c_{ij}$计算为点积$\mathbf{a}^\top_i \mathbf{b}_j$:
  $$
  \mathbf{C} = \mathbf{AB} = \begin{bmatrix}
  \mathbf{a}^\top_{1} \\
  \mathbf{a}^\top_{2} \\
  \vdots \\
  \mathbf{a}^\top_n \\
  \end{bmatrix}
  \begin{bmatrix}
   \mathbf{b}_{1} & \mathbf{b}_{2} & \cdots & \mathbf{b}_{m} \\
  \end{bmatrix}
  = \begin{bmatrix}
  \mathbf{a}^\top_{1} \mathbf{b}_1 & \mathbf{a}^\top_{1}\mathbf{b}_2& \cdots & \mathbf{a}^\top_{1} \mathbf{b}_m \\
   \mathbf{a}^\top_{2}\mathbf{b}_1 & \mathbf{a}^\top_{2} \mathbf{b}_2 & \cdots & \mathbf{a}^\top_{2} \mathbf{b}_m \\
   \vdots & \vdots & \ddots &\vdots\\
  \mathbf{a}^\top_{n} \mathbf{b}_1 & \mathbf{a}^\top_{n}\mathbf{b}_2& \cdots& \mathbf{a}^\top_{n} \mathbf{b}_m
  \end{bmatrix}.
  $$

- [**我们可以将矩阵-矩阵乘法$\mathbf{AB}$看作简单地执行$m$次矩阵-向量积，并将结果拼接在一起，形成一个$n \times m$矩阵**]。

### 对角阵的乘积🎈

#### 一般对角阵的情况

- 设矩阵P按列分块为:$P=(\alpha_1,\cdots,\alpha_n)$

- $n$阶对角阵$A=\Lambda=\rm{diag}(\lambda_1,\cdots,\lambda_n)$

- $$
  A=
  \begin{pmatrix}
     {{a _{11}}} & {} & {} & {}  \cr 
     {} & {{a _{22}}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a _{nn}}}  \cr 
  \end{pmatrix}=
  \begin{pmatrix}
     {{\lambda _1}} & {} & {} & {}  \cr 
     {} & {{\lambda _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{\lambda _n}}  \cr 
  \end{pmatrix}
  \\
  B_{n\times{s}}=  
  \begin{pmatrix}  
    b_{11}& b_{12}& \cdots  & b_{1s} \\  
    b_{21}& b_{22}& \cdots  & b_{2s} \\  
    \vdots & \vdots & \ddots & \vdots \\  
    b_{n1}& b_{n2}& \cdots  & b_{ns}  
  \end{pmatrix}
  $$

- 

  - $$
    c_{ij}=\begin{cases}
    0&i\neq{j}\\
    a_{kk}=\lambda_{k}&i=j=k
    \end{cases}
    \\
    C=AB
    \\
    c_{ij}=\sum_{i=1}^n
    a_{ik}b_{kj}=a_{ii}b_{ij}=\lambda_{i}b_{ij},(k=i)
    \\
    可见,对角矩阵\Lambda(\lambda_{1},\cdots,\lambda_{2})
    左乘B相当于对B的第i行乘以\lambda_{i}
    \\
    $$


#### 更一般的情况@每行不超过一个非0元素

- 假设矩阵$A$是$m\times{n}$的,其中每一行中的非零元素不超过1个(或者假设每行就有一个非0元素)

- 将该矩阵中每行的非0元素所在的列记为$j_1,\cdots,j_m$,即每行的非零元素表示为:$\large{a_{i,j_{i}}}=\xi_{i}$,其中$i=1,2,\cdots,m$;$j或j_{i}=1,2,\cdots,n$

- 我们可以将此时的矩阵A记为$A=\eta(\xi_1,\cdots,\xi_m)$

- 
  $$
  a_{ij}=
  \begin{cases}
  0&j\neq j_i\\
  \xi_i&j=j_{i}
  \end{cases}
  \\
  c_{ij}
  =\sum_{k=1}^{n}a_{ik}b_{kj}
  =a_{i,j_i}b_{j_i,j}=\xi_ib_{j_i,j}
  $$
  
  $$
  \begin{aligned}
  C
      &=AB\\
      &=\eta(\xi_1,\cdots,\xi_m)
      \begin{pmatrix}  
        b_{11}& b_{12}& \cdots  & b_{1s} \\  
        b_{21}& b_{22}& \cdots  & b_{2s} \\  
        \vdots & \vdots & \ddots & \vdots \\  
        b_{n1}& b_{n2}& \cdots  & b_{ns}  
      \end{pmatrix}
      \\
      &=\begin{pmatrix}
      \xi_1b_{j_1,1}&\xi_1b_{j_1,2}&\cdots&\xi_1b_{j_1,s}\\
      \xi_2b_{j_2,1}&\xi_2b_{j_2,2}&\cdots&\xi_2b_{j_2,s}\\
      \vdots&&&\vdots\\
      \xi_mb_{j_m,1}&\xi_mb_{j_m,2}&\cdots&\xi_mb_{j_m,s}
      \end{pmatrix}
  \end{aligned}
  $$
  
  
  
- 观察可以发现,C的第$i$行是通过对B中的第$j_i$行乘以一个系数$\xi_{i}$得到

- 因此,可以对矩阵B左乘$A$来间接调整B中的行的效果(将系数都设为1)

- 此外,当$j_p=j_q,\xi_{p}=\xi_{q},p\neq{q}$时,$C=AB$中第p行和第q行会是相等的

- 基于上述基本结论,如果我们将A设定为某个初等矩阵,也就是第i行和第j行交互位置,那么$C=AB$等价于对矩阵B的第i,j行对调

- #### 使用分块矩阵来描述

  

- $$
  \Lambda{P}
  =\begin{pmatrix}
     {{\lambda _1}} & {} & {} & {}  \cr 
     {} & {{\lambda _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{\lambda _n}}  \cr 
  \end{pmatrix}
  \begin{pmatrix}
    \beta_{1}\\
    \beta_{2}\\
    \vdots    \\
    \beta_{n}  \\
  \end{pmatrix}
  =\begin{pmatrix}
    \lambda_1\beta_{1}\\
    \lambda_2\beta_{2}\\
    \vdots    \\
    \lambda_n\beta_{n} \\
  \end{pmatrix}
  $$

  
  $$
  \Lambda
  =(\alpha_1,\cdots,\alpha_n)
  \begin{pmatrix}
     {{\lambda _1}} & {} & {} & {}  \cr 
     {} & {{\lambda _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{\lambda _n}}  \cr 
  \end{pmatrix}
  =(\lambda_{1}\alpha_1,\cdots,\lambda_n\alpha_n)
  $$
  
- $$
  \begin{pmatrix}
     {{a _1}} & {} & {} & {}  \cr 
     {} & {{a _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a _n}}  \cr 
  \end{pmatrix}
  \begin{pmatrix}
     {{b_1}} & {} & {} & {}  \cr 
     {} & {{b _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{b _n}}  \cr 
  \end{pmatrix}
  =\begin{pmatrix}
     {{a_1b _1}} & {} & {} & {}  \cr 
     {} & {{a_2b _2}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a_nb _n}}  \cr 
  \end{pmatrix}
  $$

  - 也就是说,两个同型对角阵的矩阵乘法和hadamard运算结果一致$\Lambda_1\Lambda_2=\Lambda\odot\Lambda_2$

- $$
  \begin{pmatrix}
     {{a _{11}}} & {} & {} & {}  \cr 
     {} & {{a _{22}}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a _{nn}}}  \cr 
  \end{pmatrix}
  \begin{pmatrix}
     {{b_{11}}} & {} & {} & {}  \cr 
     {} & {{b _{22}}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{b _{nn}}}  \cr 
  \end{pmatrix}
  =\begin{pmatrix}
     {{a_{11}b _{11}}} & {} & {} & {}  \cr 
     {} & {{a_{22}b _{22}}} & {} & {}  \cr 
     {} & {} &  \ddots  & {}  \cr 
     {} & {} & {} & {{a_{nn}b _{nn}}}  \cr 
  \end{pmatrix}
  $$

  - $c_{ij}=\sum_{k=1}^{j}a_{ik}b_{kj}$

    - $a_{ik}=\delta{(i,k)}a_{ik}$

    - $b_{kj}=\delta(k,j)b_{kj}$

    - $a_{ik}b_{kj}=\delta(i,k)a_{ik}\delta(k,j)b_{kj}$

      - 可见,$c_{ij}=0,i\neq{j}$
      - 当$i=j=k$,$c_{kk}=\delta(k,k)a_{kk}\delta(k,k)b_{kk}=a_{kk}b_{kk}$

    - 其他写法:

      - $$
        a_{ij}=
        \begin{cases}
        a_{ij}&i=j\\
        0&i\neq{j}
        \end{cases}
        \\
        b_{ij}=
        \begin{cases}
        b_{ij}&i=j\\
        0&i\neq{j}
        \end{cases}
        \\
        c_{ij}=\sum_{i=1}^{n}a_{ik}b_{kj}
        =\begin{cases}
        0&i\neq{j}
        \\
        a_{kk}b_{kk}&i=j=k
        \end{cases}
        $$

### 分块乘法

- $$
  P=(\alpha_1,\cdots,\alpha_n)
  \\
  A\in{\mathbb{R}^{n\times{n}}},P\in\mathbb{R}^{n\times{n}}
  ,AP\in\mathbb{R}^{n\times{n}},
  A\alpha_i\in\mathbb{R}^{n\times{1}}
  \\根据矩阵分块乘法:
  \\
  AP=A(\alpha_1,\cdots,\alpha_n)=(A\alpha_1,\cdots,A\alpha_n)
  $$

  

### 互为转置的矩阵乘积

- $$
  \\
  A=\begin{pmatrix}
  \alpha_1&\alpha_2&\cdots &\alpha_{n}
  \end{pmatrix}
  \\
  A^T=\begin{pmatrix}
  \alpha_1^T\\
  \alpha_2^T\\
  \vdots  \\
  \alpha_{n}^T
  \end{pmatrix}
  \\
  A^TA=\begin{pmatrix}
  \alpha_{1}^T\alpha_1&\alpha_{1}^T\alpha_2&\cdots&\alpha_{1}^T\alpha_n\\
  \alpha_{2}^T\alpha_1&\alpha_{2}^T\alpha_2&\cdots&\alpha_{n}^T\alpha_n\\
  \vdots&\vdots&&\vdots\\
  \alpha_{n}^T\alpha_1&\alpha_{n}^T\alpha_2&\cdots&\alpha_{n}^T\alpha_n\\
  \end{pmatrix}
  $$

  

- $c_{ij}=\alpha_{i}^T\alpha_{j}$

- $c_{ji}=\alpha_{j}^T\alpha_{i}$

- 可以看出$c_{ij}=c_{ji}$,即$A^TA$是一个对称阵

- 或者通过计算$(A^TA)^T=A^TA$可知,$A^TA$是对称阵

  

  

## 方阵行列式和特征值

- 行列式，记作 det(A)，是一个将方阵 A 映射到实数的函数。
- 行列式等于**方阵特征值的乘积**。$|A|=\prod_{i=1}{\lambda_i}$
- 行列式的**绝对值**可以用来衡量<u>矩阵参与矩阵乘法后</u>空间扩大或者缩小了多少。
  - 如果行列式是 0，那么空间至少沿着某一维完全收缩了，使其失去了所有的体积。
  - 如果行列式是 1，那么这个转换保持空间体积不变。



