## 学习任务和概念

- 使用机器学习来发掘表示本身，而不仅仅把表示映射到输出。这种方法我们称之为 表示学习（representation learning）。

  - 例如从识别图像中的车轮
    - 车轮的基本特征几何是圆的,但是这个远远不足以良好表示和描述车轮(比如圆的东西不一定是车轮,车轮被遮挡后显露出来的非圆图形)
  - 表示学习到的表示往往比手动设计的表示表现得更好。
  - 并且它们只需最少的人工干预，就能让AI系统迅速适应新的任务。
  - 表示学习算法只需几分钟就可以为简单的任务发现一个很好的特征集，对于复杂任务则需要几小时到几个月。
  - 手动为一个复杂的任务设计特征需要耗费大量的人工时间和精力；甚至需要花费整个社群研究人员几十年的时间。

- 表示学习算法的典型例子是 **自编码器**（autoencoder）。

  - 自编码器由一个 编码器（encoder）函数和一个 解码器（decoder）函数组合而成。
  - 编码器函数将<u>输入数据</u>转换为一种<u>不同的表示</u>，而解码器函数则将这个<u>新的表示转换到原来的形式</u>。
  - 我们期望当输入数据经过编码器和解码器之后<u>尽可能多地保留信息</u>，同时希望<u>新的表示有各种好的特性</u>，这也是自编码器的<u>训练目标</u>。
  - 为了实现不同的特性，我们可以<u>设计不同形式的自编码器</u>。当设计特征或设计用于学习特征的算法时，我们的目<u>标通常是**分离出**能解释观察数据</u>的 **变差因素**（factors of variation）。
    - 在此背景下，‘‘因素’’ 这个词仅<u>指代影响的不同来源</u>；因素通常不是乘性组合。这些因素通常是不能被直接观察到的量。
    - 相反，它们可能是现实世界中观察不到的物体或者不可观测的力，但<u>会影响可观测的量</u>。
    - 为了对观察到的数据提供有用的简化**解释**或推断其**原因**，它们还可能以概念的形式存在于人类的思维中。它们可以被看作<u>数据的概念或者抽象</u>，帮助我们了解这些数据的丰富多样性。
      - 当分析语音记录时，变差因素包括说话者的年龄、性别、他们的口音和他们正在说的词语。
      - 当分析汽车的图像时，变差因素包括汽车的位置、它的颜色、太阳的角度和亮度。
    - 在许多现实的人工智能应用中，困难主要源于多个变差因素同时影响着我们能够观察到的每一个数据。
      - 比如，在一张包含红色汽车的图片中，其单个像素在夜间可能会非常接近黑色。
      - 汽车轮廓的形状取决于视角。大多数应用需要我们理清变差因素并忽略我们不关心的因素。

- 显然，从原始数据中提取高层次、抽象的特征是非常困难的。

  - 许多诸如说话口音这样的变差因素，只能通过对数据进行复杂的、接近人类水平的理解来辨识。这几乎与获得原问题的表示一样困难

- 深度学习（deep learning）通过其他较简单的表示来表达复杂表示，解决了表示学习中的核心问题。

  - 深度学习让计算机通过较简单概念构建复杂的概念。
  - 如何通过组合较简单的概念（例如转角和轮廓，它们转而由边线定义）来表示图像中人的概念。深度学习模型的典型例子是前馈深度网络或 多层感知机（multilayerperceptron, MLP）。多层感知机仅仅是一个将一组输入值映射到输出值的数学函数。该函数由许多较简单的函数复合而成。我们可以认为不同数学函数的每一次应用都为输入提供了新的表示。
  - 深度学习是一种特定类型的机器学习，具有强大的能力和灵活性，它将大千世界表示为嵌套的层次概念体系（由较简单概念间的联系定义复杂概念、从一般抽象概括到高级抽象表示）

- 深度学习是一种表示学习，也是一种机器学习

- AI技术的包含关系(大致为四层)

  - AI
    - MachineLearning(ML)
      - RepresentationLearning(RL)
        - DeepLearning(DL)

  - $DL\sub{RL}\sub{ML}\sub{AI}$



