[toc]

# åˆ†ç±»é—®é¢˜

- åˆ†ç±»é—®é¢˜æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸€ç§é‡è¦é—®é¢˜ï¼Œå…¶ç›®æ ‡æ˜¯å°†æ•°æ®åˆ†ä¸ºä¸åŒçš„ç±»åˆ«æˆ–æ ‡ç­¾ã€‚åœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨ä¸€äº›å·²çŸ¥ç±»åˆ«çš„è®­ç»ƒæ•°æ®æ¥è®­ç»ƒåˆ†ç±»æ¨¡å‹ï¼Œç„¶åç”¨è¯¥æ¨¡å‹å¯¹æœªçŸ¥æ•°æ®è¿›è¡Œåˆ†ç±»é¢„æµ‹ã€‚

- åˆ†ç±»é—®é¢˜å¯ä»¥åˆ†ä¸ºä¸¤ç±»ï¼šå•æ ‡ç­¾åˆ†ç±»é—®é¢˜å’Œå¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ã€‚åœ¨å•æ ‡ç­¾åˆ†ç±»é—®é¢˜ä¸­ï¼Œæ¯ä¸ªæ ·æœ¬åªæœ‰ä¸€ä¸ªæ ‡ç­¾ï¼Œéœ€è¦å°†å…¶åˆ†ä¸ºä¸¤ä¸ªæˆ–å¤šä¸ªç±»åˆ«ï¼›è€Œåœ¨å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ä¸­ï¼Œæ¯ä¸ªæ ·æœ¬å¯ä»¥å±äºå¤šä¸ªç±»åˆ«ï¼Œéœ€è¦åŒæ—¶é¢„æµ‹å¤šä¸ªæ ‡ç­¾ã€‚

- åœ¨åˆ†ç±»é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä½¿ç”¨ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œå¦‚å†³ç­–æ ‘ã€é€»è¾‘å›å½’ã€æ”¯æŒå‘é‡æœºã€ç¥ç»ç½‘ç»œç­‰æ¥è¿›è¡Œå»ºæ¨¡å’Œé¢„æµ‹ã€‚åœ¨å»ºæ¨¡è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬éœ€è¦é€‰æ‹©åˆé€‚çš„ç‰¹å¾å’Œæ¨¡å‹ï¼Œä½¿ç”¨è®­ç»ƒæ•°æ®æ¥æ‹Ÿåˆæ¨¡å‹ï¼Œå¹¶ä½¿ç”¨è¯„ä¼°æŒ‡æ ‡ï¼ˆå¦‚å‡†ç¡®ç‡ã€å¬å›ç‡ã€ç²¾ç¡®ç‡ã€F1å¾—åˆ†ç­‰ï¼‰æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

- åˆ†ç±»é—®é¢˜åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰å¹¿æ³›çš„åº”ç”¨ï¼Œå¦‚æ–‡æœ¬åˆ†ç±»ã€å›¾åƒåˆ†ç±»ã€éŸ³é¢‘åˆ†ç±»ã€ä¿¡ç”¨è¯„çº§ç­‰ã€‚


### classifierå’Œestimator

- åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œåˆ†ç±»å™¨ï¼ˆclassifierï¼‰å’Œä¼°è®¡å™¨ï¼ˆestimatorï¼‰éƒ½æ˜¯æŒ‡ç”¨äºæ„å»ºæ¨¡å‹çš„ç®—æ³•æˆ–ç±»ã€‚å®ƒä»¬çš„ä¸»è¦åŒºåˆ«åœ¨äºï¼Œåˆ†ç±»å™¨æ˜¯ä¸€ç§ç”¨äºåˆ†ç±»ä»»åŠ¡çš„ç®—æ³•æˆ–ç±»ï¼Œè€Œä¼°è®¡å™¨åˆ™æ˜¯ä¸€ç§ç”¨äºé¢„æµ‹ä»»åŠ¡çš„ç®—æ³•æˆ–ç±»ã€‚
- å…·ä½“æ¥è¯´ï¼Œåˆ†ç±»å™¨ç”¨äºå°†æ ·æœ¬åˆ†åˆ°ä¸åŒçš„ç±»åˆ«ä¸­ï¼Œä¾‹å¦‚äºŒå…ƒåˆ†ç±»ã€å¤šç±»åˆ†ç±»ã€å¤šæ ‡ç­¾åˆ†ç±»ç­‰ã€‚å¸¸è§çš„åˆ†ç±»å™¨åŒ…æ‹¬æœ´ç´ è´å¶æ–¯ã€å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºã€éšæœºæ£®æ—ç­‰ã€‚
- è€Œä¼°è®¡å™¨åˆ™ç”¨äºé¢„æµ‹æ•°å€¼å‹çš„ç›®æ ‡å˜é‡ï¼Œä¾‹å¦‚çº¿æ€§å›å½’ã€å²­å›å½’ã€Kè¿‘é‚»å›å½’ç­‰ã€‚ä¼°è®¡å™¨å¯ä»¥ç”¨äºå›å½’ä»»åŠ¡ã€èšç±»ä»»åŠ¡ã€é™ç»´ä»»åŠ¡ç­‰ã€‚
- éœ€è¦æ³¨æ„çš„æ˜¯ï¼ŒScikit-learnä¸­çš„ä¼°è®¡å™¨ï¼ˆestimatorï¼‰æ˜¯ä¸€ä¸ªæ›´å¹¿æ³›çš„æ¦‚å¿µï¼Œå®ƒåŒ…æ‹¬äº†åˆ†ç±»å™¨ã€å›å½’å™¨ã€èšç±»å™¨ã€é™ç»´å™¨ç­‰ä¸åŒç±»å‹çš„ç®—æ³•æˆ–ç±»ã€‚


## ä¸åŒç±»å‹çš„åˆ†ç±»é—®é¢˜çš„æ¯”è¾ƒ

- A classifier supports modeling some of [binary](https://scikit-learn.org/stable/glossary.html#term-binary), [multiclass](https://scikit-learn.org/stable/glossary.html#term-multiclass), [multilabel](https://scikit-learn.org/stable/glossary.html#term-multilabel), or [multiclass multioutput](https://scikit-learn.org/stable/glossary.html#term-multiclass-multioutput) targets. Within scikit-learn, all classifiers support multi-class classification, defaulting to using a one-vs-rest strategy over the binary classification problem.
- ä¸€ä¸ªåˆ†ç±»å™¨å¯ä»¥æ”¯æŒå»ºæ¨¡ä¸€äº›äºŒå…ƒåˆ†ç±»ï¼ˆbinaryï¼‰ã€å¤šç±»åˆ†ç±»ï¼ˆmulticlassï¼‰ã€å¤šæ ‡ç­¾åˆ†ç±»ï¼ˆmultilabelï¼‰æˆ–è€…å¤šè¾“å‡ºå¤šç±»åˆ†ç±»ï¼ˆmulticlass multioutputï¼‰çš„ç›®æ ‡æ•°æ®ã€‚åœ¨scikit-learnä¸­ï¼Œæ‰€æœ‰çš„åˆ†ç±»å™¨éƒ½æ”¯æŒå¤šç±»åˆ«åˆ†ç±»ï¼ˆmulti-class classificationï¼‰ï¼Œé»˜è®¤ä½¿ç”¨ä¸€å¯¹å¤šï¼ˆone-vs-restï¼‰ç­–ç•¥æ¥è§£å†³äºŒå…ƒåˆ†ç±»é—®é¢˜ã€‚

## åŸºæœ¬æœ¯è¯­å’Œæ¦‚å¿µ

- [Glossary of Common Terms and API Elements â€” scikit-learn 1.2.2 documentation](https://scikit-learn.org/stable/glossary.html#glossary-target-types)
- [é€šç”¨æœ¯è¯­è¡¨å’ŒAPIå…ƒç´ -scikit-learnä¸­æ–‡ç¤¾åŒº](https://scikit-learn.org.cn/view/846.html)

### samples

- We usually use this term as a noun to indicate a single feature vector. 
  - Elsewhere a sample is called an instance, data point, or observation.
-  n_samples indicates the number of samples in a dataset, being the number of rows in a data array X.
- åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å°†â€œsamplesâ€è¿™ä¸ªæœ¯è¯­ç”¨ä½œåè¯ï¼Œè¡¨ç¤º**å•ä¸ªç‰¹å¾å‘é‡**ã€‚
  - åœ¨å…¶ä»–åœ°æ–¹ï¼Œæ ·æœ¬ä¹Ÿè¢«ç§°ä¸ºå®ä¾‹ã€æ•°æ®ç‚¹æˆ–è§‚å¯Ÿã€‚
- n_samplesè¡¨ç¤ºæ•°æ®é›†ä¸­æ ·æœ¬çš„æ•°é‡ï¼Œå³æ•°æ®æ•°ç»„Xä¸­çš„è¡Œæ•°ã€‚

### targets

- The dependent variable in supervised (and semisupervised) learning, passed as `y` to an estimatorâ€™s fit method. 
- Also known as:
  -  `dependent variable`, 
  - `outcome variable`, 
  - `response variable`, 
  - `ground truth` ,
  -  `label`. 
- Scikit-learn works with targets that have minimal structure: a class from a finite set, a finite real-valued number, multiple classes, or multiple numbers. See Target Types.
- åœ¨ç›‘ç£å­¦ä¹ ï¼ˆå’ŒåŠç›‘ç£å­¦ä¹ ï¼‰ä¸­ï¼Œç›®æ ‡å˜é‡æ˜¯ä¼ é€’ç»™ä¼°è®¡å™¨çš„â€œfitâ€æ–¹æ³•çš„yå‚æ•°ï¼Œè¡¨ç¤ºä¾èµ–å˜é‡ã€‚ç›®æ ‡å˜é‡ä¹Ÿè¢«ç§°ä¸ºå› å˜é‡ã€ç»“æœå˜é‡ã€å“åº”å˜é‡ã€å®é™…å€¼æˆ–æ ‡ç­¾ã€‚
- Scikit-learnä¸å…·æœ‰æœ€å°ç»“æ„çš„ç›®æ ‡å˜é‡ä¸€èµ·å·¥ä½œï¼šæ¥è‡ªæœ‰é™é›†çš„ç±»åˆ«ã€æœ‰é™çš„å®æ•°å€¼ã€å¤šä¸ªç±»åˆ«æˆ–å¤šä¸ªæ•°å­—ã€‚è¯·å‚è§ç›®æ ‡ç±»å‹ï¼ˆTarget Typesï¼‰ã€‚
- ä¸¾ä¸ªä¾‹å­ï¼Œå‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­æ¯ä¸ªæ ·æœ¬éƒ½æœ‰ä¸€ç»„ç‰¹å¾ï¼Œä¾‹å¦‚ä¸€äº›æ•°å€¼æˆ–æ–‡æœ¬ï¼Œä»¥åŠä¸€ä¸ªç›®æ ‡å˜é‡ï¼Œå¦‚å•†å“çš„ä»·æ ¼ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å°†ä»·æ ¼è§†ä¸ºç›®æ ‡å˜é‡ï¼Œå¹¶å°†å…¶ä½œä¸ºyä¼ é€’ç»™ç›‘ç£å­¦ä¹ ç®—æ³•çš„æ‹Ÿåˆæ–¹æ³•ã€‚ç®—æ³•å°†ä½¿ç”¨ç‰¹å¾æ¥é¢„æµ‹ä»·æ ¼ï¼Œå¹¶å°†è¿™äº›é¢„æµ‹ä¸å®é™…ä»·æ ¼è¿›è¡Œæ¯”è¾ƒï¼Œä»¥è¯„ä¼°ç®—æ³•çš„æ€§èƒ½ã€‚åœ¨è¿™é‡Œï¼Œä»·æ ¼æ˜¯æˆ‘ä»¬çš„å“åº”å˜é‡/ç›®æ ‡å˜é‡/åŸºæœ¬äº‹å®/æ ‡ç­¾ã€‚

### outputsğŸˆ( output variable )

- Individual scalar/categorical variables per sample in the [target](https://scikit-learn.org/stable/glossary.html#term-target). 
- For example, in multilabel classification each possible label corresponds to a binary output.
- Also called *responses*, *tasks* or *targets*. See [multiclass multioutput](https://scikit-learn.org/stable/glossary.html#term-multiclass-multioutput) and [continuous multioutput](https://scikit-learn.org/stable/glossary.html#term-continuous-multioutput).
- ä¾‹å¦‚ï¼Œåœ¨å¤šæ ‡ç­¾åˆ†ç±»ä¸­ï¼Œæ¯ä¸ªå¯èƒ½çš„æ ‡ç­¾å¯¹åº”ä¸€ä¸ªäºŒè¿›åˆ¶è¾“å‡ºã€‚
  - å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ•°æ®é›†ï¼Œå…¶ä¸­æ¯ä¸ªæ ·æœ¬å¯ä»¥è¢«åˆ†ä¸ºå¤šä¸ªç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œä¸€ç¯‡æ–‡ç« å¯èƒ½å±äºå¤šä¸ªä¸»é¢˜ï¼Œå¦‚ç§‘æŠ€ã€ä½“è‚²å’Œæ”¿æ²»ç­‰ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ¯ä¸ªä¸»é¢˜è§†ä¸ºä¸€ä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜ï¼Œå…¶ä¸­æ¯ä¸ªä¸»é¢˜éƒ½æ˜¯ä¸€ä¸ªäºŒå…ƒè¾“å‡ºå˜é‡ï¼Œå¦‚æœè¯¥æ–‡ç« å±äºè¯¥ä¸»é¢˜ï¼Œåˆ™å¯¹åº”çš„å˜é‡ä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚
  - æˆ‘ä»¬å¯ä»¥å°†è¿™äº›äºŒå…ƒå˜é‡æ”¾åœ¨ä¸€ä¸ªçŸ©é˜µä¸­ï¼Œæ¯è¡Œå¯¹åº”ä¸€ä¸ªæ ·æœ¬ï¼Œæ¯åˆ—å¯¹åº”ä¸€ä¸ªä¸»é¢˜ï¼Œè¿™å°±æ˜¯å¤šæ ‡ç­¾æŒ‡ç¤ºçŸ©é˜µã€‚åœ¨è¿™é‡Œï¼Œæ¯ä¸ªå•ç‹¬çš„æ ‡ç­¾éƒ½æ˜¯ç›®æ ‡ä¸­çš„ä¸€ä¸ªæ ‡é‡/åˆ†ç±»å˜é‡ï¼Œæ¯ä¸ªæ ·æœ¬éƒ½æœ‰è‡ªå·±çš„ä¸€ç»„è¿™äº›å˜é‡ä½œä¸ºå“åº”/ä»»åŠ¡/ç›®æ ‡ã€‚

- è¿™äº›å˜é‡ä¹Ÿè¢«ç§°ä¸º<u>å“åº”ã€ä»»åŠ¡æˆ–ç›®æ ‡</u>ã€‚è¯·å‚è§å¤šç±»å¤šè¾“å‡ºå’Œè¿ç»­å¤šè¾“å‡ºã€‚

## Target Types

- [target types|document](https://scikit-learn.org/stable/glossary.html#target-types)
- æ³¨æ„ç±»å‹å…¼å®¹

### type_of_targetå‡½æ•°ğŸˆ

- [sklearn.utils.multiclass.type_of_target â€” scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html)
  - Determine the type of data indicated by the target. Note that this type is the most specific type that can be inferred. For example: binary is more specific but compatible with multiclass. multiclass of integers is more specific but compatible with continuous. multilabel-indicator is more specific but compatible with multiclass-multioutput. 

- ç¡®å®šç›®æ ‡æŒ‡ç¤ºçš„æ•°æ®ç±»å‹ã€‚ éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¿™ä¸ªç±»å‹æ˜¯å¯ä»¥æ¨æ–­å‡ºçš„æœ€å…·ä½“çš„ç±»å‹ã€‚
  - ä¾‹å¦‚ï¼š äºŒå…ƒç±»å‹æ›´å…·ä½“ï¼Œä½†ä¸å¤šç±»ç±»å‹å…¼å®¹ã€‚ æ•´æ•°çš„å¤šç±»ç±»å‹æ›´å…·ä½“ï¼Œä½†ä¸è¿ç»­ç±»å‹å…¼å®¹ã€‚ å¤šæ ‡ç­¾ç±»å‹æ›´å…·ä½“ï¼Œä½†ä¸å¤šç±»å¤šè¾“å‡ºç±»å‹å…¼å®¹ã€‚

- target_typestr,One of:

  - â€˜continuousâ€™: y is an array-like of floats that are not all integers, and is 1d or a column vector.

  - â€˜continuous-multioutputâ€™: y is a 2d array of floats that are not all integers, and both dimensions are of size > 1.

  - â€˜binaryâ€™: y contains <= 2 discrete values and is 1d or a column vector.

  - â€˜multiclassâ€™: y contains more than two discrete values, is not a sequence of sequences, and is 1d or a column vector.

  - â€˜multiclass-multioutputâ€™: y is a 2d array that contains more than two discrete values, is not a sequence of sequences, and both dimensions are of size > 1.

  - â€˜multilabel-indicatorâ€™: y is a label indicator matrix, an array of two dimensions with at least two columns, and at most 2 unique values.

  - â€˜unknownâ€™: y is array-like but none of the above, such as a 3d array, sequence of sequences, or an array of non-sequence objects.

- target_typestræ˜¯ç”¨äºæè¿°ç›®æ ‡æ•°æ®ç±»å‹çš„å­—ç¬¦ä¸²ï¼ŒåŒ…æ‹¬ä»¥ä¸‹ä¸ƒç§ç±»å‹ï¼š

  â€˜continuousâ€™ï¼šyæ˜¯ä¸€ä¸ªæµ®ç‚¹æ•°æ•°ç»„ï¼Œä¸å…¨æ˜¯æ•´æ•°ï¼Œå¯ä»¥æ˜¯1ç»´æ•°ç»„æˆ–åˆ—å‘é‡ã€‚

  â€˜continuous-multioutputâ€™ï¼šY æ˜¯ä¸€ä¸ª2d æµ®ç‚¹æ•°ç»„ï¼Œå®ƒä¸å…¨æ˜¯æ•´æ•°ï¼Œè€Œä¸”ä¸¤ä¸ªç»´åº¦çš„å¤§å°éƒ½å¤§äº1

  â€˜binaryâ€™ï¼šyåŒ…å«<=2ä¸ªç¦»æ•£å€¼ï¼Œå¯ä»¥æ˜¯1ç»´æ•°ç»„æˆ–åˆ—å‘é‡ã€‚

  â€˜multiclassâ€™ï¼šyåŒ…å«å¤šäºä¸¤ä¸ªç¦»æ•£å€¼ï¼Œä¸æ˜¯ä¸€ä¸ªåºåˆ—çš„åºåˆ—ï¼Œå¯ä»¥æ˜¯1ç»´æ•°ç»„æˆ–åˆ—å‘é‡ã€‚

  â€˜multiclass-multioutputâ€™ï¼šyæ˜¯ä¸€ä¸ªå¤§å°å¤§äº1çš„2ç»´æ•°ç»„ï¼ŒåŒ…å«å¤šäºä¸¤ä¸ªç¦»æ•£å€¼ï¼Œä¸æ˜¯ä¸€ä¸ªåºåˆ—çš„åºåˆ—ã€‚

  â€˜multilabel-indicatorâ€™ï¼šyæ˜¯ä¸€ä¸ªæ ‡ç­¾æŒ‡ç¤ºçŸ©é˜µï¼Œä¸€ä¸ªå¤§å°ä¸º2çš„äºŒç»´æ•°ç»„ï¼Œå…¶ä¸­è‡³å°‘æœ‰ä¸¤åˆ—ï¼Œæœ€å¤šæœ‰ä¸¤ä¸ªå”¯ä¸€å€¼ã€‚

  â€˜unknownâ€™ï¼šyæ˜¯ç±»æ•°ç»„çš„æ•°æ®ç±»å‹ï¼Œä½†ä¸å±äºä¸Šè¿°ä»»ä½•ä¸€ç§ç±»å‹ï¼Œä¾‹å¦‚3ç»´æ•°ç»„ã€åºåˆ—çš„åºåˆ—æˆ–éåºåˆ—å¯¹è±¡çš„æ•°ç»„ã€‚

#### demos

##### multiclass-multioutput

- ```python
  type_of_target(np.array([[1, 2], [3, 1]]))
  ```

  

##### continuous-multioutput

- ```python
  type_of_target(np.array([[1.5, 2.0], [3.0, 1.6]]))
  ```

##### mulitlabel-indicator vs multiclass-multioutput

- 

  ```python
  def unique_matrix(rng=10,u=2,m=3,n=4):
      """ 
      #è°ƒæ•´unique valueæ¥æ§åˆ¶target_type
      #å¦‚æœunique<=2,åˆ™ç»“æœæ˜¯multilabel-indicator
      #å¦‚æœunique>2,åˆ™ç»“æœæ˜¯multilabel-multioutput
      #m,néšä¾¿è°ƒ,åªè¦ä¿è¯éƒ½å¤§äº0å³å¯
      examples:
      --------
      >>>unique_matrix()
      @u=3,m=3,n=4
      array([[6, 8, 6, 2],
          [8, 6, 8, 8],
          [6, 6, 8, 2]])
    
      """
      l=range(rng) 
      c=np.random.choice(l,u,replace=False)
      print(f"@{u=},{m=},{n=}")
      M=np.random.choice(c,size=(m,n))
      print(M,'@{M2}')
      print(type_of_target(M),"@{type_of_target(M)}")
  
      return M
  ```

  - ```bash
    unique_matrix()
    unique_matrix(u=3,m=6)
    ```

    

- ```bash
  @u=2,m=3,n=4
  [[8 8 9 8]
   [9 9 9 8]
   [9 9 8 8]] @{M2}
  multilabel-indicator @{type_of_target(M)}
  @u=3,m=6,n=4
  [[0 1 1 3]
   [1 0 0 1]
   [3 1 3 1]
   [3 3 0 3]
   [0 1 1 1]
   [1 1 0 1]] @{M2}
  multiclass-multioutput @{type_of_target(M)}
  ```

  

### æ•°é‡åè¯

#### n_features

The number of features.

#### n_outputs

The number of outputs in the target.

#### n_samples

The number of samples.

#### n_targets

Synonym for n_outputs.

### binary

A classification problem consisting of two classes. A binary target may be represented as for a [multiclass](https://scikit-learn.org/stable/glossary.html#term-multiclass) problem but with only two labels. A binary decision function is represented as a 1d array.

Semantically, one class is often considered the â€œpositiveâ€ class. Unless otherwise specified (e.g. using [pos_label](https://scikit-learn.org/stable/glossary.html#term-pos_label) in [evaluation metrics](https://scikit-learn.org/stable/glossary.html#term-evaluation-metrics)), we consider the class label with the greater value (numerically or lexicographically) as the positive class: of labels [0, 1], 1 is the positive class; of [1, 2], 2 is the positive class; of [â€˜noâ€™, â€˜yesâ€™], â€˜yesâ€™ is the positive class; of [â€˜noâ€™, â€˜YESâ€™], â€˜noâ€™ is the positive class. This affects the output of [decision_function](https://scikit-learn.org/stable/glossary.html#term-decision_function), for instance.

Note that a dataset sampled from a multiclass `y` or a continuous `y` may appear to be binary.

[`type_of_target`](https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target) will return â€˜binaryâ€™ for binary input, or a similar array with only a single class present.

- äºŒå…ƒåˆ†ç±»é—®é¢˜ç”±ä¸¤ä¸ªç±»åˆ«ç»„æˆã€‚ä¸€ä¸ªäºŒå…ƒç›®æ ‡å¯ä»¥è¡¨ç¤ºä¸ºå¤šç±»é—®é¢˜ï¼Œä½†åªæœ‰ä¸¤ä¸ªæ ‡ç­¾ã€‚äºŒå…ƒå†³ç­–å‡½æ•°è¡¨ç¤ºä¸º1ç»´æ•°ç»„ã€‚
- ä»è¯­ä¹‰ä¸Šè®²ï¼Œé€šå¸¸å°†ä¸€ä¸ªç±»åˆ«è§†ä¸ºâ€œæ­£ç±»â€ã€‚
  - é™¤éå¦æœ‰è¯´æ˜ï¼ˆä¾‹å¦‚åœ¨è¯„ä¼°æŒ‡æ ‡ä¸­ä½¿ç”¨pos_labelï¼‰ï¼Œå¦åˆ™æˆ‘ä»¬è®¤ä¸ºå…·æœ‰æ›´å¤§å€¼ï¼ˆæŒ‰æ•°å­—æˆ–å­—å…¸é¡ºåºï¼‰çš„ç±»æ ‡ç­¾æ˜¯æ­£ç±»ï¼š
  - åœ¨æ ‡ç­¾[0ï¼Œ1]ä¸­ï¼Œ1æ˜¯æ­£ç±»ï¼›åœ¨[1ï¼Œ2]ä¸­ï¼Œ2æ˜¯æ­£ç±»ï¼›
  - åœ¨[â€œnoâ€ï¼Œâ€œyesâ€]ä¸­ï¼Œâ€œyesâ€æ˜¯æ­£ç±»ï¼›
  - åœ¨[â€œnoâ€ï¼Œâ€œYESâ€]ä¸­ï¼Œâ€œnoâ€æ˜¯æ­£ç±»ã€‚
  - è¿™ä¼šå½±å“decision_functionçš„è¾“å‡º,ä¾‹å¦‚è¯´ã€‚
- è¯·æ³¨æ„ï¼Œä»å¤šç±»yæˆ–è¿ç»­yä¸­æŠ½æ ·çš„æ•°æ®é›†å¯èƒ½çœ‹èµ·æ¥æ˜¯äºŒå…ƒçš„ã€‚
- type_of_targetå°†è¿”å›â€œbinaryâ€ç”¨äºäºŒå…ƒè¾“å…¥ï¼Œæˆ–ç±»ä¼¼çš„æ•°ç»„ä»…åŒ…å«ä¸€ä¸ªç±»åˆ«ã€‚

### multi-output multi-class

- A classification problem where each sampleâ€™s target consists of `n_outputs` [outputs](https://scikit-learn.org/stable/glossary.html#term-outputs), each a class label, for a fixed int n_outputs > 1 in a particular dataset. 

- Each **output** has a fixed set of available **classes**, and each sample is labeled with a **class** for each output. 

- An **output** may be binary or multiclass, and in the case where all outputs are binary, the target is [multilabel](https://scikit-learn.org/stable/glossary.html#term-multilabel).

- Multiclass multioutput targets are represented as multiple [multiclass](https://scikit-learn.org/stable/glossary.html#term-multiclass) targets, horizontally stacked into an array of shape (n_samples, n_outputs).

  XXX: For simplicity, we may not always support string class labels for multiclass multioutput, and integer class labels should be used.

  multioutput provides estimators which estimate multi-output problems using multiple single-output estimators. This may not fully account for dependencies among the different outputs, which methods natively handling the multioutput case (e.g. decision trees, nearest neighbors, neural networks) may do better.

  [**type_of_target**](https://scikit-learn.org/stable/modules/generated/sklearn.utils.multiclass.type_of_target.html#sklearn.utils.multiclass.type_of_target) will return â€˜multiclass-multioutputâ€™ for multiclass multioutput input.

- ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œå…¶ä¸­æ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾éƒ½ç”±n_outputsä¸ªè¾“å‡ºç»„æˆï¼Œæ¯ä¸ªè¾“å‡ºæ˜¯ä¸€ä¸ªæ ‡ç­¾ç±»åˆ«ï¼Œä¸ç‰¹å®šæ•°æ®é›†ä¸­çš„å›ºå®šçš„ã€æ•´æ•°å‹çš„ã€å¤§äº1çš„n_outputsç›¸å¯¹åº”ã€‚

- æ¯ä¸ªè¾“å‡ºéƒ½æœ‰ä¸€ç»„å›ºå®šçš„å¯ç”¨ç±»ï¼Œæ¯ä¸ªæ ·æœ¬åœ¨æ¯ä¸ªè¾“å‡ºä¸‹éƒ½æ ‡è®°æœ‰ä¸€ä¸ªç±»ã€‚

- è¾“å‡ºå¯ä»¥æ˜¯äºŒåˆ†ç±»æˆ–å¤šåˆ†ç±»çš„ï¼Œå¹¶ä¸”åœ¨æ‰€æœ‰è¾“å‡ºéƒ½æ˜¯äºŒåˆ†ç±»çš„æƒ…å†µä¸‹ï¼Œç›®æ ‡æ˜¯å¤šæ ‡ç­¾çš„ã€‚(å¤šè¾“å‡ºé—®é¢˜é€€åŒ–ä¸ºå¤šæ ‡ç­¾é—®é¢˜)

-  å¤šåˆ†ç±»å¤šè¾“å‡ºçš„æ ‡ç­¾è¢«è¡¨ç¤ºä¸ºå¤šä¸ªåˆ†ç±»å‹ç›®æ ‡ï¼Œå®ƒä»¬å¯ä»¥è¢«æ°´å¹³å †å æˆï¼ˆn_samplesï¼Œn_outputsï¼‰å½¢çŠ¶çš„æ•°ç»„ã€‚ ä¸ºç®€å•èµ·è§ï¼Œæˆ‘ä»¬åœ¨å¤šåˆ†ç±»å¤šè¾“å‡ºé—®é¢˜ä¸­å¯èƒ½å¹¶ä¸æ€»æ˜¯æ”¯æŒå­—ç¬¦ä¸²ç±»æ ‡ç­¾ï¼Œåº”è¯¥ä½¿ç”¨æ•´æ•°ç±»æ ‡ç­¾ã€‚

- multioutputæä¾›äº†ä½¿ç”¨å¤šä¸ªå•è¾“å‡ºä¼°ç®—å™¨æ¥ä¼°è®¡å¤šè¾“å‡ºé—®é¢˜çš„ä¼°ç®—å™¨ã€‚è¿™å¯èƒ½æ— æ³•å®Œå…¨è¯´æ˜ä¸åŒè¾“å‡ºä¹‹é—´çš„ä¾èµ–å…³ç³»ï¼Œé‚£äº›æœ¬æ¥å°±èƒ½å¤Ÿå¤„ç†å¤šè¾“å‡ºæƒ…å†µçš„ç®—æ³•ï¼ˆä¾‹å¦‚å†³ç­–æ ‘ï¼Œæœ€è¿‘é‚»ç®—æ³•ï¼Œç¥ç»ç½‘ç»œç­‰ï¼‰å¯èƒ½ä¼šåšå¾—æ›´å¥½ã€‚

- æŒ‰æˆ‘çš„ç†è§£æ˜¯è¿™æ ·çš„,ä¾‹å¦‚,æˆ‘ä»¬å¯¹ä¸€æ‰¹å­¦ä¹ èµ„æ–™è¿›è¡Œåˆ†ç±»

- | ç§‘ç›®(subject) | é€‚ç”¨é˜¶æ®µ(stage)    | åª’ä»‹(medium) |
  | ------------- | ------------------ | ------------ |
  | math          | Elementary school  | ebook        |
  | Chinese       | Junior high school | pbook        |
  | english       | High school        |              |
  |               | University         |              |

  - n_outputs=3,3ä¸ªoutputå˜é‡åˆ†åˆ«æ˜¯subject,stage,medium
  - è¿™3ä¸ªoutputæ„æˆä¸€ä¸ªtargetå‘é‡
  - multi-outputæŒ‡çš„æ˜¯n_outputs=3>1
  - multi-classæŒ‡çš„æ˜¯
    - è®°å„ä¸ªoutputçš„å¯èƒ½å–çš„ç¦»æ•£å€¼ä¸ªæ•°ä¸º$n_i$
    - åˆ™$max(n_1,n_2,n_3)\geqslant{2}$

### multi-label

- A multiclass multioutput target where each output is binary. This may be represented as a 2d (dense) array or sparse matrix of integers, such that each column is a separate binary target, where positive labels are indicated with 1 and negative labels are usually -1 or 0. Sparse multilabel targets are not supported everywhere that dense multilabel targets are supported.
- **Semantically**, a multilabel target can be thought of as a set of labels for each sample. While not used internally, preprocessing.MultiLabelBinarizer is provided as a utility to convert from a list of sets representation to a 2d array or sparse matrix. One-hot encoding a multiclass target with preprocessing.LabelBinarizer turns it into a multilabel problem.

- type_of_target will return â€˜multilabel-indicatorâ€™ for multilabel input, whether sparse or dense.

- å¤šæ ‡ç­¾åˆ†ç±»ï¼ˆmulti-label classificationï¼‰æ˜¯ä¸€ç§ç‰¹æ®Šçš„å¤šè¾“å‡ºå¤šç±»åˆ†ç±»ï¼ˆmulticlass multioutputï¼‰é—®é¢˜ï¼Œå…¶ä¸­æ¯ä¸ªè¾“å‡ºéƒ½æ˜¯äºŒå…ƒçš„ã€‚å¤šæ ‡ç­¾åˆ†ç±»å¯ä»¥ä½¿ç”¨ä¸€ä¸ªäºŒç»´æ•°ç»„æˆ–è€…ç¨€ç–çŸ©é˜µæ¥è¡¨ç¤ºï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºä¸€ä¸ªä¸åŒçš„äºŒå…ƒç›®æ ‡ï¼Œå…¶ä¸­æ­£ç±»æ ‡ç­¾ç”¨1è¡¨ç¤ºï¼Œè´Ÿç±»æ ‡ç­¾é€šå¸¸ç”¨-1æˆ–0è¡¨ç¤ºã€‚ç¨€ç–å¤šæ ‡ç­¾ç›®æ ‡å¹¶ä¸æ˜¯åœ¨æ‰€æœ‰æ”¯æŒå¯†é›†å¤šæ ‡ç­¾ç›®æ ‡çš„åœ°æ–¹éƒ½è¢«æ”¯æŒã€‚

- ä»è¯­ä¹‰ä¸Šè®²ï¼Œå¤šæ ‡ç­¾ç›®æ ‡å¯ä»¥è¢«è§†ä¸ºæ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾é›†åˆã€‚è™½ç„¶åœ¨å†…éƒ¨æ²¡æœ‰è¢«ä½¿ç”¨ï¼Œä½†æ˜¯å¯ä»¥ä½¿ç”¨preprocessing.MultiLabelBinarizerå°†å¤šæ ‡ç­¾ç›®æ ‡ä»åˆ—è¡¨é›†åˆçš„è¡¨ç¤ºæ–¹å¼è½¬æ¢ä¸ºäºŒç»´æ•°ç»„æˆ–ç¨€ç–çŸ©é˜µã€‚ä½¿ç”¨preprocessing.LabelBinarizerå¯¹å¤šç±»åˆ«ç›®æ ‡è¿›è¡Œone-hotç¼–ç å¯ä»¥å°†å…¶è½¬æ¢ä¸ºå¤šæ ‡ç­¾é—®é¢˜ã€‚

- å¯¹äºå¤šæ ‡ç­¾è¾“å…¥ï¼Œtype_of_targetå‡½æ•°å°†è¿”å›'multilabel-indicator'ã€‚




### multi-output

- A target where each sample has multiple classification/regression labels. See multiclass multioutput and continuous multioutput. We do not currently support modelling mixed classification and regression targets.
  - multi-outputä¸­çš„outputæŒ‡çš„å°±æ˜¯åŒ…å«å¤šä¸ªæ ‡ç­¾çš„targetçš„åˆ†é‡
- å¤šè¾“å‡ºï¼ˆmulti-outputï¼‰æ˜¯æŒ‡æ¯ä¸ªæ ·æœ¬å…·æœ‰å¤šä¸ªåˆ†ç±»/å›å½’æ ‡ç­¾çš„ç›®æ ‡æ•°æ®(target)ã€‚ä¸å¤šç±»åˆ«å¤šè¾“å‡ºï¼ˆmulticlass multioutputï¼‰å’Œè¿ç»­å¤šè¾“å‡ºï¼ˆcontinuous multioutputï¼‰ç±»ä¼¼ã€‚

### å¤šæ ‡ç­¾@å¤šç±»åˆ«@å¤šè¾“å‡ºçš„ä¾‹å­

å¤šæ ‡ç­¾ï¼ˆMultilabelï¼‰ã€å¤šç±»åˆ«ï¼ˆMulticlassï¼‰å’Œå¤šè¾“å‡ºï¼ˆMultioutputï¼‰åˆ†ç±»æ˜¯æœºå™¨å­¦ä¹ ä¸­çš„ä¸‰ç§ä¸åŒåˆ†ç±»é—®é¢˜ã€‚è®©æˆ‘ä»¬åˆ†åˆ«äº†è§£å®ƒä»¬ä¹‹é—´çš„å…³ç³»å’ŒåŒºåˆ«ï¼Œå¹¶ç»™å‡ºä¸€äº›ä¾‹å­ã€‚

- **å¤šç±»åˆ«åˆ†ç±» (Multiclass Classification)**

å¤šç±»åˆ«åˆ†ç±»æ˜¯æŒ‡ä¸€ä¸ªæ ·æœ¬åªèƒ½å±äºä¸€ä¸ªç±»åˆ«ã€‚è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„åˆ†ç±»é—®é¢˜ï¼Œæ¯”å¦‚æ‰‹å†™æ•°å­—è¯†åˆ«ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æœ‰10ä¸ªç±»åˆ«ï¼ˆ0åˆ°9ï¼‰ï¼Œä½†ä¸€ä¸ªæ ·æœ¬åªèƒ½å±äºå…¶ä¸­ä¸€ä¸ªç±»åˆ«ã€‚

ä¾‹å­ï¼šé¢„æµ‹å›¾ç‰‡ä¸­çš„åŠ¨ç‰©æ˜¯çŒ«ã€ç‹—è¿˜æ˜¯é¸Ÿã€‚

- **å¤šæ ‡ç­¾åˆ†ç±» (Multilabel Classification)**

å¤šæ ‡ç­¾åˆ†ç±»æ˜¯æŒ‡ä¸€ä¸ªæ ·æœ¬å¯ä»¥å±äºå¤šä¸ªç±»åˆ«ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ¯ä¸ªæ ·æœ¬éƒ½å¯èƒ½æœ‰ä¸æ­¢ä¸€ä¸ªæ ‡ç­¾ã€‚

ä¾‹å­ï¼šç»™ä¸€ç¯‡æ–‡ç« æ‰“æ ‡ç­¾ï¼Œå¯èƒ½çš„æ ‡ç­¾åŒ…æ‹¬ï¼š"ç§‘æŠ€"ã€"æ”¿æ²»"ã€"ç»æµ"ã€"å¨±ä¹"ç­‰ã€‚ä¸€ç¯‡æ–‡ç« å¯èƒ½æ—¢æ¶‰åŠ"ç§‘æŠ€"ï¼Œåˆæ¶‰åŠ"æ”¿æ²»"ï¼Œæ‰€ä»¥å¯ä»¥è¢«åŒæ—¶æ‰“ä¸Šè¿™ä¸¤ä¸ªæ ‡ç­¾ã€‚

- **å¤šè¾“å‡ºåˆ†ç±» (Multioutput Classification)**

å¤šè¾“å‡ºåˆ†ç±»æ˜¯æŒ‡æœ‰å¤šä¸ªè¾“å‡ºå˜é‡ï¼Œæ¯ä¸ªè¾“å‡ºå˜é‡éƒ½æœ‰å¤šä¸ªç±»åˆ«ã€‚è¿™å¯ä»¥çœ‹ä½œæ˜¯å¤šä¸ªå¤šç±»åˆ«åˆ†ç±»é—®é¢˜çš„ç»„åˆã€‚

ä¾‹å­ï¼šé¢„æµ‹ä¸€ä¸ªäººçš„èŒä¸šå’Œæ•™è‚²æ°´å¹³ã€‚åœ¨è¿™ä¸ªé—®é¢˜ä¸­ï¼Œæœ‰ä¸¤ä¸ªè¾“å‡ºå˜é‡ï¼šèŒä¸šï¼ˆå¦‚åŒ»ç”Ÿã€å¾‹å¸ˆã€æ•™å¸ˆç­‰ï¼‰å’Œæ•™è‚²æ°´å¹³ï¼ˆå¦‚é«˜ä¸­ã€å¤§å­¦ã€ç ”ç©¶ç”Ÿç­‰ï¼‰ã€‚æ¯ä¸ªè¾“å‡ºå˜é‡éƒ½æœ‰å¤šä¸ªç±»åˆ«ï¼Œå› æ­¤è¿™æ˜¯ä¸€ä¸ªå¤šè¾“å‡ºåˆ†ç±»é—®é¢˜ã€‚

å…³ç³»ï¼š

- å¤šç±»åˆ«åˆ†ç±»æ˜¯æœ€åŸºæœ¬çš„åˆ†ç±»é—®é¢˜ï¼Œæ¯ä¸ªæ ·æœ¬åªå±äºä¸€ä¸ªç±»åˆ«ã€‚
- å¤šæ ‡ç­¾åˆ†ç±»æ˜¯å¤šç±»åˆ«åˆ†ç±»çš„æ‰©å±•ï¼Œå…è®¸æ¯ä¸ªæ ·æœ¬å±äºå¤šä¸ªç±»åˆ«ã€‚
- å¤šè¾“å‡ºåˆ†ç±»å¯ä»¥çœ‹ä½œæ˜¯å¤šä¸ªå¤šç±»åˆ«åˆ†ç±»é—®é¢˜çš„ç»„åˆï¼Œæ¯ä¸ªè¾“å‡ºå˜é‡éƒ½æ˜¯ä¸€ä¸ªå¤šç±»åˆ«åˆ†ç±»é—®é¢˜ã€‚

ç®€è€Œè¨€ä¹‹ï¼Œå¤šç±»åˆ«åˆ†ç±»å…³æ³¨å•ä¸€æ ‡ç­¾ï¼Œå¤šæ ‡ç­¾åˆ†ç±»å…³æ³¨å¤šä¸ªæ ‡ç­¾ï¼Œè€Œå¤šè¾“å‡ºåˆ†ç±»å…³æ³¨å¤šä¸ªè¾“å‡ºå˜é‡ï¼Œæ¯ä¸ªå˜é‡å¯ä»¥æœ‰å¤šä¸ªç±»åˆ«ã€‚

### label indicator matrix@One-Hot@1-of-kç¼–ç 

- multilabel indicator matrices
  - The format used to represent multilabel data, where each row of a 2d array or sparse matrix corresponds to a sample, each column corresponds to a class, and each element is 1 if the sample is labeled with the class and 0 if not.å¤šæ ‡ç­¾æŒ‡ç¤ºçŸ©é˜µæ˜¯ç”¨äºè¡¨ç¤ºå¤šæ ‡ç­¾æ•°æ®çš„æ ¼å¼ï¼Œå…¶ä¸­2ç»´æ•°ç»„æˆ–ç¨€ç–çŸ©é˜µçš„æ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªæ ·æœ¬ï¼Œæ¯ä¸€åˆ—å¯¹åº”ä¸€ä¸ªç±»åˆ«ï¼Œæ¯ä¸ªå…ƒç´ éƒ½æ˜¯1ï¼Œè¡¨ç¤ºè¯¥æ ·æœ¬å¸¦æœ‰è¯¥ç±»åˆ«çš„æ ‡ç­¾ï¼Œå¦åˆ™ä¸º0

- Label indicatoræ˜¯ä¸€ç§ç”¨äºè¡¨ç¤ºå¤šåˆ†ç±»é—®é¢˜ä¸­æ ‡ç­¾çš„æ–¹æ³•ï¼Œé€šå¸¸åœ¨æœºå™¨å­¦ä¹ ä¸­ä½¿ç”¨ã€‚åœ¨Label indicatorä¸­ï¼Œæ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªå‘é‡ï¼Œå‘é‡çš„é•¿åº¦ç­‰äºç±»åˆ«æ•°ï¼Œæ¯ä¸ªå…ƒç´ è¡¨ç¤ºè¯¥æ ·æœ¬æ˜¯å¦å±äºè¯¥ç±»åˆ«ã€‚

- å¦‚æœä¸€ä¸ªæ ·æœ¬å±äºæŸä¸ªç±»åˆ«ï¼Œåˆ™è¯¥ç±»åˆ«å¯¹åº”çš„å‘é‡å…ƒç´ **å–å€¼ä¸º1ï¼Œå¦åˆ™ä¸º0**ã€‚

- å› æ­¤ï¼ŒLabel indicatorä¹Ÿè¢«ç§°ä¸ºOne-Hotç¼–ç æˆ–One-of-Kç¼–ç ã€‚

- ä¾‹å¦‚

  - åœ¨ä¸€ä¸ª3ç±»åˆ†ç±»é—®é¢˜ä¸­ï¼Œå¦‚æœä¸€ä¸ªæ ·æœ¬å±äºç¬¬2ç±»ï¼Œåˆ™è¯¥æ ·æœ¬çš„Label indicatorä¸º[0, 1, 0]ã€‚å¦‚æœä¸€ä¸ªæ ·æœ¬åŒæ—¶å±äºç¬¬1ç±»å’Œç¬¬3ç±»ï¼Œåˆ™è¯¥æ ·æœ¬çš„Label indicatorä¸º[1, 0, 1]ã€‚

- ä½¿ç”¨Label indicatorçš„å¥½å¤„æ˜¯ï¼Œå¯ä»¥å°†å¤šåˆ†ç±»é—®é¢˜ä¸­çš„æ ‡ç­¾è½¬åŒ–ä¸ºä¸€ä¸ªç®€å•çš„å‘é‡å½¢å¼ï¼Œæ–¹ä¾¿æ¨¡å‹è®­ç»ƒå’Œé¢„æµ‹ã€‚åŒæ—¶ï¼ŒLabel indicatorä¹Ÿå¯ä»¥é¿å…æ ‡ç­¾å€¼ä¹‹é—´çš„å¤§å°å…³ç³»å¯¹æ¨¡å‹å¸¦æ¥çš„å½±å“ï¼Œå› ä¸ºåœ¨Label indicatorä¸­ï¼Œæ¯ä¸ªç±»åˆ«è¢«è§†ä¸ºç‹¬ç«‹çš„äºŒå…ƒå˜é‡ã€‚

- sklearnä¸­çš„`type_of_target`å‡½æ•°å°†è¦æ±‚ç¨å¾®æ”¾å®½,åªè¦æ˜¯åŒ…å«çš„å…ƒç´ åªæœ‰ä¸¤ç§å°±è¡Œ,è€Œä¸è¦æ±‚å¿…é¡»æ˜¯0æˆ–1

  - â€˜multilabel-indicatorâ€™: y is a label indicator matrix, an array of **two dimensions** with **at least two columns**, and <u>at most 2 **unique values**.</u>

  

### å…¶ä»–

äºŒåˆ†ç±»ã€å¤šåˆ†ç±»ã€å•æ ‡ç­¾åˆ†ç±»ã€å¤šæ ‡ç­¾åˆ†ç±»æ˜¯åˆ†ç±»é—®é¢˜çš„ä¸åŒç±»å‹ï¼Œå®ƒä»¬ä¹‹é—´çš„å…³ç³»å¦‚ä¸‹ï¼š

1. äºŒåˆ†ç±»é—®é¢˜Binary classification problemï¼šå°†æ•°æ®åˆ†ä¸ºä¸¤ä¸ªç±»åˆ«ï¼Œé€šå¸¸æ˜¯æ­£ç±»å’Œè´Ÿç±»ã€‚æ¯ä¸ªæ ·æœ¬åªèƒ½å±äºå…¶ä¸­ä¸€ä¸ªç±»åˆ«ï¼Œå› æ­¤æ˜¯å•æ ‡ç­¾åˆ†ç±»é—®é¢˜çš„ä¸€ç§ã€‚
2. å¤šåˆ†ç±»é—®é¢˜Multiclass classification problemï¼šå°†æ•°æ®åˆ†ä¸ºä¸‰ä¸ªæˆ–æ›´å¤šä¸ªç±»åˆ«ã€‚æ¯ä¸ªæ ·æœ¬åªèƒ½å±äºå…¶ä¸­ä¸€ä¸ªç±»åˆ«ï¼Œå› æ­¤æ˜¯å•æ ‡ç­¾åˆ†ç±»é—®é¢˜çš„ä¸€ç§ã€‚
3. å•æ ‡ç­¾åˆ†ç±»é—®é¢˜Single-label classification problemï¼šæ¯ä¸ªæ ·æœ¬åªæœ‰ä¸€ä¸ªæ ‡ç­¾ï¼Œå³åªèƒ½å±äºä¸€ä¸ªç±»åˆ«ã€‚æ—¢å¯ä»¥æ˜¯äºŒåˆ†ç±»é—®é¢˜ï¼Œä¹Ÿå¯ä»¥æ˜¯å¤šåˆ†ç±»é—®é¢˜ã€‚
4. å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜Multilabel classification problemï¼šæ¯ä¸ªæ ·æœ¬å¯ä»¥å±äºå¤šä¸ªç±»åˆ«ï¼Œå› æ­¤éœ€è¦åŒæ—¶é¢„æµ‹å¤šä¸ªæ ‡ç­¾ã€‚å¯ä»¥çœ‹ä½œæ˜¯å¤šä¸ªäºŒåˆ†ç±»é—®é¢˜çš„ç»„åˆï¼Œæ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€ä¸ªäºŒåˆ†ç±»é—®é¢˜ã€‚

## apiæºç æŸ¥çœ‹

- æŸäº›æ—¶å€™,æŸ¥çœ‹æ–‡æ¡£è¿˜æ˜¯ä¸å¤ªæ¸…æ¥šæŸäº›è¡Œä¸º,æœç´¢å¼•æ“ä¹Ÿæœä¸åˆ°æ»¡æ„çš„èµ„æ–™,å°±å¯ä»¥å°è¯•æŸ¥çœ‹æºç äº†
- ä¾‹å¦‚,æˆ‘ä»LabelBinarizerçš„fitæ–¹æ³•çš„å¤„ç†è¿‡ç¨‹é‚£é‡Œé‡åˆ°äº†äº›å›°æƒ‘(å¤„ç†äºŒè¿›åˆ¶çŸ©é˜µçš„æ—¶å€™)
  - æŸ¥çœ‹æºç æ–‡ä»¶,å‘ç°äº†type_of_targetå‡½æ•°,è¿™ä¸ªå‡½æ•°æ˜¯ç”¨æ¥åˆ†æè¾“å…¥çš„å‚æ•°å¯¹åº”çš„åˆ†ç±»é—®é¢˜å…·ä½“æ˜¯å“ªä¸€ç§ç±»å‹çš„

## sklearn processing

- [sklearn.Processing](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.preprocessing)

- `sklearn.preprocessing`æ˜¯Scikit-learnåº“ï¼ˆä¹Ÿç§°ä¸ºsklearnï¼‰ä¸­çš„ä¸€ä¸ªæ¨¡å—ï¼Œæä¾›äº†ä¸€ç³»åˆ—æ•°æ®é¢„å¤„ç†å·¥å…·ï¼Œç”¨äºåœ¨æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒä¹‹å‰å¯¹æ•°æ®è¿›è¡Œå¤„ç†å’Œè½¬æ¢ã€‚è¯¥æ¨¡å—åŒ…å«äº†è®¸å¤šå¸¸ç”¨çš„æ•°æ®é¢„å¤„ç†æ–¹æ³•ï¼Œä¾‹å¦‚æ ‡å‡†åŒ–ã€ç¼©æ”¾ã€äºŒå€¼åŒ–ã€ç¼–ç ã€å¡«å……ç­‰ç­‰ã€‚

  ä»¥ä¸‹æ˜¯sklearn.preprocessingæ¨¡å—ä¸­å¸¸ç”¨çš„ä¸€äº›ç±»å’Œå‡½æ•°ï¼š

  - StandardScalerï¼šç”¨äºå°†æ•°æ®è¿›è¡Œæ ‡å‡†åŒ–å¤„ç†ï¼Œå³å°†æ•°æ®æŒ‰ç…§å‡å€¼ä¸º0ã€æ–¹å·®ä¸º1çš„æ ‡å‡†æ­£æ€åˆ†å¸ƒè¿›è¡Œç¼©æ”¾ã€‚
  - MinMaxScalerï¼šç”¨äºå°†æ•°æ®è¿›è¡Œç¼©æ”¾å¤„ç†ï¼Œå³å°†æ•°æ®ç¼©æ”¾åˆ°æŒ‡å®šçš„èŒƒå›´å†…ï¼Œé€šå¸¸æ˜¯[0, 1]æˆ–[-1, 1]ã€‚
  - MaxAbsScalerï¼šç”¨äºå°†æ•°æ®è¿›è¡Œç¼©æ”¾å¤„ç†ï¼Œå³å°†æ•°æ®ç¼©æ”¾åˆ°[-1, 1]çš„èŒƒå›´å†…ã€‚
  - RobustScalerï¼šç”¨äºå°†æ•°æ®è¿›è¡Œç¼©æ”¾å¤„ç†ï¼Œå¯¹å¼‚å¸¸å€¼å…·æœ‰æ›´å¼ºçš„é²æ£’æ€§ï¼Œé€‚åˆå¤„ç†å­˜åœ¨ç¦»ç¾¤ç‚¹çš„æ•°æ®ã€‚
  - LabelEncoderï¼šç”¨äºå°†æ ‡ç­¾æ•°æ®è¿›è¡Œç¼–ç ï¼Œå°†æ¯ä¸ªç±»åˆ«æ˜ å°„ä¸ºä¸€ä¸ªæ•´æ•°å€¼ã€‚
  - OneHotEncoderï¼šç”¨äºå°†æ ‡ç­¾æ•°æ®è¿›è¡Œç¼–ç ï¼Œå°†æ¯ä¸ªç±»åˆ«æ˜ å°„ä¸ºä¸€ä¸ªäºŒè¿›åˆ¶å‘é‡ã€‚
  - Imputerï¼šç”¨äºå¡«å……ç¼ºå¤±å€¼ï¼Œå¯ä»¥ä½¿ç”¨å‡å€¼ã€ä¸­ä½æ•°ã€ä¼—æ•°ç­‰æ–¹æ³•è¿›è¡Œå¡«å……ã€‚
  - Binarizerï¼šç”¨äºå°†æ•°å€¼å‹æ•°æ®è¿›è¡ŒäºŒå€¼åŒ–å¤„ç†ï¼Œå°†å¤§äºé˜ˆå€¼çš„å€¼è®¾ç½®ä¸º1ï¼Œå°äºç­‰äºé˜ˆå€¼çš„å€¼è®¾ç½®ä¸º0ã€‚

  é™¤äº†ä¸Šè¿°æ–¹æ³•å¤–ï¼Œsklearn.preprocessingæ¨¡å—è¿˜æä¾›äº†è®¸å¤šå…¶ä»–çš„æ•°æ®é¢„å¤„ç†å·¥å…·ï¼Œå¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚è¿›è¡Œé€‰æ‹©å’Œä½¿ç”¨ã€‚è¿™äº›å·¥å…·å¯ä»¥å¸®åŠ©æˆ‘ä»¬åœ¨æœºå™¨å­¦ä¹ æ¨¡å‹è®­ç»ƒä¹‹å‰å¯¹æ•°æ®è¿›è¡Œå¤„ç†å’Œè½¬æ¢ï¼Œæé«˜æ¨¡å‹çš„å‡†ç¡®æ€§å’Œå¯é æ€§ã€‚



### one-vs-all

- "one-vs-all"ï¼ˆä¸€å¯¹å¤šï¼‰æ˜¯ä¸€ç§å¤šç±»åˆ«åˆ†ç±»çš„ç­–ç•¥ã€‚åœ¨è¿™ç§ç­–ç•¥ä¸­ï¼Œå¯¹äºæ¯ä¸ªç±»åˆ«ï¼Œæˆ‘ä»¬å°†å…¶ä¸å…¶ä»–æ‰€æœ‰ç±»åˆ«åˆ†å¼€ï¼Œå½¢æˆä¸€ä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæˆ‘ä»¬è®­ç»ƒä¸€ä¸ªåˆ†ç±»å™¨æ¥åŒºåˆ†å½“å‰ç±»åˆ«å’Œå…¶ä»–æ‰€æœ‰ç±»åˆ«çš„æ ·æœ¬ï¼Œè¿™æ ·å°±å¯ä»¥å¾—åˆ°æ¯ä¸ªç±»åˆ«å¯¹åº”çš„äºŒå…ƒåˆ†ç±»å™¨ã€‚
- åœ¨é¢„æµ‹æ—¶ï¼Œå¯¹äºä¸€ä¸ªæ–°çš„æ ·æœ¬ï¼Œæˆ‘ä»¬åˆ†åˆ«ä½¿ç”¨æ¯ä¸ªäºŒå…ƒåˆ†ç±»å™¨è¿›è¡Œé¢„æµ‹ï¼Œç„¶åé€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„é‚£ä¸ªåˆ†ç±»å™¨å¯¹åº”çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœã€‚è¿™ç§ç­–ç•¥é€šå¸¸è¢«ç”¨äºä¸€äº›äºŒå…ƒåˆ†ç±»å™¨æ— æ³•ç›´æ¥æ‰©å±•åˆ°å¤šç±»åˆ«åˆ†ç±»çš„æƒ…å†µä¸‹ï¼Œä¾‹å¦‚æ”¯æŒå‘é‡æœºç­‰ç®—æ³•ã€‚

### one-vs-restï¼ˆOvRï¼‰@OneVsRestClassifier

- [sklearn.multiclass.OneVsRestClassifier â€” scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.multiclass.OneVsRestClassifier.html)

- OvRæ˜¯ä¸€ç§å¸¸ç”¨çš„å¤šç±»åˆ†ç±»æ–¹æ³•ï¼Œä¹Ÿç§°ä¸ºone-vs-allã€‚å®ƒçš„åŸºæœ¬æ€æƒ³æ˜¯å°†å¤šç±»åˆ†ç±»é—®é¢˜è½¬åŒ–ä¸ºå¤šä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜ï¼Œæ¯ä¸ªé—®é¢˜éƒ½æ˜¯å°†å…¶ä¸­ä¸€ä¸ªç±»åˆ«ä¸å…¶ä»–æ‰€æœ‰ç±»åˆ«åŒºåˆ†å¼€æ¥ã€‚

- å…·ä½“æ¥è¯´ï¼Œå¯¹äºä¸€ä¸ªæœ‰kä¸ªç±»åˆ«çš„å¤šç±»åˆ†ç±»é—®é¢˜ï¼Œone-vs-restæ–¹æ³•å°†å»ºç«‹kä¸ªäºŒå…ƒåˆ†ç±»å™¨ï¼Œæ¯ä¸ªåˆ†ç±»å™¨åˆ†åˆ«å°†å…¶ä¸­ä¸€ä¸ªç±»åˆ«ä½œä¸ºæ­£ä¾‹ï¼Œå…¶ä»–æ‰€æœ‰ç±»åˆ«ä½œä¸ºè´Ÿä¾‹ã€‚åœ¨é¢„æµ‹æ—¶ï¼Œå°†æ¯ä¸ªåˆ†ç±»å™¨çš„æ¦‚ç‡è¾“å‡ºè¿›è¡Œæ¯”è¾ƒï¼Œå°†æ¦‚ç‡æœ€é«˜çš„ç±»åˆ«ä½œä¸ºé¢„æµ‹ç»“æœã€‚

- one-vs-restæ–¹æ³•çš„ä¼˜ç‚¹æ˜¯ç®€å•ã€æ˜“äºå®ç°ï¼Œå¹¶ä¸”å¯ä»¥ä½¿ç”¨ä»»ä½•äºŒå…ƒåˆ†ç±»å™¨ä½œä¸ºåŸºåˆ†ç±»å™¨ã€‚ä½†æ˜¯ï¼Œå®ƒä¹Ÿå­˜åœ¨ä¸€äº›ç¼ºç‚¹ï¼Œä¾‹å¦‚å½“å„ä¸ªç±»åˆ«ä¹‹é—´å­˜åœ¨è¾ƒå¤§é‡å æ—¶ï¼Œä¼šå‡ºç°é¢„æµ‹ä¸å‡†ç¡®çš„æƒ…å†µã€‚

- åœ¨scikit-learnä¸­ï¼Œone-vs-restæ–¹æ³•è¢«å¹¿æ³›åº”ç”¨äºå¤šç±»åˆ†ç±»é—®é¢˜ï¼Œä¾‹å¦‚åœ¨LogisticRegressionã€SVMã€DecisionTreeç­‰ç®—æ³•ä¸­ã€‚åŒæ—¶ï¼Œscikit-learnè¿˜æä¾›äº†å…¶ä»–ä¸€äº›å¤šç±»åˆ†ç±»æ–¹æ³•ï¼Œä¾‹å¦‚one-vs-oneã€Error-Correcting Output Codesç­‰ï¼Œå¯ä»¥æ ¹æ®å…·ä½“é—®é¢˜é€‰æ‹©æœ€é€‚åˆçš„æ–¹æ³•ã€‚

- Also known as one-vs-all, this strategy consists in fitting one **classifier** per **class**. For each classifier, the class is fitted against all the other classes. In addition to its computational efficiency (only `n_classes` classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and one classifier only, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy for **multiclass** classification and is a fair default choice.

  OneVsRestClassifier can also be used for **multilabel** classification. To use this feature, provide an indicator matrix for the target y when calling .fit. In other words, the target labels should be formatted as a 2D binary (0/1) matrix, where [i, j] == 1 indicates the presence of label j in sample i. This estimator uses the binary relevance method to perform multilabel classification, which involves training one binary classifier independently for each label.

  ä¹Ÿè¢«ç§°ä¸ºä¸€å¯¹å¤šç­–ç•¥ï¼Œè¯¥ç­–ç•¥åŒ…æ‹¬ä¸ºæ¯ä¸ªç±»åˆ«æ‹Ÿåˆä¸€ä¸ªåˆ†ç±»å™¨ã€‚å¯¹äºæ¯ä¸ªåˆ†ç±»å™¨ï¼Œè¯¥ç±»åˆ«ä¸æ‰€æœ‰å…¶ä»–ç±»åˆ«è¿›è¡Œæ‹Ÿåˆã€‚é™¤äº†å…¶è®¡ç®—æ•ˆç‡ï¼ˆåªéœ€è¦n_classesä¸ªåˆ†ç±»å™¨ï¼‰ï¼Œæ­¤æ–¹æ³•çš„ä¸€ä¸ªä¼˜ç‚¹æ˜¯å…¶å¯è§£é‡Šæ€§ã€‚ç”±äºæ¯ä¸ªç±»åˆ«ä»…ç”±ä¸€ä¸ªåˆ†ç±»å™¨è¡¨ç¤ºï¼Œå› æ­¤å¯ä»¥é€šè¿‡æ£€æŸ¥å…¶ç›¸åº”çš„åˆ†ç±»å™¨æ¥è·å¾—å…³äºç±»åˆ«çš„çŸ¥è¯†ã€‚è¿™æ˜¯ç”¨äºå¤šç±»åˆ†ç±»çš„æœ€å¸¸ç”¨ç­–ç•¥ï¼Œä¹Ÿæ˜¯ä¸€ä¸ªå…¬å¹³çš„é»˜è®¤é€‰æ‹©ã€‚

  OneVsRestClassifierä¹Ÿå¯ä»¥ç”¨äºå¤šæ ‡ç­¾åˆ†ç±»ã€‚è¦ä½¿ç”¨æ­¤åŠŸèƒ½ï¼Œè¯·åœ¨è°ƒç”¨.fitæ—¶ä¸ºç›®æ ‡yæä¾›ä¸€ä¸ªæŒ‡ç¤ºå™¨çŸ©é˜µã€‚æ¢å¥è¯è¯´ï¼Œç›®æ ‡æ ‡ç­¾åº”æ ¼å¼åŒ–ä¸ºäºŒç»´äºŒè¿›åˆ¶ï¼ˆ0/1ï¼‰çŸ©é˜µï¼Œå…¶ä¸­[iï¼Œj]== 1è¡¨ç¤ºæ ·æœ¬iä¸­å­˜åœ¨æ ‡ç­¾jã€‚è¯¥ä¼°è®¡å™¨ä½¿ç”¨äºŒå…ƒå…³è”æ–¹æ³•æ‰§è¡Œå¤šæ ‡ç­¾åˆ†ç±»ï¼Œè¿™æ¶‰åŠç‹¬ç«‹åœ°ä¸ºæ¯ä¸ªæ ‡ç­¾è®­ç»ƒä¸€ä¸ªäºŒå…ƒåˆ†ç±»å™¨ã€‚

#### eg 

ä»¥ä¸‹æ˜¯ä¸€ä¸ªéä»£ç çš„ä¾‹å­ï¼Œè¯´æ˜å¦‚ä½•ä½¿ç”¨one-vs-restæ–¹æ³•å®ç°å¤šç±»åˆ†ç±»ï¼š

- å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ªæ–‡æœ¬åˆ†ç±»çš„é—®é¢˜ï¼Œéœ€è¦å°†æ–‡æœ¬åˆ†ä¸ºä¸‰ä¸ªç±»åˆ«ï¼šä½“è‚²ã€æ”¿æ²»å’Œç§‘æŠ€ã€‚æˆ‘ä»¬å¯ä»¥ä½¿ç”¨one-vs-restæ–¹æ³•æ¥è§£å†³è¿™ä¸ªé—®é¢˜ã€‚
- é¦–å…ˆï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶ä½¿ç”¨è®­ç»ƒé›†æ¥è®­ç»ƒ3ä¸ªäºŒå…ƒåˆ†ç±»å™¨
  - 3ä¸ªäºŒå…ƒåˆ†ç±»å™¨(åŸºæœ¬åˆ†ç±»å™¨)åˆ†åˆ«å°†ä½“è‚²ã€æ”¿æ²»å’Œç§‘æŠ€ä½œä¸ºæ­£ä¾‹ï¼Œå…¶ä»–ç±»åˆ«ä½œä¸ºè´Ÿä¾‹ã€‚
  - æ›´ç®€å•åœ°è¯´,æœ‰`a,b,c`ä¸‰ä¸ªç±»åˆ«,æ„å»ºçš„ä¸‰ä¸ªäºŒå…ƒåˆ†ç±»å™¨è®°ä¸º`c1,c2,c3`,å…¶ä¸­`c1,c2,c3`åˆ†åˆ«ç”¨æ¥åŒºåˆ†`aå’Œéa`,`bå’Œéb`,`cå’Œéc`
  - æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¾‹å¦‚é€»è¾‘å›å½’ä½œä¸ºåŸºåˆ†ç±»å™¨ã€‚
- ç„¶åï¼Œåœ¨é¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬å°†**æ¯ä¸ªåˆ†ç±»å™¨çš„æ¦‚ç‡è¾“å‡ºè¿›è¡Œæ¯”è¾ƒ**ï¼Œé€‰æ‹©æ¦‚ç‡æœ€é«˜çš„åˆ†ç±»å™¨ä½œä¸ºé¢„æµ‹ç»“æœã€‚
  - ä¾‹å¦‚ï¼Œå¦‚æœåˆ†ç±»å™¨1é¢„æµ‹æ¦‚ç‡æœ€é«˜ï¼Œåˆ™å°†æ–‡æœ¬åˆ†ç±»ä¸ºä½“è‚²ï¼›å¦‚æœåˆ†ç±»å™¨2é¢„æµ‹æ¦‚ç‡æœ€é«˜ï¼Œåˆ™å°†æ–‡æœ¬åˆ†ç±»ä¸ºæ”¿æ²»ï¼›å¦‚æœåˆ†ç±»å™¨3é¢„æµ‹æ¦‚ç‡æœ€é«˜ï¼Œåˆ™å°†æ–‡æœ¬åˆ†ç±»ä¸ºç§‘æŠ€ã€‚
- éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨ä½¿ç”¨one-vs-restæ–¹æ³•æ—¶ï¼Œæ¯ä¸ªåˆ†ç±»å™¨éƒ½æ˜¯ç‹¬ç«‹çš„ï¼Œå› æ­¤å®ƒä»¬ä¹‹é—´çš„å†³ç­–è¾¹ç•Œå¯èƒ½å­˜åœ¨é‡å ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€äº›æ–¹æ³•ï¼Œä¾‹å¦‚è°ƒæ•´åˆ†ç±»å™¨çš„é˜ˆå€¼ã€ä½¿ç”¨æ›´å¤æ‚çš„åŸºåˆ†ç±»å™¨ã€ä½¿ç”¨é›†æˆå­¦ä¹ æ–¹æ³•ç­‰ï¼Œæ¥æé«˜åˆ†ç±»å™¨çš„æ€§èƒ½å’Œé²æ£’æ€§ã€‚

#### eg

- ```python
  import numpy as np
  from sklearn.multiclass import OneVsRestClassifier
  from sklearn.svm import SVC
  X = np.array([
      [10, 10],
      [8, 10],
      [-5, 5.5],
      [-5.4, 5.5],
      [-20, -20],
      [-15, -20]
  ])
  y = np.array([0, 0, 1, 1, 2, 2])
  print(y,"@{y}")
  clf = OneVsRestClassifier(SVC()).fit(X, y)
  clf.predict([[-19, -20], [9, 9], [-5, 5]])
  
  ```

  - ```bash
    [0 0 1 1 2 2] @{y}
    array([2, 0, 1])
    ```

    

  - ä½¿ç”¨äº† `OneVsRestClassifier` ç±»ï¼Œæ„å»ºäº†ä¸€ä¸ªå¤šåˆ†ç±»æ¨¡å‹ï¼Œå¹¶ä½¿ç”¨ `fit` æ–¹æ³•å¯¹è®­ç»ƒæ•°æ®è¿›è¡Œæ‹Ÿåˆã€‚å…¶ä¸­ï¼š

    - `SVC()` åˆ›å»ºä¸€ä¸ªæ”¯æŒå‘é‡æœºåˆ†ç±»å™¨å¯¹è±¡ã€‚
    - `OneVsRestClassifier(SVC())` å°†æ”¯æŒå‘é‡æœºåˆ†ç±»å™¨åŒ…è£…ä¸ºä¸€ä¸ªå¤šåˆ†ç±»æ¨¡å‹å¯¹è±¡ã€‚
    - `fit(X, y)` ä½¿ç”¨è®­ç»ƒæ•°æ® `X` å’Œæ ‡ç­¾ `y` å¯¹å¤šåˆ†ç±»æ¨¡å‹è¿›è¡Œæ‹Ÿåˆã€‚

## ç‰¹å¾äºŒå…ƒåŒ–(ç‹¬çƒ­ç¼–ç )

### OneHotEncoder

- [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html#sklearn.preprocessing.OneHotEncoder)

- Specifies a methodology to use to drop one of the categories per feature. This is useful in situations where perfectly collinear features cause problems, such as when feeding the resulting data into an unregularized linear regression model. ä½¿ç”¨ä¸€ç§æ–¹æ³•æ¥åˆ é™¤æ¯ä¸ªç‰¹å¾ä¸­çš„ä¸€ä¸ªç±»åˆ«ã€‚è¿™åœ¨å­˜åœ¨å®Œå…¨å…±çº¿ç‰¹å¾å¯¼è‡´é—®é¢˜çš„æƒ…å†µä¸‹éå¸¸æœ‰ç”¨ï¼Œä¾‹å¦‚å°†ç»“æœæ•°æ®è¾“å…¥åˆ°éæ­£åˆ™åŒ–çº¿æ€§å›å½’æ¨¡å‹ä¸­ã€‚ ç®€è€Œè¨€ä¹‹ï¼Œè¿™ç§æŠ€æœ¯å¯ä»¥ç”¨æ¥è§£å†³ç‰¹å¾ä¹‹é—´å­˜åœ¨é«˜åº¦ç›¸å…³æ€§ï¼ˆå…±çº¿æ€§ï¼‰å¯¼è‡´çš„é—®é¢˜ã€‚åœ¨æŸäº›æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ï¼Œè¿™ç§é—®é¢˜å¯èƒ½ä¼šå¯¼è‡´æ¨¡å‹è¿‡æ‹Ÿåˆæˆ–è€…æ€§èƒ½ä¸‹é™ã€‚é€šè¿‡åˆ é™¤æ¯ä¸ªç‰¹å¾ä¸­çš„ä¸€ä¸ªç±»åˆ«ï¼Œå¯ä»¥å‡å°‘å…±çº¿æ€§ï¼Œä»è€Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä½¿ç»“æœæ›´æ˜“äºè§£é‡Šã€‚

- åœ¨æœºå™¨å­¦ä¹ å’Œæ•°æ®åˆ†æä¸­ï¼Œé€šå¸¸éœ€è¦å¯¹æ•°æ®è¿›è¡Œé¢„å¤„ç†å’Œè½¬æ¢ï¼Œä»¥ä½¿å…¶é€‚ç”¨äºç‰¹å®šçš„ç®—æ³•æˆ–ä»»åŠ¡ã€‚å…¶ä¸­ä¸€ä¸ªå¸¸è§çš„é¢„å¤„ç†æ­¥éª¤æ˜¯å°†ç±»åˆ«æ•°æ®ç¼–ç ä¸ºæ•°å€¼å½¢å¼ï¼Œä»¥ä¾¿äºè®¡ç®—æœºå¤„ç†ã€‚

  ä¸ºäº†å°†ç±»åˆ«æ•°æ®ç¼–ç ä¸ºæ•°å€¼å½¢å¼ï¼Œéœ€è¦ç¡®å®šæ¯ä¸ªç‰¹å¾çš„ç±»åˆ«ï¼Œå³å°†æ¯ä¸ªç±»åˆ«æ˜ å°„åˆ°å”¯ä¸€çš„æ•°å€¼ã€‚è¿™é€šå¸¸éœ€è¦ä½¿ç”¨è®­ç»ƒæ•°æ®é›†ä¸­çš„æ ·æœ¬æ¥ç¡®å®šç±»åˆ«ï¼Œç„¶åå°†è¯¥æ˜ å°„åº”ç”¨äºæ•´ä¸ªæ•°æ®é›†ã€‚

- ä¾‹å¦‚ï¼Œå¦‚æœæœ‰ä¸€ä¸ªç‰¹å¾è¡¨ç¤ºé¢œè‰²ï¼Œå¯èƒ½æœ‰å¤šä¸ªä¸åŒçš„ç±»åˆ«ï¼Œå¦‚çº¢è‰²ã€è“è‰²ã€ç»¿è‰²ç­‰ã€‚ä¸ºäº†åœ¨æœºå™¨å­¦ä¹ ç®—æ³•ä¸­ä½¿ç”¨è¿™ä¸ªç‰¹å¾ï¼Œéœ€è¦å°†æ¯ä¸ªé¢œè‰²ç±»åˆ«æ˜ å°„åˆ°ä¸€ä¸ªæ•°å€¼ï¼Œå¦‚çº¢è‰²å¯¹åº”0ï¼Œè“è‰²å¯¹åº”1ï¼Œç»¿è‰²å¯¹åº”2ç­‰ã€‚å¯ä»¥ä½¿ç”¨è®­ç»ƒæ•°æ®é›†ä¸­çš„é¢œè‰²æ ·æœ¬æ¥ç¡®å®šè¿™ä¸ªæ˜ å°„ï¼Œå¹¶å°†å…¶åº”ç”¨äºæ•´ä¸ªæ•°æ®é›†ã€‚

# æ ‡ç­¾è¿›è¡ŒäºŒå…ƒåŒ–

## LabelBinarizer

- [sklearn.preprocessing.LabelBinarizer â€” scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer.inverse_transform)

- Binarize labels in a **one-vs-all** fashion.

  Several regression and binary classification algorithms are available in scikit-learn. A simple way to extend these algorithms to the multi-class classification case is to use the so-called one-vs-all scheme.

  At learning time, this simply consists in learning one regressor or binary classifier per class. In doing so, one needs to convert multi-class labels to binary labels (belong or does not belong to the class). LabelBinarizer makes this process easy with the transform method.

  At prediction time, one assigns the class for which the corresponding model gave the greatest confidence. LabelBinarizer makes this easy with the inverse_transform method.

- ç”¨ä¸€å¯¹å¤šçš„æ–¹æ³•å¯¹æ ‡ç­¾è¿›è¡ŒäºŒå…ƒåŒ–ã€‚

  scikit-learnä¸­æä¾›äº†å¤šç§å›å½’å’ŒäºŒå…ƒåˆ†ç±»ç®—æ³•ã€‚å°†è¿™äº›ç®—æ³•æ‰©å±•åˆ°å¤šç±»åˆ«åˆ†ç±»æƒ…å†µçš„ä¸€ç§ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨æ‰€è°“çš„ä¸€å¯¹å¤šæ–¹æ¡ˆã€‚

  åœ¨å­¦ä¹ æ—¶ï¼Œè¿™ä¸ªæ–¹æ¡ˆå°±æ˜¯é’ˆå¯¹æ¯ä¸ªç±»å­¦ä¹ ä¸€ä¸ªå›å½’å™¨æˆ–äºŒå…ƒåˆ†ç±»å™¨ã€‚ä¸ºäº†åšåˆ°è¿™ä¸€ç‚¹ï¼Œéœ€è¦å°†å¤šç±»åˆ«æ ‡ç­¾è½¬æ¢ä¸ºäºŒå…ƒæ ‡ç­¾ï¼ˆå±äºæˆ–ä¸å±äºè¯¥ç±»ï¼‰ã€‚LabelBinarizeræä¾›äº†transformæ–¹æ³•ä½¿è¿™ä¸ªè¿‡ç¨‹å˜å¾—å®¹æ˜“ã€‚

  åœ¨é¢„æµ‹æ—¶ï¼Œæˆ‘ä»¬ä¼šå°†æ ·æœ¬åˆ†é…ç»™ç›¸åº”æ¨¡å‹ç»™å‡ºçš„ç½®ä¿¡åº¦æœ€é«˜çš„ç±»åˆ«ã€‚LabelBinarizeræä¾›äº†inverse_transformæ–¹æ³•ä½¿è¿™ä¸ªè¿‡ç¨‹å˜å¾—å®¹æ˜“ã€‚

- scikit-learnä¸­çš„LabelBinarizeræ¨¡å—æ˜¯ä¸€ç§ç”¨äºå°†æ ‡ç­¾æ•°æ®è¿›è¡ŒäºŒå€¼åŒ–å¤„ç†çš„å·¥å…·ã€‚

- åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸä¸­ï¼Œç»å¸¸éœ€è¦å°†æ ‡ç­¾æ•°æ®è½¬åŒ–ä¸ºäºŒè¿›åˆ¶è¡¨ç¤ºå½¢å¼ï¼Œä»¥ä¾¿äºå¯¹å…¶è¿›è¡Œå¤„ç†å’Œåˆ†æã€‚LabelBinarizeræ¨¡å—å°±æ˜¯ç”¨æ¥å®ç°è¿™ä¸€åŠŸèƒ½çš„ã€‚

### LabelBinarizeræ¨¡å—çš„ä¸€äº›é‡è¦ç‰¹ç‚¹å’Œç”¨æ³•

1. LabelBinarizerå¯ä»¥å°†å¤šç±»åˆ«æ ‡ç­¾æ•°æ®è½¬åŒ–ä¸ºäºŒè¿›åˆ¶å½¢å¼ã€‚ä¾‹å¦‚ï¼Œå‡è®¾æœ‰ä¸€ä¸ªåŒ…å«ä¸‰ç§ç±»åˆ«æ ‡ç­¾çš„æ•°æ®é›†ï¼ŒLabelBinarizerå¯ä»¥å°†å…¶è½¬åŒ–ä¸ºä¸€ä¸ªåŒ…å«ä¸‰åˆ—çš„äºŒè¿›åˆ¶æ•°ç»„ï¼Œå…¶ä¸­æ¯ä¸€åˆ—è¡¨ç¤ºä¸€ç§ç±»åˆ«çš„å­˜åœ¨æˆ–ä¸å­˜åœ¨ã€‚
2. LabelBinarizerå¯ä»¥é€‚ç”¨äºå¤šç§ç±»å‹çš„æ ‡ç­¾æ•°æ®ã€‚æ— è®ºæ˜¯å­—ç¬¦ä¸²ç±»å‹çš„æ ‡ç­¾ï¼Œè¿˜æ˜¯æ•°å€¼å‹çš„æ ‡ç­¾ï¼Œéƒ½å¯ä»¥ä½¿ç”¨LabelBinarizerè¿›è¡ŒäºŒå€¼åŒ–å¤„ç†ã€‚
3. LabelBinarizerå¯ä»¥é€šè¿‡fit_transform()æ–¹æ³•è¿›è¡Œæ‹Ÿåˆå’Œè½¬æ¢æ“ä½œã€‚æ‹Ÿåˆæ“ä½œä¼šå¯¹æ ‡ç­¾æ•°æ®è¿›è¡Œå¤„ç†å¹¶ç”Ÿæˆä¸€ä¸ªäºŒè¿›åˆ¶ç¼–ç çŸ©é˜µï¼Œè½¬æ¢æ“ä½œåˆ™ä¼šå°†æ ‡ç­¾æ•°æ®è½¬åŒ–ä¸ºå¯¹åº”çš„äºŒè¿›åˆ¶ç¼–ç ã€‚
4. LabelBinarizerè¿˜æä¾›äº†inverse_transform()æ–¹æ³•ï¼Œç”¨äºå°†äºŒè¿›åˆ¶ç¼–ç çŸ©é˜µè½¬åŒ–ä¸ºåŸå§‹çš„æ ‡ç­¾æ•°æ®ã€‚è¿™ä¸€æ–¹æ³•åœ¨è¿›è¡Œé¢„æµ‹æ—¶éå¸¸æœ‰ç”¨ï¼Œå¯ä»¥å°†æœºå™¨å­¦ä¹ æ¨¡å‹è¾“å‡ºçš„ç»“æœè½¬åŒ–ä¸ºåŸå§‹çš„æ ‡ç­¾æ•°æ®ã€‚
5. LabelBinarizerè¿˜æä¾›äº†ä¸€äº›å…¶ä»–çš„å‚æ•°å’Œå±æ€§ï¼Œä¾‹å¦‚sparse_outputå‚æ•°å¯ä»¥æ§åˆ¶è¾“å‡ºçš„ç¨ å¯†æˆ–ç¨€ç–æ€§ï¼Œclasses_å±æ€§å¯ä»¥æŸ¥çœ‹æ ‡ç­¾çš„ç±»åˆ«ä¿¡æ¯ç­‰ã€‚

- ç»¼ä¸Šæ‰€è¿°ï¼ŒLabelBinarizeræ¨¡å—æ˜¯ä¸€ä¸ªéå¸¸å®ç”¨çš„å·¥å…·ï¼Œå¯ä»¥æ–¹ä¾¿åœ°å°†æ ‡ç­¾æ•°æ®è¿›è¡ŒäºŒå€¼åŒ–å¤„ç†ï¼Œé€‚ç”¨äºå¤šç§ç±»å‹çš„æ ‡ç­¾æ•°æ®ï¼Œå¹¶æä¾›äº†è®¸å¤šå®ç”¨çš„æ–¹æ³•å’Œå±æ€§ã€‚

### methods

- | methods(https links)                                         | Descriptoins                                                 |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer.fit)(y) | Fit label binarizer.                                         |
  | [`fit_transform`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer.fit_transform)(y) | Fit label binarizer/transform multi-class labels to binary labels. |
  | [`get_params`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer.get_params)([deep]) | Get parameters for this estimator.                           |
  | [`inverse_transform`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer.inverse_transform)(Y[, threshold]) | Transform binary labels back to multi-class labels.          |
  | [`set_output`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer.set_output)(*[, transform]) | Set output container.                                        |
  | [`set_params`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer.set_params)(**params) | Set the parameters of this estimator.                        |
  | [`transform`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer.transform)(y) | Transform multi-class labels to binary labels.               |

### äºŒè¿›åˆ¶çŸ©é˜µ

- åªåŒ…å«0å’Œ1çš„çŸ©é˜µé€šå¸¸è¢«ç§°ä¸ºäºŒè¿›åˆ¶çŸ©é˜µï¼ˆbinary matrixï¼‰ï¼Œä¹Ÿå¯ä»¥ç§°ä¸ºå¸ƒå°”çŸ©é˜µï¼ˆBoolean matrixï¼‰ã€‚è¿™ç§ç±»å‹çš„çŸ©é˜µé€šå¸¸ç”¨äºè¡¨ç¤ºå›¾å½¢ã€ç½‘ç»œæˆ–é€»è¾‘å…³ç³»ç­‰é—®é¢˜ã€‚

- åœ¨Pythonä¸­ï¼Œå¯ä»¥ä½¿ç”¨NumPyåº“æ¥åˆ›å»ºäºŒè¿›åˆ¶çŸ©é˜µã€‚ä¾‹å¦‚è¦å¾—åˆ°ä¸€ä¸ª5x3çš„äºŒè¿›åˆ¶è¿›åˆ¶çŸ©é˜µï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç 

  - ```python
    M=np.random.randint(0,2,size=(5,3))
    print(M)
    ```

    

### fit(y)

- Fit label binarizer.

- Parameters:

  - y:ndarray of shape (**n_samples**,) or (**n_samples**, n_classes)
  - Target values. **The 2-d matrix should only contain 0 and 1**, represents multilabel classification.

- Returns:

  - self:object
  - Returns the instance itself.

- å‚æ•°`y`æ˜¯ç›®æ ‡å€¼ï¼Œç”¨äºå¤šæ ‡ç­¾åˆ†ç±»ä»»åŠ¡ã€‚å¯¹äºäºŒå…ƒåˆ†ç±»é—®é¢˜ï¼Œ`y`å¯ä»¥æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º`(n_samples,)`çš„ä¸€ç»´æ•°ç»„ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ è¡¨ç¤ºä¸€ä¸ªæ ·æœ¬çš„æ ‡ç­¾ï¼Œå–å€¼ä¸º0æˆ–1ï¼Œè¡¨ç¤ºè¯¥æ ·æœ¬å±äºæˆ–ä¸å±äºæŸä¸ªç±»åˆ«ã€‚å¯¹äºå¤šç±»åˆ«åˆ†ç±»é—®é¢˜ï¼Œ`y`å¯ä»¥æ˜¯ä¸€ä¸ªå½¢çŠ¶ä¸º`(n_samples, n_classes)`çš„äºŒç»´æ•°ç»„ï¼Œå…¶ä¸­`n_samples`è¡¨ç¤ºæ ·æœ¬æ•°ï¼Œ`n_classes`è¡¨ç¤ºç±»åˆ«æ•°ï¼Œæ¯ä¸ªå…ƒç´ è¡¨ç¤ºä¸€ä¸ªæ ·æœ¬åœ¨å¯¹åº”ç±»åˆ«ä¸Šçš„æ ‡ç­¾ï¼Œå–å€¼ä¸º0æˆ–1ï¼Œè¡¨ç¤ºè¯¥æ ·æœ¬å±äºæˆ–ä¸å±äºè¯¥ç±»åˆ«ã€‚

- å½“ä¸€ä¸ªæ ·æœ¬å±äºå¤šä¸ªç±»åˆ«æ—¶ï¼Œå¯¹åº”çš„å…ƒç´ å–å€¼ä¸º1ï¼Œå¦åˆ™ä¸º0ã€‚å› æ­¤ï¼Œå‚æ•°`y`çš„äºŒç»´æ•°ç»„å¯ä»¥è¢«çœ‹åšæ˜¯å¤šä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜çš„ç»„åˆï¼Œæ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€ä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜ã€‚

- åœ¨**å¤šæ ‡ç­¾**åˆ†ç±»é—®é¢˜ä¸­ï¼Œ**ä¸€ä¸ªæ ·æœ¬å¯ä»¥åŒæ—¶å±äºå¤šä¸ªç±»åˆ«**ï¼Œä¸ä¼ ç»Ÿçš„**å•æ ‡ç­¾**åˆ†ç±»é—®é¢˜ä¸åŒï¼Œå› æ­¤éœ€è¦ä½¿ç”¨å¤šæ ‡ç­¾åˆ†ç±»ç®—æ³•è¿›è¡Œå¤„ç†ã€‚

- eg:

  - ```python
    >>> from sklearn import preprocessing
    >>> lb = preprocessing.LabelBinarizer()
    >>> lb.fit([1, 2, 6, 4, 2])
    LabelBinarizer()
    >>> lb.classes_
    array([1, 2, 4, 6])
    >>> lb.transform([1, 6])
    array([[1, 0, 0, 0],
           [0, 0, 0, 1]])
    ```

  - ```python
    >>> import numpy as np
    >>> lb.fit(np.array([[0, 1, 1], [1, 0, 0]]))
    LabelBinarizer()
    >>> lb.classes_
    array([0, 1, 2])
    >>> lb.transform([0, 1, 2, 1])
    array([[1, 0, 0],
           [0, 1, 0],
           [0, 0, 1],
           [0, 1, 0]])
    ```

#### binaryğŸˆ

- ```python
  lb = preprocessing.LabelBinarizer()
  bool_seq=['yes', 'no', 'no', 'yes']
  lf=lb.fit(bool_seq)
  
  classes=lf.classes_
  print(f'{classes=}')
  lb = preprocessing.LabelBinarizer()
  lbft=lb.fit_transform(['yes', 'no', 'no', 'yes'])
  print(lbft,'@{lbft}')
  # 
  print(f'{lb.y_type_=}')
  ```

  - ```bash
    classes=array(['no', 'yes'], dtype='<U3')
    [[1]
     [0]
     [0]
     [1]] @{lbft}
    lb.y_type_='binary'
    ```

#### multiclass

- ```python
  from sklearn.preprocessing import LabelBinarizer
  
  # ä¸‰åˆ†ç±»
  # labelsä¸­å«æœ‰4ä¸ªæ ·æœ¬çš„æ ‡ç­¾(label)
  labels = ['cat', 'dog', 'bird', 'dog']
  lb = LabelBinarizer()#å®ä¾‹åŒ–äºŒå…ƒé¢„å¤„ç†å¯¹è±¡
  # ä½¿ç”¨fit_transfrom(labels)æ‹Ÿåˆåç›´æ¥è½¬æ¢labels
  binary_labels = lb.fit_transform(labels)
  
  # æ‰“å°ç»“æœ
  print(lb.y_type_,'@{lb.y_type}')
  print(binary_labels,'@{binary_labels}')
  
  # é€šå¸¸ä¼šæ’åºå»é‡åå†ç¼–ç ,è¿™é‡Œæ’åºlabelsåªæ˜¯ä¸ºäº†æ”¾ä¾¿å¯¹æ¯”
  l=list(set(labels))
  l.sort()
  # print(l)
  ord=len(l)
  m=[list(range(ord)),l]
  m=np.array(m,dtype='<U10')
  print(m)
  ```

  - ```bash
    multiclass @{lb.y_type}
    [[0 1 0]
     [0 0 1]
     [1 0 0]
     [0 0 1]] @{binary_labels}
    [['0' '1' '2']
     ['bird' 'cat' 'dog']]
    ```

#### multilabel-indicator

#### 

- ```python
  import numpy as np
  # np.random.seed(0)
  M=np.random.randint(0,2,size=(5,8))
  print(M)
  
  lb = LabelBinarizer()
  #lbæ‹ŸåˆäºŒè¿›åˆ¶çŸ©é˜µM(æ˜¯5ä¸ªæ ·æœ¬çš„æ ‡ç­¾,æ¯ä¸ªæ ‡ç­¾æ˜¯äºŒè¿›åˆ¶å‘é‡,ä¸”å‘é‡é•¿åº¦ä¸º8,è¯´æ˜è¯¥åˆ†ç±»é—®é¢˜åŒ…å«8ä¸ªæ ‡ç­¾)
  #æ¯ä¸ªå‘é‡ä¸­å¯èƒ½åŒ…å«kä¸ª1(kå¯èƒ½å¤§äº1),è¯´æ˜å¯¹åº”çš„æ ·æœ¬è¢«æ‰“ä¸Šäº†kä¸ªæ ‡ç­¾
  lb.fit(M)
  print(f'{lb.classes_=}')
  
  N=np.random.randint(0,2,size=(5,8))
  print()
  print(N,'@N')
  R=lb.transform(N)
  print(R,'@{R}')
  print(f'{np.array_equal(N,R)=}')
  print()
  v=[0, 1, 4,7,9]
  print(v,'@{v}')
  lb.transform(v)
  print(lb.transform(v),'@{lb.transform(v)}')
  
  lb.y_type_
  ```

  - ```bash
    [[0 0 1 0 1 1 1 1]
     [1 1 0 1 0 0 0 0]
     [0 1 1 0 0 0 0 1]
     [0 0 0 1 0 1 0 1]
     [0 1 0 0 1 1 0 0]]
    lb.classes_=array([0, 1, 2, 3, 4, 5, 6, 7])
    
    [[0 1 1 1 1 0 1 1]
     [0 1 0 1 0 0 0 0]
     [0 0 1 0 0 1 1 1]
     [1 1 0 1 0 0 1 0]
     [0 1 0 1 1 1 1 0]] @N
    [[0 1 1 1 1 0 1 1]
     [0 1 0 1 0 0 0 0]
     [0 0 1 0 0 1 1 1]
     [1 1 0 1 0 0 1 0]
     [0 1 0 1 1 1 1 0]] @{R}
    np.array_equal(N,R)=True
    
    [0, 1, 4, 7, 9] @{v}
    [[1 0 0 0 0 0 0 0]
     [0 1 0 0 0 0 0 0]
     [0 0 0 0 1 0 0 0]
     [0 0 0 0 0 0 0 1]
     [0 0 0 0 0 0 0 0]] @{lb.transform(v)}
    'multilabel-indicator'
    ```

  - è²Œä¼¼å¦‚æœå°†ä¸€ç»´æ•°ç»„vä¼ é€’ç»™`lb.transform`,ä¼šå°†å¤„ç†ä¸ºå•æ ‡ç­¾
    - ä¾‹å¦‚,outputs=n,(æ ‡ç­¾å·`0,1,2,...,n-1`)é‚£ä¹ˆvä¸­å¤§ç­‰äºnçš„å€¼è¢«è½¬æ¢ä¸º0å‘é‡
  - å¦‚æœä¼ é€’äºŒè¿›åˆ¶çŸ©é˜µ,åˆ™ä¼šåŸæ ·è¾“å‡º)



### transform(y)

- Transform multi-class labels to binary labels.

- The output of transform is sometimes referred to by some authors as the 1-of-K coding scheme.

  - Parameters:

    - y{array, sparse matrix} of <u>shape (n_samples,)</u> or <u>(n_samples, n_classes)</u>
    - Target values. The 2-d matrix should only contain 0 and 1, represents multilabel classification. Sparse matrix can be CSR, CSC, COO, DOK, or LIL.

  - Returns:
    - Y{ndarray, sparse matrix} of shape (n_samples, n_classes)
    - Shape will be (n_samples, 1) for binary problems. Sparse matrix will be of CSR format.

### fit_transform(y)

Fit label binarizer/transform multi-class labels to binary labels.

The output of transform is sometimes referred to as the 1-of-K coding scheme.

Fit label binarizer/transform multi-class labels to binary labelsæŒ‡çš„æ˜¯å°†å¤šç±»æ ‡ç­¾è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾çš„è¿‡ç¨‹ï¼Œé€šè¿‡å°†æ¯ä¸ªç±»åˆ«è½¬æ¢ä¸ºä¸€ä¸ªäºŒè¿›åˆ¶å‘é‡ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªå…ƒç´ ä¸º1ï¼Œå…¶ä»–å…ƒç´ ä¸º0ã€‚è¿™ä¸ªè¿‡ç¨‹å¯ä»¥ä½¿ç”¨Scikit-learnä¸­çš„LabelBinarizerç±»æ¥å®ç°ã€‚

LabelBinarizerç±»å¯ä»¥å°†å¤šç±»æ ‡ç­¾è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾ï¼Œå…¶ä¸­æ¯ä¸ªç±»åˆ«å¯¹åº”ä¸€ä¸ªäºŒè¿›åˆ¶å‘é‡ã€‚è¯¥ç±»è¿˜å¯ä»¥ç”¨äºåè½¬è½¬æ¢ï¼Œå°†äºŒè¿›åˆ¶æ ‡ç­¾è½¬æ¢å›å¤šç±»æ ‡ç­¾ã€‚

è¾“å‡ºçš„äºŒè¿›åˆ¶æ ‡ç­¾æœ‰æ—¶ä¹Ÿç§°ä¸º1-of-Kç¼–ç æ–¹æ¡ˆï¼Œå…¶ä¸­Kè¡¨ç¤ºç±»åˆ«çš„æ•°é‡ã€‚åœ¨è¿™ç§ç¼–ç æ–¹æ¡ˆä¸‹ï¼Œæ¯ä¸ªæ ·æœ¬çš„æ ‡ç­¾éƒ½æ˜¯ä¸€ä¸ªKç»´çš„äºŒè¿›åˆ¶å‘é‡ï¼Œå…¶ä¸­åªæœ‰ä¸€ä¸ªå…ƒç´ ä¸º1ï¼Œå…¶ä»–å…ƒç´ ä¸º0ï¼Œç”¨äºè¡¨ç¤ºè¯¥æ ·æœ¬æ‰€å±çš„ç±»åˆ«ã€‚

#### eg

- ä»¥ä¸‹æ˜¯å‡ ä¸ªä½¿ç”¨LabelBinarizerçš„ç¤ºä¾‹ï¼š

- å°†å­—ç¬¦ä¸²ç±»å‹çš„æ ‡ç­¾æ•°æ®è¿›è¡ŒäºŒå€¼åŒ–å¤„ç†ï¼š

  ```python
  from sklearn.preprocessing import LabelBinarizer
  
  labels = ['cat', 'dog', 'bird', 'dog']
  lb = LabelBinarizer()
  binary_labels = lb.fit_transform(labels)
  
  # é€šå¸¸ä¼šæ’åºå»é‡åå†ç¼–ç ,è¿™é‡Œæ’åºlabelsåªæ˜¯ä¸ºäº†æ”¾ä¾¿å¯¹æ¯”
  l=list(set(labels))
  l.sort()
  # print(l)
  ord=len(l)
  m=[list(range(ord)),l]
  m=np.array(m,dtype='<U10')
  print(m)
  # 
  print(binary_labels)
  ```

  - ```bash
    [['0' '1' '2']
     ['bird' 'cat' 'dog']]
    [[0 1 0]
     [0 0 1]
     [1 0 0]
     [0 0 1]]
    ```

    

  - åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼Œå°†å­—ç¬¦ä¸²ç±»å‹çš„æ ‡ç­¾æ•°æ®è¿›è¡Œäº†äºŒå€¼åŒ–å¤„ç†ï¼Œå…¶ä¸­æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ ·æœ¬ï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºä¸€ä¸ªç±»åˆ«ï¼Œ1è¡¨ç¤ºè¯¥æ ·æœ¬å±äºè¯¥ç±»åˆ«ï¼Œ0è¡¨ç¤ºä¸å±äºè¯¥ç±»åˆ«ã€‚

- å°†æ•°å€¼å‹çš„æ ‡ç­¾æ•°æ®è¿›è¡ŒäºŒå€¼åŒ–å¤„ç†ï¼š

  ```python
  from sklearn.preprocessing import LabelBinarizer
  
  labels = [1, 2, 3, 2]
  lb = LabelBinarizer()
  binary_labels = lb.fit_transform(labels)
  
  print(binary_labels)
  # è¾“å‡ºï¼šarray([[1, 0, 0],
  #             [0, 1, 0],
  #             [0, 0, 1],
  #             [0, 1, 0]])
  ```

  - åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼Œå°†æ•°å€¼å‹çš„æ ‡ç­¾æ•°æ®è¿›è¡Œäº†äºŒå€¼åŒ–å¤„ç†ï¼Œå…¶ä¸­æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ ·æœ¬ï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºä¸€ä¸ªç±»åˆ«ï¼Œ1è¡¨ç¤ºè¯¥æ ·æœ¬å±äºè¯¥ç±»åˆ«ï¼Œ0è¡¨ç¤ºä¸å±äºè¯¥ç±»åˆ«ã€‚


### inverse_transform

- å°†æœºå™¨å­¦ä¹ æ¨¡å‹è¾“å‡ºçš„ç»“æœè½¬åŒ–ä¸ºåŸå§‹çš„æ ‡ç­¾æ•°æ®ï¼š`inverse_transform`æ–¹æ³•

  - In the case when the binary labels are fractional (probabilistic), inverse_transform chooses the class with the greatest value. Typically, this allows to use the output of a linear modelâ€™s decision_function method directly as the input of inverse_transform.

    åœ¨äºŒå…ƒæ ‡ç­¾ä¸ºåˆ†æ•°ï¼ˆæ¦‚ç‡ï¼‰çš„æƒ…å†µä¸‹ï¼Œ`inverse_transform`æ–¹æ³•ä¼šé€‰æ‹©å…·æœ‰æœ€å¤§å€¼çš„ç±»åˆ«ã€‚é€šå¸¸ï¼Œè¿™å…è®¸ç›´æ¥å°†çº¿æ€§æ¨¡å‹`decision_function`æ–¹æ³•çš„è¾“å‡ºä½œä¸º`inverse_transform`æ–¹æ³•çš„è¾“å…¥ã€‚

    è¿™å¥è¯çš„æ„æ€æ˜¯ï¼Œåœ¨äºŒå…ƒæ ‡ç­¾ä¸ä»…ä»…æ˜¯0å’Œ1ï¼Œè€Œæ˜¯ä»¥æ¦‚ç‡æˆ–åˆ†æ•°çš„å½¢å¼è¡¨ç¤ºï¼ˆä¾‹å¦‚ï¼Œåœ¨é€»è¾‘å›å½’ä¸­ï¼‰ï¼Œæ ‡ç­¾ç¼–ç å™¨çš„`inverse_transform`æ–¹æ³•ä¼šé€‰æ‹©æ¦‚ç‡å€¼æœ€é«˜çš„ç±»åˆ«æ¥å°†ç¼–ç æ ‡ç­¾æ˜ å°„å›å…¶åŸå§‹å½¢å¼ã€‚

    ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬æœ‰ä¸€ä¸ªäºŒå…ƒåˆ†ç±»é—®é¢˜ï¼Œæ ‡ç­¾ä»¥æ¦‚ç‡çš„å½¢å¼è¡¨ç¤ºï¼Œä¾‹å¦‚[0.2, 0.8]ï¼Œå…¶ä¸­ç¬¬ä¸€ä¸ªå€¼è¡¨ç¤ºè´Ÿç±»çš„æ¦‚ç‡ï¼Œç¬¬äºŒä¸ªå€¼è¡¨ç¤ºæ­£ç±»çš„æ¦‚ç‡ï¼Œå¦‚æœæˆ‘ä»¬ä½¿ç”¨`sklearn.preprocessing`æ¨¡å—ä¸­çš„`LabelEncoder`å¯¹å®ƒä»¬è¿›è¡Œç¼–ç ï¼Œå¾—åˆ°çš„ç¼–ç æ ‡ç­¾å¯èƒ½æ˜¯[0, 1]ã€‚è¦å°†æ ‡ç­¾è§£ç å›å…¶åŸå§‹å½¢å¼ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨æ ‡ç­¾ç¼–ç å™¨çš„`inverse_transform`æ–¹æ³•ï¼Œå®ƒå°†é€‰æ‹©å…·æœ‰æœ€é«˜æ¦‚ç‡å€¼çš„ç±»åˆ«ï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯æ¦‚ç‡ä¸º0.8çš„ç¬¬äºŒç±»ï¼‰ï¼Œå°†å…¶æ˜ å°„å›åŸå§‹æ ‡ç­¾å€¼ï¼ˆåœ¨æœ¬ä¾‹ä¸­æ˜¯æ­£ç±»ï¼‰ã€‚

    `inverse_transform`æ–¹æ³•çš„è¿™ä¸ªæ€§è´¨å…è®¸æˆ‘ä»¬ç›´æ¥å°†çº¿æ€§æ¨¡å‹çš„`decision_function`æ–¹æ³•çš„è¾“å‡ºï¼ˆäº§ç”Ÿè¿ç»­å¾—åˆ†æˆ–æ¦‚ç‡ï¼‰ä½œä¸º`inverse_transform`æ–¹æ³•çš„è¾“å…¥ï¼Œé¿å…åœ¨è§£ç ä¹‹å‰å°†å¾—åˆ†æˆ–æ¦‚ç‡èˆå…¥ä¸ºäºŒå…ƒæ ‡ç­¾çš„éœ€æ±‚ã€‚

  - ```python
    from sklearn.preprocessing import LabelBinarizer
    
    labels = ['cat', 'dog', 'bird', 'dog']
    lb = LabelBinarizer()
    binary_labels = lb.fit_transform(labels)
    print(binary_labels,'@{binary_labels}')
    #éšæœºæ„é€ äºŒè¿›åˆ¶å½¢å¼çš„mä¸ªæ ·æœ¬æ ‡ç­¾
    m=6
    v=np.random.randint(0,2,size=(m,3))
    print(v,'@{v}')
    label_str1 = lb.inverse_transform(binary_labels)
    label_str2=lb.inverse_transform(v)
    print(label_str1,'@{label_str1}')
    print(label_str2,'@{label_str2}')
    # è¾“å‡ºï¼šarray(['dog'])
    ```
  
  - ```bash
    [[0 1 0]
     [0 0 1]
     [1 0 0]
     [0 0 1]] @{binary_labels}
    [[0 1 0]
     [1 0 1]
     [0 1 0]
     [1 0 0]
     [0 1 0]
     [1 1 1]] @{v}
    ['cat' 'dog' 'bird' 'dog'] @{label_str1}
    ['cat' 'bird' 'cat' 'bird' 'cat' 'bird'] @{label_str2}
    ```
  
    
  
  åœ¨ä¸Šè¿°ç¤ºä¾‹ä¸­ï¼Œå°†æœºå™¨å­¦ä¹ æ¨¡å‹è¾“å‡ºçš„ç»“æœè½¬åŒ–ä¸ºäº†åŸå§‹çš„æ ‡ç­¾æ•°æ®ï¼Œå³å°†[0, 1, 0]è½¬åŒ–ä¸º'dog'ã€‚

### decision_function

- `decision_function` (å†³ç­–(å€¼)å‡½æ•°)æ˜¯è®¸å¤šæœºå™¨å­¦ä¹ åº“ï¼ˆä¾‹å¦‚ scikit-learnï¼‰ä¸­çš„æ–¹æ³•ï¼Œç”¨äºè·å–è®­ç»ƒåˆ†ç±»å™¨æ¨¡å‹çš„å†³ç­–å€¼æˆ–åˆ†æ•°ã€‚

  å¯¹äºäºŒå…ƒåˆ†ç±»æ¨¡å‹ï¼Œå†³ç­–å‡½æ•°ä¸ºæ¯ä¸ªè¾“å…¥æ ·æœ¬è¿”å›ä¸€ä¸ªæ ‡é‡å€¼ï¼Œè¡¨ç¤ºç½®ä¿¡åº¦æ°´å¹³æˆ–ä¸å†³ç­–è¾¹ç•Œçš„è·ç¦»ã€‚æ­£åˆ†æ•°è¡¨ç¤ºé¢„æµ‹ç±»æ˜¯æ­£ç±»ï¼Œè€Œè´Ÿåˆ†æ•°è¡¨ç¤ºé¢„æµ‹ç±»æ˜¯è´Ÿç±»ã€‚

  å¯¹äºå¤šç±»åˆ†ç±»æ¨¡å‹ï¼Œå†³ç­–å‡½æ•°è¿”å›ä¸€ä¸ªå½¢çŠ¶ä¸º `(n_samples, n_classes)` çš„æ•°ç»„ï¼Œå…¶ä¸­æ¯åˆ—è¡¨ç¤ºæ¯ä¸ªç±»çš„å†³ç­–åˆ†æ•°ã€‚é€šå¸¸é€‰æ‹©å¾—åˆ†æœ€é«˜çš„ç±»ä½œä¸ºé¢„æµ‹ç±»ã€‚

  `decision_function` çš„è¾“å‡ºå¯ä»¥ç”¨äºæŒ‰å…¶å±äºç‰¹å®šç±»åˆ«çš„å¯èƒ½æ€§å¯¹å®ä¾‹è¿›è¡Œæ’åï¼Œæˆ–ç”¨äºäºŒå…ƒåˆ†ç±»é€‰æ‹©é˜ˆå€¼çš„é€‰æ‹©ã€‚

  ç¤ºä¾‹ä»£ç ï¼š

  ```python
  from sklearn import datasets
  from sklearn.svm import SVC
  
  iris = datasets.load_iris()
  X = iris.data
  y = iris.target
  
  clf = SVC(kernel='linear', C=1)
  clf.fit(X, y)
  
  decision_values = clf.decision_function(X)
  print(decision_values)
  ```

  - ```bash
    [[ 2.24627744  1.2980152  -0.30616012]
     [ 2.23781119  1.29663601 -0.30453043]
     [ 2.24548583  1.2968967  -0.30542241]
    
     [ 2.24582594  1.29755577 -0.30584425]
     [ 2.23172213  1.29740176 -0.30449171]
     [ 2.24234659  1.29677295 -0.30503889]
     [ 2.25994866  1.29851536 -0.30791884]
     [ 2.22220568  1.29446718 -0.30181542]
     [ 2.22238071  1.2949585  -0.3021531 ]
    ...
     [-0.27556832  1.23623884  2.23345589]
     [-0.27601105  1.23609444  2.23492045]
     [-0.2782753   1.21204627  2.25592049]
     [-0.27247876  1.23683133  2.22308144]]
    ```

    

  è¿™ä¸ªä¾‹å­ä½¿ç”¨ SVM è¿›è¡Œåˆ†ç±»ï¼Œè¾“å‡ºæ¯ä¸ªæ ·æœ¬ç›¸å¯¹äºåˆ†ç±»è¾¹ç•Œçš„è·ç¦»ï¼ˆå†³ç­–å‡½æ•°çš„å€¼ï¼‰ã€‚

- ```python
  from sklearn.datasets import make_classification
  from sklearn.linear_model import LogisticRegression
  from sklearn.metrics import precision_recall_curve, f1_score, auc
  from sklearn.model_selection import train_test_split
  import numpy as np
  
  # ç”ŸæˆäºŒå…ƒåˆ†ç±»æ•°æ®
  X, y = make_classification(n_samples=1000, n_classes=2, random_state=42)
  
  # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
  
  # è®­ç»ƒé€»è¾‘å›å½’æ¨¡å‹
  clf = LogisticRegression()
  clf.fit(X_train, y_train)
  
  # é¢„æµ‹æµ‹è¯•é›†
  y_pred = clf.predict(X_test)
  
  # è®¡ç®—é¢„æµ‹æ¦‚ç‡å€¼
  y_pred_prob = clf.predict_proba(X_test)[:, 1]
  
  # è®¡ç®—ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œ F1 åˆ†æ•°
  precision, recall, thresholds = precision_recall_curve(y_test, y_pred_prob)
  f1_scores = 2 * (precision * recall) / (precision + recall)
  
  # æ‰¾åˆ° F1 åˆ†æ•°æœ€å¤§çš„é˜ˆå€¼ï¼Œå¹¶è®¡ç®—ç›¸åº”çš„ AUC å€¼
  best_threshold = thresholds[np.argmax(f1_scores)]
  y_pred_best = (y_pred_prob >= best_threshold).astype(int)
  auc_score = auc(recall, precision)
  
  # ä½¿ç”¨æœ€ä½³é˜ˆå€¼è¿›è¡Œé¢„æµ‹
  decision_values = clf.decision_function(X_test)
  y_pred_threshold = (decision_values >= best_threshold).astype(int)
  
  # è¾“å‡ºç»“æœ
  print('Best Threshold:', best_threshold)
  print('F1 Score:', f1_score(y_test, y_pred_best))
  print('AUC Score:', auc_score)
  ```

  - ```bash
    Best Threshold: 0.447523986784808
    F1 Score: 0.881516587677725
    AUC Score: 0.9390805456541883
    ```

    

- åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨é€»è¾‘å›å½’æ¨¡å‹è¿›è¡ŒäºŒå…ƒåˆ†ç±»ï¼Œå¹¶ä½¿ç”¨ `decision_function` æ–¹æ³•è®¡ç®—æ¯ä¸ªæµ‹è¯•æ ·æœ¬çš„å†³ç­–å€¼ã€‚ç„¶åï¼Œæˆ‘ä»¬é€šè¿‡è®¡ç®—ç²¾ç¡®ç‡ã€å¬å›ç‡å’Œ F1 åˆ†æ•°æ¥æ‰¾åˆ°æœ€ä½³é˜ˆå€¼ï¼Œå¹¶ä½¿ç”¨è¯¥é˜ˆå€¼è¿›è¡Œé¢„æµ‹ã€‚



## MultilabelBinarizer

- [MultilableBinarizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html)

- Transform between iterable of iterables and a multilabel format.

  Although a list of sets or tuples is a very intuitive format for multilabel data, it is unwieldy to process. This transformer converts between this intuitive format and the supported multilabel format: a (samples x classes) binary matrix indicating the presence of a class label.å¯è¿­ä»£çš„å¯è¿­ä»£å¯¹è±¡å’Œå¤šæ ‡ç­¾æ ¼å¼ä¹‹é—´çš„è½¬æ¢ã€‚è™½ç„¶ä»¥é›†åˆæˆ–å…ƒç»„çš„å½¢å¼è¡¨ç¤ºå¤šæ ‡ç­¾æ•°æ®æ˜¯ä¸€ç§éå¸¸ç›´è§‚çš„æ ¼å¼ï¼Œä½†å®ƒä¸ä¾¿äºå¤„ç†ã€‚æ­¤è½¬æ¢å™¨å¯ä»¥åœ¨è¿™ç§ç›´è§‚çš„æ ¼å¼å’Œæ”¯æŒçš„å¤šæ ‡ç­¾æ ¼å¼ä¹‹é—´è¿›è¡Œè½¬æ¢ï¼šä¸€ä¸ªï¼ˆæ ·æœ¬æ•° x ç±»åˆ«æ•°ï¼‰çš„äºŒè¿›åˆ¶çŸ©é˜µï¼ŒæŒ‡ç¤ºç±»åˆ«æ ‡ç­¾çš„å­˜åœ¨ã€‚

- `MultiLabelBinarizer` æ˜¯ Python ä¸­ scikit-learn åº“ä¸­çš„ `sklearn.preprocessing` æ¨¡å—ä¸­çš„ä¸€ä¸ªç±»ã€‚å®ƒç”¨äºå°†å¤šæ ‡ç­¾æ•°æ®è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾è¡¨ç¤ºã€‚

- åœ¨å¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ä¸­ï¼Œæ¯ä¸ªæ ·æœ¬å¯ä»¥å±äºå¤šä¸ªç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒåˆ†ç±»é—®é¢˜ä¸­ï¼Œä¸€å¼ å›¾ç‰‡å¯èƒ½åŒæ—¶åŒ…å«ç‹—å’ŒçŒ«ã€‚`MultiLabelBinarizer` å¯ä»¥å°†è¿™ç§å¤šæ ‡ç­¾æ•°æ®è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾è¡¨ç¤ºï¼Œå…¶ä¸­æ¯ä¸ªæ ‡ç­¾è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªäºŒè¿›åˆ¶ä½ã€‚

`MultiLabelBinarizer` ç±»æœ‰ä¸¤ä¸ªä¸»è¦æ–¹æ³•ï¼š

- `fit`ï¼šä»å¤šæ ‡ç­¾æ•°æ®ä¸­è·å–æ ‡ç­¾é›†åˆï¼Œå¹¶å°†æ¯ä¸ªæ ‡ç­¾æ˜ å°„åˆ°ä¸€ä¸ªäºŒè¿›åˆ¶ä½ã€‚
- `transform`ï¼šå°†å¤šæ ‡ç­¾æ•°æ®è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾è¡¨ç¤ºã€‚

`MultiLabelBinarizer` è¿˜æœ‰å‡ ä¸ªæœ‰ç”¨çš„å±æ€§ï¼Œä¾‹å¦‚ï¼š

- `classes_`ï¼šå·²çŸ¥çš„æ ‡ç­¾é›†åˆã€‚
- `inverse_transform`ï¼šå°†äºŒè¿›åˆ¶æ ‡ç­¾è¡¨ç¤ºè½¬æ¢å›å¤šæ ‡ç­¾æ ¼å¼ã€‚
- `sparse_output`ï¼šæŒ‡å®šæ˜¯å¦ä½¿ç”¨ç¨€ç–çŸ©é˜µè¡¨ç¤ºè¾“å‡ºã€‚

### methods

- å„ä¸ªæ–¹æ³•çš„å‚è€ƒæ–‡æ¡£è¿æ¥

- | [`fit`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.fit)(y) | Fit the label sets binarizer, storing [classes_](https://scikit-learn.org/stable/glossary.html#term-classes_). |
  | ------------------------------------------------------------ | ------------------------------------------------------------ |
  | [`fit_transform`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.fit_transform)(y) | Fit the label sets binarizer and transform the given label sets. |
  | [`get_params`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.get_params)([deep]) | Get parameters for this estimator.                           |
  | [`inverse_transform`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.inverse_transform)(yt) | Transform the given indicator matrix into label sets.        |
  | [`set_output`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.set_output)(*[, transform]) | Set output container.                                        |
  | [`set_params`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.set_params)(**params) | Set the parameters of this estimator.                        |
  | [`transform`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html#sklearn.preprocessing.MultiLabelBinarizer.transform)(y) | Transform the given label sets.                              |

### eg

- ```python
  >>> from sklearn.preprocessing import MultiLabelBinarizer
  >>> mlb = MultiLabelBinarizer()
  >>> mlb.fit_transform([(1, 2), (3,)])
  array([[1, 1, 0],
         [0, 0, 1]])
  >>> mlb.classes_
  array([1, 2, 3])
  >>> mlb.fit_transform([{'sci-fi', 'thriller'}, {'comedy'}])
  array([[0, 1, 1], [1, 0, 0]]) 
  >>> list(mlb.classes_) ['comedy', 'sci-fi', 'thriller']
  ```

  - `fit_transform`çš„å‚æ•°y("y:iterable of iterables")æ˜¯äºŒé‡å¯è¿­ä»£å¯¹è±¡(æ¯”å¦‚å…ƒç»„çš„å…ƒç»„æˆ–æ•°ç»„çš„æ•°ç»„)

### eg

```python
from sklearn.preprocessing import MultiLabelBinarizer

y = [('cat', 'dog'), ('dog',), ('bird', 'cat', 'dog')]
mlb = MultiLabelBinarizer()
y_bin = mlb.fit_transform(y)

print(y_bin)
print(mlb.classes_)
```

è¿™å°†è¾“å‡ºä»¥ä¸‹å†…å®¹ï¼š

```bash
[[0 1 1]
 [0 0 1]
 [1 1 1]]
['bird' 'cat' 'dog']
```

åœ¨æ­¤ç¤ºä¾‹ä¸­ï¼Œ`y` æ˜¯ä¸€ä¸ªåŒ…å«ä¸‰ä¸ªå…ƒç»„çš„åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç»„è¡¨ç¤ºä¸€ä¸ªæ ·æœ¬çš„å¤šæ ‡ç­¾ã€‚ä½¿ç”¨ `MultiLabelBinarizer` å°†è¿™äº›å¤šæ ‡ç­¾æ•°æ®è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾è¡¨ç¤ºã€‚è½¬æ¢åçš„äºŒè¿›åˆ¶æ ‡ç­¾è¡¨ç¤ºå­˜å‚¨åœ¨ `y_bin` å˜é‡ä¸­ï¼Œ`classes_` å±æ€§åŒ…å«å·²çŸ¥çš„æ ‡ç­¾é›†åˆã€‚

### eg

- With multilabel outputs, it is similarly possible for an instance to be assigned multiple labels:å¯¹äºå¤šæ ‡ç­¾è¾“å‡ºï¼ŒåŒæ ·å¯èƒ½å°†ä¸€ä¸ªå®ä¾‹åˆ†é…ç»™å¤šä¸ªæ ‡ç­¾ï¼š

- ```python
  from sklearn.preprocessing import MultiLabelBinarizer
  y = [[0, 1], [0, 2], [1, 3], [0, 2, 3], [2, 4]]
  mlb = MultiLabelBinarizer()
  ymlb=mlb.fit_transform(y)
  # mlb.fit_transformå±æ€§åªæœ‰åœ¨fitæˆ–fit_transformæ–¹æ³•è¢«æˆåŠŸè°ƒç”¨åæ‰è¢«åˆ›å»ºè€Œå­˜åœ¨
  print(mlb.classes_,"@{mlb.classes_}")
  print(ymlb,"@{ymlb}")
  
  ```

  - ```bash
    [0 1 2 3 4] @{mlb.classes_}
    [[1 1 0 0 0]
     [1 0 1 0 0]
     [0 1 0 1 0]
     [1 0 1 1 0]
     [0 0 1 0 1]] @{ymlb}
    ```

- In this case, the classifier is fit upon instances each assigned multiple labels. The MultiLabelBinarizer is used to binarize the 2d array of multilabels to fit upon. As a result, predict() returns a 2d array with multiple predicted labels for each instance.

  åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œåˆ†ç±»å™¨æ˜¯æ ¹æ®åˆ†é…äº†å¤šä¸ªæ ‡ç­¾çš„å®ä¾‹æ¥æ‹Ÿåˆçš„ã€‚MultiLabelBinarizerç”¨äºå°†å¤šæ ‡ç­¾çš„2Dæ•°ç»„äºŒå…ƒåŒ–ä»¥é€‚åˆåˆ†ç±»å™¨ã€‚å› æ­¤ï¼Œpredict()è¿”å›ä¸€ä¸ª2Dæ•°ç»„ï¼Œå…¶ä¸­æ¯ä¸ªå®ä¾‹éƒ½æœ‰å¤šä¸ªé¢„æµ‹æ ‡ç­¾ã€‚"upon"å¯ä»¥ç¿»è¯‘æˆ "åœ¨...ä¹‹ä¸Š"ï¼Œåœ¨è¿™å¥è¯ä¸­ï¼Œå¯ä»¥ç†è§£ä¸ºåˆ†ç±»å™¨æ˜¯åœ¨åˆ†é…äº†å¤šä¸ªæ ‡ç­¾çš„å®ä¾‹ä¹‹ä¸Šæ‹Ÿåˆçš„ï¼Œå³åŸºäºè¿™äº›å®ä¾‹è¿›è¡Œæ‹Ÿåˆã€‚

## `MultiLabelBinarizer` vs `LabelBinarizer`

- `MultiLabelBinarizer` å’Œ `LabelBinarizer` éƒ½æ˜¯ scikit-learn åº“ä¸­çš„æ ‡ç­¾äºŒå€¼åŒ–å·¥å…·ï¼Œä½†å®ƒä»¬çš„åº”ç”¨åœºæ™¯ä¸åŒã€‚
- `LabelBinarizer` ç”¨äº**å°†å•æ ‡ç­¾æ•°æ®**è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾è¡¨ç¤ºï¼Œå…¶ä¸­æ¯ä¸ªæ ‡ç­¾è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªäºŒè¿›åˆ¶ä½ã€‚å®ƒé€‚ç”¨äºäºŒå…ƒåˆ†ç±»å’Œå•æ ‡ç­¾å¤šç±»åˆ«åˆ†ç±»é—®é¢˜ï¼Œå…¶ä¸­æ¯ä¸ªæ ·æœ¬åªå±äºä¸€ä¸ªç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒåˆ†ç±»é—®é¢˜ä¸­ï¼Œä¸€å¼ å›¾ç‰‡åªèƒ½å±äºä¸€ä¸ªç±»åˆ«ï¼Œå¦‚çŒ«ã€ç‹—æˆ–é¸Ÿç±»ã€‚
- `MultiLabelBinarizer` ç”¨äºå°†**å¤šæ ‡ç­¾æ•°æ®**è½¬æ¢ä¸ºäºŒè¿›åˆ¶æ ‡ç­¾è¡¨ç¤ºï¼Œå…¶ä¸­æ¯ä¸ªæ ‡ç­¾è¢«è¡¨ç¤ºä¸ºä¸€ä¸ªäºŒè¿›åˆ¶ä½ã€‚å®ƒé€‚ç”¨äºå¤šæ ‡ç­¾åˆ†ç±»é—®é¢˜ï¼Œå…¶ä¸­æ¯ä¸ªæ ·æœ¬å¯ä»¥å±äºå¤šä¸ªç±»åˆ«ã€‚ä¾‹å¦‚ï¼Œåœ¨å›¾åƒæ ‡æ³¨é—®é¢˜ä¸­ï¼Œä¸€å¼ å›¾ç‰‡å¯ä»¥åŒæ—¶åŒ…å«çŒ«ã€ç‹—å’Œé¸Ÿç±»ç­‰å¤šä¸ªæ ‡ç­¾ã€‚

åœ¨ä½¿ç”¨è¿™äº›å·¥å…·æ—¶ï¼Œéœ€è¦æ³¨æ„ä»¥ä¸‹å‡ ç‚¹ï¼š

- `LabelBinarizer` åªèƒ½å¤„ç†å•æ ‡ç­¾æ•°æ®ï¼Œè€Œ `MultiLabelBinarizer` åªèƒ½å¤„ç†å¤šæ ‡ç­¾æ•°æ®ã€‚

- åœ¨ä½¿ç”¨ `MultiLabelBinarizer` æ—¶ï¼Œéœ€è¦æ³¨æ„æ ·æœ¬çš„æ ‡ç­¾å¿…é¡»ä»¥å…ƒç»„æˆ–åˆ—è¡¨çš„å½¢å¼è¡¨ç¤ºï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ è¡¨ç¤ºä¸€ä¸ªæ ‡ç­¾ã€‚ä¾‹å¦‚ï¼Œå¯¹äºåŒ…å«ä¸‰ä¸ªæ ·æœ¬çš„å¤šæ ‡ç­¾æ•°æ®(æ¯”å¦‚ä¸‰å¼ ç…§ç‰‡å„è‡ªåŒ…å«çš„å“ªäº›åŠ¨ç‰©)ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹ä»£ç åˆ›å»ºæ ‡ç­¾åˆ—è¡¨ï¼š

  - ```
    y = [('cat', 'dog'), ('dog',), ('bird', 'cat', 'dog')]
    ```

- æ€»ä¹‹ï¼Œ`LabelBinarizer` é€‚ç”¨äºå•æ ‡ç­¾é—®é¢˜ï¼Œ`MultiLabelBinarizer` é€‚ç”¨äºå¤šæ ‡ç­¾é—®é¢˜ã€‚é€‰æ‹©æ­£ç¡®çš„å·¥å…·å¯ä»¥å¸®åŠ©æˆ‘ä»¬æ›´å¥½åœ°å¤„ç†ä¸åŒç±»å‹çš„åˆ†ç±»é—®é¢˜ã€‚

## demo@multiclass-vs-multilabel-fitting

- [Multiclass vs. multilabel fitting](https://scikit-learn.org/stable/tutorial/basic/tutorial.html#multiclass-vs-multilabel-fitting)

### svcå¤šå…ƒåˆ†ç±»çš„ä¾‹å­

- ```python
  from sklearn.datasets import load_iris,load_digits
  from sklearn.model_selection import train_test_split
  from sklearn.svm import SVC
  from sklearn.metrics import accuracy_score, classification_report
  
  # åŠ è½½é¸¢å°¾èŠ±æ•°æ®é›†
  # db = load_iris()
  db=load_digits()
  X = db.data
  y = db.target
  # target_names = db.target_names
  
  
  # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
  X_train, X_test, y_train, y_test = train_test_split(
      X, y, test_size=0.4, random_state=42)
  
  # è®­ç»ƒSVCæ¨¡å‹
  svc = SVC(kernel='linear', C=1, decision_function_shape='ovr')
  svc.fit(X_train, y_train)
  
  # åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹
  y_pred = svc.predict(X_test)
  y_pred
  
  # è®¡ç®—å‡†ç¡®ç‡
  acc = accuracy_score(y_test, y_pred)
  rep=classification_report(y_test,y_pred)
  print(rep,"@{rep}")
  print("Accuracy:", acc)
  
  ```

  - ```bash
                  precision    recall  f1-score   support
    
               0       1.00      1.00      1.00        67
               1       0.96      0.99      0.97        72
               2       1.00      1.00      1.00        66
               3       0.99      0.97      0.98        71
               4       0.97      1.00      0.99        78
               5       0.98      0.98      0.98        83
               6       1.00      1.00      1.00        69
               7       0.99      0.99      0.99        71
               8       0.98      0.94      0.96        65
               9       0.97      0.97      0.97        77
    
        accuracy                           0.98       719
       macro avg       0.98      0.98      0.98       719
    weighted avg       0.98      0.98      0.98       719
     @{rep}
    Accuracy: 0.9833101529902643
    ```

    

- è¿™é‡Œä½¿ç”¨~~é¸¢å°¾èŠ±~~(iriså‡†ç¡®ç‡å¤ªé«˜(è¾¾åˆ°1),é‡‡ç”¨æ‰‹å†™æ•°å­—é›†æ¯”è¾ƒçœŸå®)æ•°æ®é›†ä½œä¸ºç¤ºä¾‹æ•°æ®é›†ï¼Œå°†å…¶åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œç„¶åä½¿ç”¨SVCæ¨¡å‹è¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œé¢„æµ‹ã€‚æœ€åä½¿ç”¨å‡†ç¡®ç‡ä½œä¸ºè¯„ä¼°æŒ‡æ ‡æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œåœ¨SVCæ¨¡å‹ä¸­ä½¿ç”¨`decision_function_shape='ovr'`æ¥å®ç°ä¸€å¯¹å¤šçš„å¤šåˆ†ç±»ç­–ç•¥ã€‚

### egğŸˆ

- è¿™ä¸ªä¾‹å­ç”±å®˜ç½‘æ”¹é€ è¿‡æ¥çš„

  ```python
  from sklearn.svm import SVC
  from sklearn.multiclass import OneVsRestClassifier
  from sklearn.preprocessing import LabelBinarizer
  
  X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]
  y = [0, 0, 1, 1, 2]
  svc = SVC(random_state=0)
  classif = OneVsRestClassifier(estimator=svc)
  y_pred = classif.fit(X, y).predict(X)
  print(y_pred, "@{y_pred}")
  y_b = LabelBinarizer().fit_transform(y)
  
  # æ ‡ç­¾äºŒè¿›åˆ¶åŒ–
  print(y, "@{y}")
  print(y_b, "@{y_b}")
  # åŸºäºäºŒè¿›åˆ¶çŸ©é˜µçš„æ ‡ç­¾è¿›è¡Œæ‹Ÿåˆ
  classif2 = OneVsRestClassifier(estimator=svc)
  y_pred_b = classif2.fit(X, y_b).predict(X)
  print(y_pred_b, "@{y_pred_b}")
  
  ```

  - ```bash
    [0 0 1 1 2] @{y_pred}
    [0, 0, 1, 1, 2] @{y}
    [[1 0 0]
     [1 0 0]
     [0 1 0]
     [0 1 0]
     [0 0 1]] @{y_b}
    [[1 0 0]
     [1 0 0]
     [0 1 0]
     [0 0 0]
     [0 0 0]] @{y_pred_b}
    ```

  - åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œå½“ä½¿ç”¨æ•´æ•°å½¢å¼çš„ç›®æ ‡å€¼è¿›è¡Œæ‹Ÿåˆå’Œé¢„æµ‹æ—¶ï¼Œåˆ†ç±»å™¨å¯ä»¥æ­£ç¡®åœ°é¢„æµ‹æ‰€æœ‰æ ·æœ¬çš„ç±»åˆ«ã€‚ç„¶è€Œï¼Œå½“ä½¿ç”¨äºŒè¿›åˆ¶çŸ©é˜µå½¢å¼çš„ç›®æ ‡å€¼æ—¶ï¼Œåˆ†ç±»å™¨åœ¨æŸäº›æ ·æœ¬ä¸Šæ— æ³•è¿›è¡Œæ­£ç¡®çš„é¢„æµ‹ã€‚

  - Here, the classifier is `fit()` on a 2d binary label representation of `y`, using the [`LabelBinarizer`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelBinarizer.html#sklearn.preprocessing.LabelBinarizer). In this case `predict()` returns a 2d array representing the corresponding multilabel predictions.

    Note that the fourth and fifth instances returned all zeroes, indicating that they matched none of the three labels `fit` upon. åœ¨è¿™é‡Œï¼Œåˆ†ç±»å™¨ä½¿ç”¨ LabelBinarizer å¯¹ y çš„äºŒå…ƒæ ‡ç­¾è¡¨ç¤ºè¿›è¡Œ fit() è®­ç»ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œpredict() è¿”å›ä¸€ä¸ªè¡¨ç¤ºç›¸åº”å¤šæ ‡ç­¾é¢„æµ‹çš„äºŒç»´æ•°ç»„ã€‚

  - è¯·æ³¨æ„ï¼Œç¬¬å››ä¸ªå’Œç¬¬äº”ä¸ªå®ä¾‹è¿”å›äº†å…¨é›¶ï¼Œè¡¨æ˜å®ƒä»¬æ²¡æœ‰åŒ¹é…åˆ° fit() è®­ç»ƒæ—¶ä½¿ç”¨çš„ä¸‰ä¸ªæ ‡ç­¾ä¸­çš„ä»»ä½•ä¸€ä¸ªã€‚

#### eg

- ```python
  from sklearn.datasets import load_iris
  from sklearn.svm import SVC
  from sklearn.multiclass import OneVsRestClassifier
  from sklearn.preprocessing import LabelBinarizer
  from sklearn.metrics import classification_report,accuracy_score
  db=load_iris()
  X=db.data
  y=db.target
  # X = [[1, 2], [2, 4], [4, 5], [3, 2], [3, 1]]
  # y = [0, 0, 1, 1, 2]
  svc=SVC(random_state=0)
  classif = OneVsRestClassifier(estimator=svc)
  y_pred=classif.fit(X, y).predict(X)
  # print(y_pred,"@{y_pred}")
  print(classification_report(y, y_pred, zero_division=1))
  print(accuracy_score(y, y_pred))
  
  
  # y_b = LabelBinarizer().fit_transform(y)
  lf=LabelBinarizer().fit(y)
  print(f'{lf.classes_=},{lf.y_type_}')
  y_b=lf.transform(y)
  #æ ‡ç­¾äºŒè¿›åˆ¶åŒ–
  # print(y,"@{y}")
  # print(y_b,"@{y_b}")
  #åŸºäºäºŒè¿›åˆ¶çŸ©é˜µçš„æ ‡ç­¾è¿›è¡Œæ‹Ÿåˆ
  y_pred_b=classif.fit(X, y_b).predict(X)
  # print(y_pred_b, "@{y_pred_b}")
  print(classification_report(y_b,y_pred_b,zero_division=1))
  print(accuracy_score(y_b, y_pred_b))
  
  ```

  - ```bash
                        precision    recall  f1-score   support
    
                   0       1.00      1.00      1.00        50
                   1       0.91      0.96      0.93        50
                   2       0.96      0.90      0.93        50
    
            accuracy                           0.95       150
           macro avg       0.95      0.95      0.95       150
        weighted avg       0.95      0.95      0.95       150
    
        0.9533333333333334
                      precision    recall  f1-score   support
    
                   0       1.00      1.00      1.00        50
                   1       0.89      0.96      0.92        50
                   2       0.96      0.96      0.96        50
    
           micro avg       0.95      0.97      0.96       150
           macro avg       0.95      0.97      0.96       150
        weighted avg       0.95      0.97      0.96       150
         samples avg       0.96      0.97      0.96       150
    
        0.9466666666666667
    ```

## classification_reportğŸˆ

- `classification_report` æ˜¯ Python ä¸­ scikit-learn åº“ä¸­çš„ `sklearn.metrics` æ¨¡å—ä¸­çš„å‡½æ•°ä¹‹ä¸€ã€‚
- å®ƒç”¨äºç”Ÿæˆä¸€ä¸ªæ–‡æœ¬æŠ¥å‘Šï¼Œæ€»ç»“äº†åˆ†ç±»é—®é¢˜ä¸­æ¯ä¸ªç±»åˆ«çš„ç²¾åº¦ã€å¬å›ç‡ã€F1åˆ†æ•°å’Œæ”¯æŒåº¦ç­‰æŒ‡æ ‡ã€‚

`classification_report` å‡½æ•°æ¥å—ä¸‰ä¸ªå‚æ•°ï¼š

- `y_true`ï¼šæ•°æ®çš„çœŸå®æ ‡ç­¾
- `y_pred`ï¼šæ•°æ®çš„é¢„æµ‹æ ‡ç­¾
- `labels`ï¼šä¸€ä¸ªå¯é€‰çš„ç±»åˆ«æ ‡ç­¾åˆ—è¡¨ï¼ŒåŒ…å«åœ¨æŠ¥å‘Šä¸­ã€‚å¦‚æœä¸æä¾›ï¼Œåˆ™æŠ¥å‘Šä¸­å°†åŒ…å« `y_true` å’Œ `y_pred` ä¸­çš„æ‰€æœ‰å”¯ä¸€æ ‡ç­¾ã€‚

`classification_report` çš„è¾“å‡ºæ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œå…¶ä¸­åŒ…æ‹¬æ¯ä¸ªç±»åˆ«çš„ç²¾åº¦ã€å¬å›ç‡ã€F1åˆ†æ•°å’Œæ”¯æŒåº¦ï¼Œä»¥åŠæ‰€æœ‰ç±»åˆ«çš„å®å¹³å‡å’ŒåŠ æƒå¹³å‡æŒ‡æ ‡ã€‚

ä»¥ä¸‹æ˜¯ `classification_report` çš„ä½¿ç”¨ç¤ºä¾‹ï¼š

```python
from sklearn.metrics import classification_report

y_true = [0, 1, 2, 0, 1, 2]
y_pred = [0, 2, 1, 0, 0, 1]
target_names = ['class 0', 'class 1', 'class 2']

print(classification_report(y_true, y_pred, target_names=target_names))
```

è¿™å°†è¾“å‡ºä»¥ä¸‹æŠ¥å‘Šï¼š

- ```bash
                precision    recall  f1-score   support
  
       class 0       0.67      1.00      0.80         2
       class 1       0.00      0.00      0.00         2
       class 2       0.50      1.00      0.67         2
  
      accuracy                           0.50         6
     macro avg       0.39      0.67      0.49         6
  weighted avg       0.39      0.50      0.42         6
  ```

- å®å¹³å‡ F1 åˆ†æ•°æ˜¯ 0.49ï¼Œå®ƒæ˜¯åˆ†ç±»å™¨åœ¨æ‰€æœ‰ç±»åˆ«ä¸Šçš„æ•´ä½“æ€§èƒ½çš„ä¸€ç§åº¦é‡ã€‚
- åŠ æƒå¹³å‡ F1 åˆ†æ•°è€ƒè™‘äº†æ¯ä¸ªç±»åˆ«ä¸­æ ·æœ¬çš„æ•°é‡ï¼Œæœ¬ä¾‹ä¸­ä¸º 0.42ã€‚

### æŠ¥å‘Šä¸­çš„å­—æ®µ

- `classification_report` å‡½æ•°ç”Ÿæˆçš„æŠ¥å‘ŠåŒ…æ‹¬ä»¥ä¸‹å­—æ®µï¼š

  - `precision`ï¼šç²¾åº¦ï¼Œå³åˆ†ç±»å™¨é¢„æµ‹ä¸ºæŸä¸ªç±»åˆ«çš„æ ·æœ¬ä¸­ï¼ŒçœŸæ­£å±äºè¯¥ç±»åˆ«çš„æ ·æœ¬æ•°å é¢„æµ‹ä¸ºè¯¥ç±»åˆ«çš„æ ·æœ¬æ•°çš„æ¯”ä¾‹ã€‚
  - `recall`ï¼šå¬å›ç‡ï¼Œå³åˆ†ç±»å™¨æ­£ç¡®é¢„æµ‹ä¸ºæŸä¸ªç±»åˆ«çš„æ ·æœ¬æ•°å è¯¥ç±»åˆ«æ‰€æœ‰çœŸå®æ ·æœ¬æ•°çš„æ¯”ä¾‹ã€‚
  - `f1-score`ï¼šF1 åˆ†æ•°ï¼Œå³ç²¾åº¦å’Œå¬å›ç‡çš„è°ƒå’Œå¹³å‡å€¼ã€‚F1 åˆ†æ•°è¶Šé«˜ï¼Œè¯´æ˜åˆ†ç±»å™¨å¯¹äºè¯¥ç±»åˆ«çš„æ€§èƒ½è¶Šå¥½ã€‚
  - `support`ï¼šæ”¯æŒåº¦ï¼Œå³è¯¥ç±»åˆ«åœ¨æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°ã€‚
  - `accuracy`ï¼šå‡†ç¡®ç‡ï¼Œå³åˆ†ç±»å™¨åœ¨æ•°æ®é›†ä¸Šçš„æ•´ä½“åˆ†ç±»æ­£ç¡®ç‡ã€‚
  - `macro avg`ï¼šå®å¹³å‡æŒ‡æ ‡ï¼Œå³å¯¹äºæ‰€æœ‰ç±»åˆ«çš„æŒ‡æ ‡å–å¹³å‡å€¼ã€‚å®å¹³å‡æŒ‡æ ‡ä¸è€ƒè™‘æ ·æœ¬æ•°é‡çš„å½±å“ï¼Œå› æ­¤æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½åœ¨è®¡ç®—å®å¹³å‡æŒ‡æ ‡æ—¶è¢«å¹³ç­‰å¯¹å¾…ã€‚
  - `weighted avg`ï¼šåŠ æƒå¹³å‡æŒ‡æ ‡ï¼Œå³å¯¹äºæ‰€æœ‰ç±»åˆ«çš„æŒ‡æ ‡åŠ æƒå–å¹³å‡å€¼ã€‚åŠ æƒå¹³å‡æŒ‡æ ‡è€ƒè™‘äº†æ¯ä¸ªç±»åˆ«åœ¨æ•°æ®é›†ä¸­çš„æ ·æœ¬æ•°é‡ï¼Œå› æ­¤æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½å¯¹äºæ•´ä½“æŒ‡æ ‡çš„è´¡çŒ®ä¸åŒã€‚

  åœ¨æŠ¥å‘Šä¸­ï¼Œæ¯ä¸ªç±»åˆ«éƒ½æœ‰è‡ªå·±çš„ä¸€è¡Œï¼ŒåŒ…æ‹¬è¯¥ç±»åˆ«çš„ç²¾åº¦ã€å¬å›ç‡ã€F1 åˆ†æ•°å’Œæ”¯æŒåº¦ã€‚æœ€åä¸¤è¡Œåˆ†åˆ«æ˜¯å®å¹³å‡å’ŒåŠ æƒå¹³å‡æŒ‡æ ‡ã€‚

