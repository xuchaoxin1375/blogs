[toc]

# ML@sklearn@MLæµç¨‹Part2@æ•°æ®åˆ’åˆ†@å äº¤å‰éªŒè¯

## Model evaluation

### æ•°æ®åˆ’åˆ†

- | `æ•°æ®åˆ’åˆ†`    | æ•°æ®é›†X          | æ ‡ç­¾é›†y          |
  | ------------- | ---------------- | ---------------- |
  | è®­ç»ƒé›†X_train | `X[train_index]` | `y[train_index]` |
  | æµ‹è¯•é›†y_train | `X[test_index]`  | `y[test_index]`  |

- åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå°†æ•°æ®é›†åˆ†æˆè‡ªå˜é‡å’Œç›®æ ‡å˜é‡ä¸¤éƒ¨åˆ†ã€‚

  è‡ªå˜é‡æ˜¯ä¸€ç»„ç”¨äºé¢„æµ‹ç›®æ ‡å˜é‡çš„å˜é‡ï¼Œä¹Ÿè¢«ç§°ä¸ºç‰¹å¾æˆ–è¾“å…¥ã€‚è‡ªå˜é‡é€šå¸¸æ˜¯ä¸€ä¸ªçŸ©é˜µï¼Œå…¶ä¸­æ¯ä¸€è¡Œè¡¨ç¤ºä¸€ä¸ªæ ·æœ¬ï¼Œæ¯ä¸€åˆ—è¡¨ç¤ºä¸€ä¸ªç‰¹å¾ã€‚

  ç›®æ ‡å˜é‡æ˜¯æˆ‘ä»¬éœ€è¦é¢„æµ‹çš„å˜é‡ï¼Œä¹Ÿè¢«ç§°ä¸ºè¾“å‡ºã€‚ç›®æ ‡å˜é‡é€šå¸¸æ˜¯ä¸€ä¸ªå‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªæ ·æœ¬çš„è¾“å‡ºå€¼ã€‚

  ä¾‹å¦‚ï¼Œåœ¨å›å½’é—®é¢˜ä¸­ï¼Œè‡ªå˜é‡é€šå¸¸æ˜¯ä¸€ä¸ªåŒ…å«å¤šä¸ªç‰¹å¾çš„çŸ©é˜µï¼Œä¾‹å¦‚æˆ¿å±‹çš„é¢ç§¯ã€å§å®¤æ•°é‡ã€åœ°ç†ä½ç½®ç­‰ç­‰ï¼›è€Œç›®æ ‡å˜é‡é€šå¸¸æ˜¯ä¸€ä¸ªè¡¨ç¤ºæˆ¿å±‹ä»·æ ¼çš„å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªå…ƒç´ å¯¹åº”ä¸€ä¸ªæˆ¿å±‹çš„ä»·æ ¼ã€‚

  åœ¨ç›‘ç£å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ä¼šå°†æ•°æ®é›†åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­è®­ç»ƒé›†ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œæµ‹è¯•é›†ç”¨äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚è®­ç»ƒé›†ä¸­åŒ…å«è‡ªå˜é‡å’Œç›®æ ‡å˜é‡ï¼Œè€Œæµ‹è¯•é›†ä¸­åªåŒ…å«è‡ªå˜é‡ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ï¼Œå¹¶å°†é¢„æµ‹ç»“æœä¸æµ‹è¯•é›†ä¸­çš„ç›®æ ‡å˜é‡è¿›è¡Œæ¯”è¾ƒï¼Œä»¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

  éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè‡ªå˜é‡å’Œç›®æ ‡å˜é‡çš„æ•°é‡å’Œç±»å‹å–å†³äºå…·ä½“çš„é—®é¢˜å’Œæ•°æ®é›†ï¼Œä¸åŒçš„é—®é¢˜å¯èƒ½éœ€è¦ä¸åŒæ•°é‡å’Œç±»å‹çš„è‡ªå˜é‡å’Œç›®æ ‡å˜é‡ã€‚

## æ¦‚å¿µ:è®­ç»ƒé›†@éªŒè¯é›†@æµ‹è¯•é›†

- [Training, validation, and test data sets - Wikipedia](https://en.wikipedia.org/wiki/Training,_validation,_and_test_data_sets)
- In [machine learning](https://en.wikipedia.org/wiki/Machine_learning), a common task is the study and construction of [algorithms](https://en.wikipedia.org/wiki/Algorithm) that can learn from and make predictions on [data](https://en.wikipedia.org/wiki/Data). Such algorithms function by making data-driven predictions or decisions, through building a [mathematical model](https://en.wikipedia.org/wiki/Mathematical_model) from input data. These input data used to build the model are usually divided into multiple [data sets](https://en.wikipedia.org/wiki/Data_set). In particular, three data sets are commonly used in different stages of the creation of the model:
  -  training, validation, and test sets.
- The model is initially fit on a **training data set**, which is a set of examples used to fit the parameters (e.g. weights of connections between neurons in [artificial neural networks](https://en.wikipedia.org/wiki/Artificial_neural_networks)) of the model .The model (e.g. a [naive Bayes classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)) is trained on the training data set using a [supervised learning](https://en.wikipedia.org/wiki/Supervised_learning) method, for example using optimization methods such as [gradient descent](https://en.wikipedia.org/wiki/Gradient_descent) or [stochastic gradient descent](https://en.wikipedia.org/wiki/Stochastic_gradient_descent). In practice, the training data set often consists of pairs of an input [vector](https://en.wikipedia.org/wiki/Array_data_structure) (or scalar) and the corresponding output vector (or scalar), where the answer key is commonly denoted as the *target* (or *label*). The current model is run with the training data set and produces a result, which is then compared with the *target*, for each input vector in the training data set. Based on the result of the comparison and the specific learning algorithm being used, the parameters of the model are adjusted. The model fitting can include both [variable selection](https://en.wikipedia.org/wiki/Feature_selection) and parameter [estimation](https://en.wikipedia.org/wiki/Estimation_theory).
- Successively, the fitted model is used to predict the responses for the observations in a second data set called the **validation data set**. The validation data set provides an unbiased evaluation of a model fit on the training data set while tuning the model's [hyperparameters](https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning)) (e.g. the number of hidden unitsâ€”layers and layer widthsâ€”in a neural network  ). Validation datasets can be used for [regularization](https://en.wikipedia.org/wiki/Regularization_(mathematics)) by [early stopping](https://en.wikipedia.org/wiki/Early_stopping) (stopping training when the error on the validation data set increases, as this is a sign of [over-fitting](https://en.wikipedia.org/wiki/Overfitting) to the training data set). This simple procedure is complicated in practice by the fact that the validation dataset's error may fluctuate during training, producing multiple local minima. This complication has led to the creation of many ad-hoc rules for deciding when over-fitting has truly begun.  
- Finally, the **test data set** is a data set used to provide an unbiased evaluation of a *final* model fit on the training data set.  If the data in the test data set has never been used in training (for example in [cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics))), the test data set is also called a **holdout data set**. The term "validation set" is sometimes used instead of "test set" in some literature (e.g., if the original data set was partitioned into only two subsets, the test set might be referred to as the validation set).
- Deciding the sizes and strategies for data set division in training, test and validation sets is very dependent on the problem and data available.
- åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œä¸€é¡¹å¸¸è§çš„ä»»åŠ¡æ˜¯ç ”ç©¶å’Œæ„å»ºèƒ½å¤Ÿå­¦ä¹ å’Œé¢„æµ‹æ•°æ®çš„ç®—æ³•ã€‚è¿™æ ·çš„ç®—æ³•é€šè¿‡ä»è¾“å…¥æ•°æ®ä¸­æ„å»ºæ•°å­¦æ¨¡å‹æ¥è¿›è¡Œæ•°æ®é©±åŠ¨çš„é¢„æµ‹æˆ–å†³ç­–ã€‚
- ç”¨äºæ„å»ºæ¨¡å‹çš„è¾“å…¥æ•°æ®é€šå¸¸è¢«åˆ†æˆå¤šä¸ªæ•°æ®é›†ã€‚
  - ç‰¹åˆ«åœ°ï¼Œ**è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†**é€šå¸¸åœ¨æ¨¡å‹åˆ›å»ºçš„ä¸åŒé˜¶æ®µä½¿ç”¨ã€‚
- æ¨¡å‹æœ€åˆåœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè¿›è¡Œæ‹Ÿåˆï¼Œè¿™æ˜¯ä¸€ç»„ç”¨äºæ‹Ÿåˆæ¨¡å‹å‚æ•°ï¼ˆä¾‹å¦‚ï¼Œäººå·¥ç¥ç»ç½‘ç»œä¸­ç¥ç»å…ƒä¹‹é—´è¿æ¥çš„æƒé‡ï¼‰çš„ç¤ºä¾‹ã€‚æ¨¡å‹ï¼ˆä¾‹å¦‚æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨ï¼‰ä½¿ç”¨ç›‘ç£å­¦ä¹ æ–¹æ³•åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè¿›è¡Œè®­ç»ƒï¼Œä¾‹å¦‚ä½¿ç”¨æ¢¯åº¦ä¸‹é™æˆ–éšæœºæ¢¯åº¦ä¸‹é™ç­‰ä¼˜åŒ–æ–¹æ³•ã€‚
- åœ¨å®è·µä¸­ï¼Œè®­ç»ƒæ•°æ®é›†é€šå¸¸ç”±ä¸€ä¸ªè¾“å…¥å‘é‡ï¼ˆæˆ–æ ‡é‡ï¼‰å’Œç›¸åº”çš„è¾“å‡ºå‘é‡ï¼ˆæˆ–æ ‡é‡ï¼‰æˆå¯¹ç»„æˆï¼Œå…¶ä¸­ç­”æ¡ˆé”®é€šå¸¸ç§°ä¸ºç›®æ ‡ï¼ˆæˆ–æ ‡ç­¾ï¼‰ã€‚å½“å‰æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè¿è¡Œå¹¶äº§ç”Ÿç»“æœï¼Œç„¶åå°†ç»“æœä¸ç›®æ ‡è¿›è¡Œæ¯”è¾ƒã€‚æ ¹æ®æ¯”è¾ƒçš„ç»“æœå’Œä½¿ç”¨çš„å…·ä½“å­¦ä¹ ç®—æ³•ï¼Œæ¨¡å‹å‚æ•°ä¼šè¿›è¡Œè°ƒæ•´ã€‚
- æ¨¡å‹æ‹Ÿåˆå¯ä»¥åŒ…æ‹¬å˜é‡é€‰æ‹©å’Œå‚æ•°ä¼°è®¡ã€‚
- éšåï¼Œæ‹Ÿåˆçš„æ¨¡å‹ç”¨äºé¢„æµ‹ç¬¬äºŒä¸ªæ•°æ®é›†ä¸­çš„è§‚æµ‹ç›¸åº”ï¼Œç§°ä¸º**éªŒè¯æ•°æ®é›†**ã€‚
- éªŒè¯æ•°æ®é›†åœ¨è°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ï¼ˆä¾‹å¦‚ç¥ç»ç½‘ç»œä¸­çš„éšè—å•å…ƒæ•°ã€å±‚æ•°å’Œå±‚å®½ï¼‰æ—¶æä¾›äº†ä¸€ä¸ª**æ— åçš„è¯„ä¼°**ã€‚é€šè¿‡æå‰åœæ­¢ï¼ˆå½“éªŒè¯æ•°æ®é›†ä¸Šçš„é”™è¯¯å¢åŠ æ—¶åœæ­¢è®­ç»ƒï¼Œå› ä¸ºè¿™æ˜¯è¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®é›†çš„ä¿¡å·ï¼‰ï¼ŒéªŒè¯æ•°æ®é›†å¯ä»¥ç”¨äºæ­£åˆ™åŒ–ã€‚
- åœ¨å®è·µä¸­ï¼ŒéªŒè¯æ•°æ®é›†çš„è¯¯å·®å¯èƒ½ä¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ³¢åŠ¨ï¼Œäº§ç”Ÿå¤šä¸ªå±€éƒ¨æœ€å°å€¼ï¼Œè¿™å¢åŠ äº†åˆ¤æ–­è¿‡æ‹Ÿåˆä½•æ—¶çœŸæ­£å¼€å§‹çš„è®¸å¤šä¸´æ—¶è§„åˆ™ã€‚
- æœ€åï¼Œæµ‹è¯•æ•°æ®é›†æ˜¯ç”¨äºåœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè¿›è¡Œæœ€ç»ˆæ¨¡å‹æ‹Ÿåˆçš„**æ— åè¯„ä¼°æ•°æ®é›†**ã€‚å¦‚æœæµ‹è¯•æ•°æ®é›†ä¸­çš„æ•°æ®ä»æœªåœ¨è®­ç»ƒä¸­ä½¿ç”¨è¿‡ï¼ˆä¾‹å¦‚åœ¨äº¤å‰éªŒè¯ä¸­ï¼‰ï¼Œåˆ™æµ‹è¯•æ•°æ®é›†ä¹Ÿç§°ä¸º**ä¿ç•™æ•°æ®é›†**ã€‚
- æœ‰äº›æ–‡çŒ®ä¸­ä½¿ç”¨â€œéªŒè¯é›†â€ä»£æ›¿â€œæµ‹è¯•é›†â€ï¼ˆä¾‹å¦‚ï¼Œå¦‚æœåŸå§‹æ•°æ®é›†è¢«åˆ’åˆ†ä¸ºä»…ä¸¤ä¸ªå­é›†ï¼Œåˆ™<u>æµ‹è¯•é›†å¯èƒ½è¢«ç§°ä¸ºéªŒè¯é›†</u>ï¼‰ã€‚
- ç¡®å®šæ•°æ®é›†åœ¨è®­ç»ƒã€æµ‹è¯•å’ŒéªŒè¯é›†ä¸­çš„å¤§å°å’Œç­–ç•¥éå¸¸<u>ä¾èµ–äºé—®é¢˜å’Œå¯ç”¨æ•°æ®</u>ã€‚

### Training data set

- A training data set is a data set of examples used during the learning process and is used to fit the parameters (e.g., weights) of, for example, a classifier.
- For classification tasks, a supervised learning algorithm looks at the training data set to determine, or learn, the optimal combinations of variables that will generate a good predictive model.[10] The goal is to produce a trained (fitted) model that generalizes well to new, unknown data.[11] The fitted model is evaluated using â€œnewâ€ examples from the held-out datasets (validation and test datasets) to estimate the modelâ€™s accuracy in classifying new data.[5] To reduce the risk of issues such as over-fitting, the examples in the validation and test datasets should not be used to train the model.

- Most approaches that search through training data for empirical relationships tend to overfit the data, meaning that they can identify and exploit apparent relationships in the training data that do not hold in general.
- è®­ç»ƒæ•°æ®é›†æ˜¯åœ¨å­¦ä¹ è¿‡ç¨‹ä¸­ä½¿ç”¨çš„ä¸€ç»„æ ·æœ¬ï¼Œç”¨äºæ‹Ÿåˆåˆ†ç±»å™¨çš„å‚æ•°ï¼ˆä¾‹å¦‚æƒé‡ï¼‰ç­‰ã€‚å¯¹äºåˆ†ç±»ä»»åŠ¡ï¼Œç›‘ç£å­¦ä¹ ç®—æ³•ä¼šæŸ¥çœ‹è®­ç»ƒæ•°æ®é›†ï¼Œä»¥ç¡®å®šæˆ–å­¦ä¹ ç”Ÿæˆè‰¯å¥½é¢„æµ‹æ¨¡å‹çš„æœ€ä½³å˜é‡ç»„åˆã€‚ç›®æ ‡æ˜¯äº§ç”Ÿä¸€ä¸ªé€‚ç”¨äºæ–°çš„æœªçŸ¥æ•°æ®çš„è®­ç»ƒï¼ˆæ‹Ÿåˆï¼‰æ¨¡å‹ã€‚
- æ‹Ÿåˆæ¨¡å‹ä½¿ç”¨æ¥è‡ªä¿ç•™æ•°æ®é›†ï¼ˆéªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ï¼‰çš„â€œæ–°â€ç¤ºä¾‹æ¥è¯„ä¼°å…¶åœ¨åˆ†ç±»æ–°æ•°æ®æ–¹é¢çš„å‡†ç¡®æ€§ã€‚ä¸ºäº†å‡å°‘è¿‡åº¦æ‹Ÿåˆç­‰é—®é¢˜çš„é£é™©ï¼ŒéªŒè¯å’Œæµ‹è¯•æ•°æ®é›†ä¸­çš„ç¤ºä¾‹<u>ä¸åº”è¯¥ç”¨äºè®­ç»ƒæ¨¡å‹</u>ã€‚
- å¤§å¤šæ•°åœ¨è®­ç»ƒæ•°æ®ä¸­å¯»æ‰¾ç»éªŒå…³ç³»çš„æ–¹æ³•å¾€å¾€ä¼šè¿‡åº¦æ‹Ÿåˆæ•°æ®ï¼Œè¿™æ„å‘³ç€å®ƒä»¬å¯èƒ½ä¼šè¯†åˆ«å’Œåˆ©ç”¨è®­ç»ƒæ•°æ®ä¸­çš„è¡¨é¢å…³ç³»ï¼Œè¿™äº›å…³ç³»åœ¨ä¸€èˆ¬æƒ…å†µä¸‹å¹¶ä¸æˆç«‹ã€‚

### Validation data set

A validation data set is a data-set of examples used to tune the hyperparameters (i.e. the architecture) of a classifier. It is sometimes also called the development set or the "dev set".

 An example of a hyperparameter for artificial neural networks includes the number of hidden units in each layer.It, as well as the testing set (as mentioned below), should follow the same probability distribution as the training data set.

In order to avoid overfitting, when any classification parameter needs to be adjusted, it is necessary to have a validation data set in addition to the training and test datasets. For example, if the most suitable classifier for the problem is sought, the training data set is used to train the different candidate classifiers, the validation data set is used to compare their performances and decide which one to take and, finally, the test data set is used to obtain the performance characteristics such as accuracy, sensitivity, specificity, F-measure, and so on. The validation data set functions as a hybrid: it is training data used for testing, but neither as part of the low-level training nor as part of the final testing.

The basic process of using a validation data set for model selection (as part of training data set, validation data set, and test data set) is:

- Since our goal is to find the network having the best performance on new data, the simplest approach to the comparison of different networks is to evaluate the error function using data which is independent of that used for training. Various networks are trained by minimization of an appropriate error function defined with respect to a training data set. The performance of the networks is then compared by evaluating the error function using an independent validation set, and the network having the smallest error with respect to the validation set is selected. This approach is called the hold out method. Since this procedure can itself lead to some overfitting to the validation set, the performance of the selected network should be confirmed by measuring its performance on a third independent set of data called a test set.


- An application of this process is in early stopping, where the candidate models are successive iterations of the same network, and training stops when the error on the validation set grows, choosing the previous model (the one with minimum error).

- éªŒè¯æ•°æ®é›†æ˜¯ç”¨äºè°ƒæ•´åˆ†ç±»å™¨çš„è¶…å‚æ•°ï¼ˆå³æ¶æ„ï¼‰çš„ä¸€ç»„æ ·æœ¬ã€‚å®ƒæœ‰æ—¶ä¹Ÿè¢«ç§°ä¸º**å¼€å‘é›†**æˆ–â€œdevé›†â€ã€‚äººå·¥ç¥ç»ç½‘ç»œçš„ä¸€ä¸ªè¶…å‚æ•°å®ä¾‹æ˜¯æ¯å±‚ä¸­éšè—å•å…ƒçš„æ•°é‡ã€‚å®ƒä»¥åŠæµ‹è¯•æ•°æ®é›†ï¼ˆå¦‚ä¸‹æ‰€è¿°ï¼‰åº”è¯¥éµå¾ªä¸è®­ç»ƒæ•°æ®é›†ç›¸åŒçš„æ¦‚ç‡åˆ†å¸ƒã€‚

- ä¸ºäº†é¿å…è¿‡åº¦æ‹Ÿåˆï¼Œå½“éœ€è¦è°ƒæ•´ä»»ä½•åˆ†ç±»å‚æ•°æ—¶ï¼Œé™¤äº†è®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†å¤–ï¼Œè¿˜éœ€è¦ä¸€ä¸ªéªŒè¯æ•°æ®é›†ã€‚ä¾‹å¦‚ï¼Œå¦‚æœè¦å¯»æ‰¾æœ€é€‚åˆé—®é¢˜çš„åˆ†ç±»å™¨ï¼Œåˆ™ä½¿ç”¨è®­ç»ƒæ•°æ®é›†æ¥è®­ç»ƒä¸åŒçš„å€™é€‰åˆ†ç±»å™¨ï¼Œä½¿ç”¨éªŒè¯æ•°æ®é›†æ¥æ¯”è¾ƒå®ƒä»¬çš„æ€§èƒ½å¹¶å†³å®šé€‰æ‹©å“ªä¸€ä¸ªï¼Œæœ€åä½¿ç”¨æµ‹è¯•æ•°æ®é›†æ¥è·å–æ€§èƒ½ç‰¹å¾ï¼Œå¦‚å‡†ç¡®æ€§ã€çµæ•åº¦ã€ç‰¹å¼‚æ€§ã€F-åº¦é‡ç­‰ã€‚
- éªŒè¯æ•°æ®é›†èµ·åˆ°äº†æ··åˆçš„ä½œç”¨ï¼šå®ƒæ˜¯**ç”¨äºæµ‹è¯•çš„è®­ç»ƒæ•°æ®**ï¼Œä½†æ—¢ä¸æ˜¯ä½çº§è®­ç»ƒçš„ä¸€éƒ¨åˆ†ï¼Œä¹Ÿä¸æ˜¯æœ€ç»ˆæµ‹è¯•çš„ä¸€éƒ¨åˆ†ã€‚
- ä½¿ç”¨éªŒè¯æ•°æ®é›†è¿›è¡Œæ¨¡å‹é€‰æ‹©ï¼ˆä½œä¸ºè®­ç»ƒæ•°æ®é›†ã€éªŒè¯æ•°æ®é›†å’Œæµ‹è¯•æ•°æ®é›†çš„ä¸€éƒ¨åˆ†ï¼‰çš„åŸºæœ¬è¿‡ç¨‹æ˜¯ï¼š
  - ç”±äºæˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ‰¾åˆ°åœ¨æ–°æ•°æ®ä¸Šè¡¨ç°æœ€ä½³çš„ç½‘ç»œï¼Œæ¯”è¾ƒä¸åŒç½‘ç»œçš„æœ€ç®€å•æ–¹æ³•æ˜¯ä½¿ç”¨ç‹¬ç«‹äºè®­ç»ƒæ•°æ®çš„æ•°æ®æ¥è¯„ä¼°è¯¯å·®å‡½æ•°ã€‚ä½¿ç”¨ä¸è®­ç»ƒæ•°æ®é›†ç›¸å…³çš„é€‚å½“è¯¯å·®å‡½æ•°å¯¹å„ç§ç½‘ç»œè¿›è¡Œè®­ç»ƒã€‚
  - ç„¶åé€šè¿‡ä½¿ç”¨ç‹¬ç«‹çš„éªŒè¯é›†æ¥è¯„ä¼°è¯¯å·®å‡½æ•°æ¥æ¯”è¾ƒç½‘ç»œçš„æ€§èƒ½ï¼Œå¹¶é€‰æ‹©ç›¸å¯¹äºéªŒè¯é›†è¯¯å·®æœ€å°çš„ç½‘ç»œã€‚è¿™ç§æ–¹æ³•ç§°ä¸ºç•™å­˜æ³•ã€‚
  - ç”±äºè¿™ä¸ªè¿‡ç¨‹æœ¬èº«å¯èƒ½ä¼šå¯¼è‡´ä¸€äº›è¿‡åº¦æ‹Ÿåˆåˆ°éªŒè¯é›†ï¼Œå› æ­¤åº”è¯¥é€šè¿‡åœ¨ç¬¬ä¸‰ä¸ªç‹¬ç«‹æ•°æ®é›†ä¸Šæµ‹é‡å…¶æ€§èƒ½æ¥ç¡®è®¤æ‰€é€‰ç½‘ç»œçš„æ€§èƒ½ï¼Œè¯¥æ•°æ®é›†ç§°ä¸ºæµ‹è¯•é›†ã€‚

- è¿™ä¸ªè¿‡ç¨‹çš„ä¸€ä¸ªåº”ç”¨æ˜¯æ—©æœŸåœæ­¢ï¼Œå…¶ä¸­å€™é€‰æ¨¡å‹æ˜¯åŒä¸€ç½‘ç»œçš„è¿ç»­è¿­ä»£ï¼Œå½“éªŒè¯é›†ä¸Šçš„è¯¯å·®å¢é•¿æ—¶ï¼Œè®­ç»ƒåœæ­¢ï¼Œé€‰æ‹©å…ˆå‰çš„æ¨¡å‹ï¼ˆå…·æœ‰æœ€å°è¯¯å·®çš„æ¨¡å‹ï¼‰ã€‚

### Test data set

- A test data set is a data set that is independent of the training data set, but that follows the same probability distribution as the training data set. If a model fit to the training data set also fits the test data set well, minimal overfitting has taken place (see figure below). A better fitting of the training data set as opposed to the test data set usually points to over-fitting.
- A test set is therefore a set of examples used only to assess the performance (i.e. generalization) of a fully specified classifier.To do this, the final model is used to predict classifications of examples in the test set. Those predictions are compared to the examples' true classifications to assess the model's accuracy.[10]


- In a scenario where both validation and test datasets are used, the test data set is typically used to assess the final model that is selected during the validation process. In the case where the original data set is partitioned into two subsets (training and test datasets), the test data set might assess the model only once (e.g., in the holdout method).[14] Note that some sources advise against such a method.[11] However, when using a method such as cross-validation, two partitions can be sufficient and effective since results are averaged after repeated rounds of model training and testing to help reduce bias and variability.

![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/db8df70538784224a92286b990687255.png)

- æµ‹è¯•æ•°æ®é›†æ˜¯ä¸€ç»„ä¸è®­ç»ƒæ•°æ®é›†ç‹¬ç«‹çš„æ•°æ®é›†ï¼Œä½†éµå¾ªä¸è®­ç»ƒæ•°æ®é›†ç›¸åŒçš„æ¦‚ç‡åˆ†å¸ƒã€‚å¦‚æœé€‚åˆè®­ç»ƒæ•°æ®é›†çš„æ¨¡å‹ä¹Ÿå¾ˆå¥½åœ°é€‚åˆæµ‹è¯•æ•°æ®é›†ï¼Œåˆ™å‘ç”Ÿçš„è¿‡åº¦æ‹Ÿåˆå¾ˆå°ã€‚ç›¸æ¯”äºæµ‹è¯•æ•°æ®é›†ï¼Œæ›´å¥½åœ°æ‹Ÿåˆè®­ç»ƒæ•°æ®é›†é€šå¸¸æŒ‡å‘è¿‡åº¦æ‹Ÿåˆã€‚
- å› æ­¤ï¼Œæµ‹è¯•é›†æ˜¯ä»…ç”¨äºè¯„ä¼°å®Œå…¨æŒ‡å®šåˆ†ç±»å™¨æ€§èƒ½ï¼ˆå³æ³›åŒ–èƒ½åŠ›ï¼‰çš„ä¸€ç»„æ ·æœ¬ã€‚ä¸ºæ­¤ï¼Œä½¿ç”¨æœ€ç»ˆæ¨¡å‹æ¥é¢„æµ‹æµ‹è¯•é›†ä¸­ç¤ºä¾‹çš„åˆ†ç±»ã€‚å°†è¿™äº›é¢„æµ‹ä¸ç¤ºä¾‹çš„çœŸå®åˆ†ç±»è¿›è¡Œæ¯”è¾ƒä»¥è¯„ä¼°æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚
- åœ¨ä½¿ç”¨éªŒè¯å’Œæµ‹è¯•æ•°æ®é›†çš„æƒ…å†µä¸‹ï¼Œé€šå¸¸ä½¿ç”¨æµ‹è¯•æ•°æ®é›†æ¥<u>è¯„ä¼°åœ¨éªŒè¯è¿‡ç¨‹ä¸­é€‰æ‹©çš„æœ€ç»ˆæ¨¡å‹</u>ã€‚åœ¨å°†åŸå§‹æ•°æ®é›†åˆ†ä¸ºä¸¤ä¸ªå­é›†ï¼ˆè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†ï¼‰çš„æƒ…å†µä¸‹ï¼Œæµ‹è¯•æ•°æ®é›†å¯èƒ½ä»…è¯„ä¼°æ¨¡å‹ä¸€æ¬¡ï¼ˆä¾‹å¦‚ï¼Œåœ¨ç•™å­˜æ³•ä¸­ï¼‰ã€‚è¯·æ³¨æ„ï¼Œä¸€äº›æ¥æºä¸å»ºè®®ä½¿ç”¨è¿™ç§æ–¹æ³•ã€‚
- ç„¶è€Œï¼Œ<u>åœ¨ä½¿ç”¨äº¤å‰éªŒè¯ç­‰æ–¹æ³•æ—¶ï¼Œä¸¤ä¸ªåˆ†åŒºå¯èƒ½è¶³å¤Ÿæœ‰æ•ˆï¼Œå› ä¸ºé€šè¿‡å¤šæ¬¡æ¨¡å‹è®­ç»ƒå’Œæµ‹è¯•åï¼Œç»“æœä¼šå¹³å‡ä»¥å¸®åŠ©å‡å°‘åå·®å’Œå˜å¼‚ã€‚</u>

### æ— åçš„è¯„ä¼°

åœ¨æœºå™¨å­¦ä¹ é¢†åŸŸï¼Œæ— åçš„è¯„ä¼°æŒ‡çš„æ˜¯é€šè¿‡ä½¿ç”¨ç‹¬ç«‹äºè®­ç»ƒæ•°æ®é›†çš„æ•°æ®é›†æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚è¿™æ˜¯å› ä¸ºåœ¨è®­ç»ƒæ¨¡å‹æ—¶ï¼Œæ¨¡å‹å¯èƒ½ä¼šè¿‡åº¦æ‹Ÿåˆè®­ç»ƒæ•°æ®é›†ï¼Œå¯¼è‡´æ¨¡å‹çš„é¢„æµ‹æ€§èƒ½åœ¨è®­ç»ƒæ•°æ®é›†ä¸Šå¾ˆå¥½ï¼Œä½†åœ¨æ–°æ•°æ®ä¸Šè¡¨ç°ä¸ä½³ã€‚å› æ­¤ï¼Œéœ€è¦ä½¿ç”¨ä¸€ä¸ªç‹¬ç«‹çš„æ•°æ®é›†æ¥è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ï¼Œä»¥ä¾¿æ›´å‡†ç¡®åœ°äº†è§£æ¨¡å‹åœ¨æ–°æ•°æ®ä¸Šçš„æ€§èƒ½ã€‚

è¯„ä¼°æ¨¡å‹æ—¶ï¼Œé€šå¸¸ä¼šå°†æ•°æ®é›†åˆ†æˆä¸‰ä¸ªéƒ¨åˆ†ï¼šè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ã€‚è®­ç»ƒé›†ç”¨äºè®­ç»ƒæ¨¡å‹ï¼ŒéªŒè¯é›†ç”¨äºè°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ï¼Œä»¥ä¾¿è·å¾—æ›´å¥½çš„æ€§èƒ½ï¼Œå¹¶é€‰æ‹©æœ€ç»ˆçš„æ¨¡å‹ã€‚æœ€åï¼Œæµ‹è¯•é›†ç”¨äºè¯„ä¼°æœ€ç»ˆæ¨¡å‹çš„æ€§èƒ½ï¼Œä»¥ä¾¿è¯„ä¼°æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›å’Œé¢„æµ‹æ–°æ•°æ®çš„èƒ½åŠ›ã€‚

é€šè¿‡ä½¿ç”¨ç‹¬ç«‹äºè®­ç»ƒæ•°æ®é›†çš„æµ‹è¯•æ•°æ®é›†ï¼Œå¯ä»¥é¿å…åœ¨è¯„ä¼°æ¨¡å‹æ€§èƒ½æ—¶å‡ºç°ä»»ä½•åå·®æˆ–ä¸å‡†ç¡®çš„æƒ…å†µã€‚å› æ­¤ï¼Œæ— åçš„è¯„ä¼°æ˜¯ç¡®ä¿æ¨¡å‹å‡†ç¡®æ€§å’Œå¯é æ€§çš„å…³é”®æ­¥éª¤ã€‚

### æµ‹è¯•é›†å’Œè®­ç»ƒé›†

- åœ¨æœºå™¨å­¦ä¹ ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸å°†æ•°æ®é›†åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸‰éƒ¨åˆ†ã€‚
- å…¶ä¸­ï¼Œè®­ç»ƒé›†ç”¨äºè®­ç»ƒæ¨¡å‹ï¼ŒéªŒè¯é›†ç”¨äºè°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ï¼Œæµ‹è¯•é›†ç”¨äºè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚

éªŒè¯é›†å’Œæµ‹è¯•é›†éƒ½ç”¨äº**è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½**ï¼Œä½†å®ƒä»¬ä¹‹é—´æœ‰ä¸€äº›åŒºåˆ«ï¼š

1. **ç”¨é€”ä¸åŒï¼š** éªŒè¯é›†ç”¨äºè°ƒæ•´æ¨¡å‹çš„è¶…å‚æ•°ï¼Œä¾‹å¦‚æ­£åˆ™åŒ–ç³»æ•°ã€å­¦ä¹ ç‡ç­‰ï¼Œä»¥æœ€å¤§åŒ–æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„æ€§èƒ½ã€‚æµ‹è¯•é›†ç”¨äºæœ€ç»ˆè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œä»¥æ£€éªŒæ¨¡å‹åœ¨çœŸå®ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚
2. **æ•°æ®é›†ä¸åŒï¼š** éªŒè¯é›†å’Œæµ‹è¯•é›†é€šå¸¸æ¥è‡ªåŒä¸€ä¸ªæ•°æ®é›†ï¼Œä½†æ˜¯å®ƒä»¬æ˜¯äº’æ–¥çš„ï¼Œå³éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸é‡å ï¼Œä»¥ç¡®ä¿æ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šè¿›è¡Œè¯„ä¼°ã€‚
   - éªŒè¯é›†é€šå¸¸æ¯”æµ‹è¯•é›†å°ï¼Œå› ä¸ºå®ƒåªç”¨äºè¶…å‚æ•°è°ƒæ•´ï¼Œè€Œæµ‹è¯•é›†éœ€è¦æ›´å¤šçš„æ•°æ®æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚
3. **ä½¿ç”¨æ–¹å¼ä¸åŒï¼š** éªŒè¯é›†å’Œæµ‹è¯•é›†åœ¨æ¨¡å‹è®­ç»ƒè¿‡ç¨‹ä¸­çš„ä½¿ç”¨æ–¹å¼ä¹Ÿä¸åŒã€‚
   - åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼ŒéªŒè¯é›†é€šå¸¸ç”¨äºåœ¨æ¯ä¸ªè®­ç»ƒå‘¨æœŸç»“æŸåè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶æ ¹æ®æ€§èƒ½æŒ‡æ ‡è°ƒæ•´è¶…å‚æ•°ã€‚
   - è€Œæµ‹è¯•é›†é€šå¸¸åœ¨æ¨¡å‹è®­ç»ƒå®Œæˆä¹‹åä½¿ç”¨ï¼Œä»¥æ£€éªŒæ¨¡å‹åœ¨æœªè§è¿‡çš„æ•°æ®ä¸Šçš„æ€§èƒ½ã€‚

ä»¥ä¸‹æ˜¯ä¸€ä¸ªåˆ†å‰²æ•°æ®é›†çš„ä¾‹å­ï¼š

```python
from sklearn.model_selection import train_test_split

# å‡è®¾Xå’Œyåˆ†åˆ«æ˜¯ç‰¹å¾çŸ©é˜µå’Œæ ‡ç­¾
X_trainval, X_test, y_trainval, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# å°†è®­ç»ƒé›†å†åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†
X_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.2, random_state=42)
```

- åœ¨ä¸Šé¢çš„ä»£ç ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨`train_test_split`å‡½æ•°å°†åŸå§‹æ•°æ®é›†åˆ†å‰²ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†ä¸­çš„20%ä½œä¸ºæµ‹è¯•é›†ï¼Œå‰©ä½™çš„80%ä½œä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç»„åˆï¼Œå…¶ä¸­è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„æ¯”ä¾‹ä¸º64%å’Œ16%ã€‚
- æ¥ç€ï¼Œæˆ‘ä»¬å°†è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç»„åˆå†æ¬¡ä½¿ç”¨`train_test_split`å‡½æ•°åˆ†å‰²ä¸ºè®­ç»ƒé›†å’ŒéªŒè¯é›†ã€‚å…·ä½“åœ°ï¼Œæˆ‘ä»¬å°†è®­ç»ƒé›†å’ŒéªŒè¯é›†çš„ç»„åˆä¸­çš„20%ä½œä¸ºéªŒè¯é›†ï¼Œå‰©ä½™çš„80%ä½œä¸ºè®­ç»ƒé›†ã€‚
- éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬ä½¿ç”¨`random_state`å‚æ•°è®¾ç½®éšæœºæ•°ç§å­ï¼Œä»¥ç¡®ä¿æ¯æ¬¡è¿è¡Œä»£ç æ—¶å¾—åˆ°ç›¸åŒçš„ç»“æœã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥ä½¿ç”¨`stratify`å‚æ•°æ¥ä¿è¯è®­ç»ƒé›†ã€éªŒè¯é›†å’Œæµ‹è¯•é›†ä¸­çš„æ ‡ç­¾åˆ†å¸ƒç›¸åŒï¼Œä»¥é¿å…å› æ ‡ç­¾åˆ†å¸ƒä¸å‡åŒ€è€Œå¯¼è‡´çš„æ¨¡å‹æ€§èƒ½è¯„ä¼°ä¸å‡†ç¡®çš„é—®é¢˜ã€‚
- éœ€è¦æ ¹æ®å…·ä½“æƒ…å†µæ¥å†³å®šåˆ†å‰²æ•°æ®é›†çš„æ¯”ä¾‹å’Œéšæœºæ•°ç§å­ç­‰å‚æ•°ã€‚

### sklearnä¸­çš„æ¨¡å‹è¯„ä¼°

- Fitting a model to some data does not entail that it will predict well on unseen data.
- This needs to be directly evaluated. We have just seen the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) helper that splits a dataset into train and test sets, but `scikit-learn` provides many other tools for model evaluation, in particular for [cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation).
- We here briefly show how to perform a 5-fold cross-validation procedure, using the [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) helper. 
  - Note that it is also possible to manually iterate over the folds, use different data splitting strategies, and use custom scoring functions. 
  - Please refer to our [User Guide](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation) for more details:

### demo

- ```python
  from sklearn.datasets import make_regression
  from sklearn.linear_model import LinearRegression
  from sklearn.model_selection import cross_validate
  
  X, y = make_regression(n_samples=1000, noise=50,random_state=0)
  # é»˜è®¤ç»´æ•°ç»´100
  # X.shape,y.shape=1000,100
  
  lr = LinearRegression()
  result = cross_validate(lr, X, y)  # defaults to 5-fold CV
  result['test_score']  # r_squared score is high because dataset is easy
  result = cross_validate(lr, X, y, cv=5, return_train_score=True)
  for v in result.items():
      print(v)
  # print(result)
  ```

  - ```bash
    0.9736842105263158
    ('fit_time', array([0.01099563, 0.00600886, 0.00399899, 0.00663686, 0.00399613]))
    ('score_time', array([0.00099921, 0.0009954 , 0.00100064, 0.        , 0.00100303]))
    ('test_score', array([0.90468242, 0.8604173 , 0.89786489, 0.9145173 , 0.89278255]))
    ('train_score', array([0.92046141, 0.92835467, 0.92186638, 0.91778192, 0.92238646]))
    ```

  - å¦‚æœè®¾ç½®`noise=0`,é‡æ–°è¿è¡Œ,ç»“æœå½¢å¦‚

  - ```bash
    ('fit_time', array([0.00899696, 0.00603986, 0.00499964, 0.07801867, 0.0049994 ]))
    ('score_time', array([0.00099921, 0.        , 0.0010035 , 0.00197124, 0.00100207]))
    ('test_score', array([1., 1., 1., 1., 1.]))
    ('train_score', array([1., 1., 1., 1., 1.]))
    ```

  - åœ¨äººå·¥å›å½’æ•°æ®é›†ä¸­ï¼Œ`noise`å‚æ•°ç”¨äºæ§åˆ¶ç›®æ ‡å˜é‡ä¸­å™ªå£°çš„å¼ºåº¦ã€‚å…·ä½“æ¥è¯´ï¼Œå½“æˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªäººå·¥å›å½’æ•°æ®é›†æ—¶ï¼Œæˆ‘ä»¬ä¼šæŒ‰ç…§ä¸€å®šçš„è§„åˆ™ç”Ÿæˆè‡ªå˜é‡`X`å’Œå› å˜é‡`y`ï¼Œå…¶ä¸­`y`çš„å€¼æ˜¯æ ¹æ®æŸç§å‡½æ•°å…³ç³»è®¡ç®—å‡ºæ¥çš„ã€‚å¦‚æœ`noise`å‚æ•°ä¸º0ï¼Œåˆ™ç”Ÿæˆçš„`y`å€¼å®Œå…¨ç¬¦åˆè¿™ç§å‡½æ•°å…³ç³»ï¼Œæ²¡æœ‰ä»»ä½•éšæœºå™ªå£°ã€‚è€Œå½“`noise`å‚æ•°å¤§äº0æ—¶ï¼Œç”Ÿæˆçš„`y`å€¼ä¼šå—åˆ°ä¸€å®šç¨‹åº¦çš„éšæœºå™ªå£°çš„å½±å“ã€‚

    åœ¨Scikit-learnä¸­ï¼Œ`noise`å‚æ•°çš„å€¼è¢«è§£é‡Šä¸ºç”Ÿæˆçš„æ•°æ®é›†ä¸­ç›®æ ‡å˜é‡ï¼ˆå³`y`ï¼‰çš„æ ‡å‡†å·®ã€‚å…·ä½“æ¥è¯´ï¼Œå½“`noise`å‚æ•°ä¸º0æ—¶ï¼Œç”Ÿæˆçš„æ•°æ®é›†ä¸­ç›®æ ‡å˜é‡çš„æ ‡å‡†å·®ä¸º0ï¼Œå³æ‰€æœ‰çš„ç›®æ ‡å˜é‡å€¼å®Œå…¨ç¬¦åˆå‡½æ•°å…³ç³»ï¼›è€Œå½“`noise`å‚æ•°ä¸ä¸º0æ—¶ï¼Œç”Ÿæˆçš„æ•°æ®é›†ä¸­ç›®æ ‡å˜é‡çš„æ ‡å‡†å·®å°†ä¼šå¤§äº0ï¼Œå³ç›®æ ‡å˜é‡å€¼ä¸å†å®Œå…¨ç¬¦åˆå‡½æ•°å…³ç³»ï¼Œè€Œæ˜¯å—åˆ°ä¸€å®šç¨‹åº¦çš„éšæœºå™ªå£°çš„å½±å“ã€‚

    éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œ`noise`å‚æ•°åªå½±å“ç”Ÿæˆçš„æ•°æ®é›†ä¸­ç›®æ ‡å˜é‡çš„éšæœºå™ªå£°ï¼Œè€Œä¸å½±å“è‡ªå˜é‡ã€‚å› æ­¤ï¼Œå½“æˆ‘ä»¬ç”Ÿæˆäººå·¥å›å½’æ•°æ®é›†æ—¶ï¼Œå¦‚æœéœ€è¦ä½¿æ•°æ®é›†æ›´åŠ çœŸå®ï¼Œå¯ä»¥å¢åŠ `noise`å‚æ•°çš„å€¼ï¼›åä¹‹ï¼Œå¦‚æœéœ€è¦ä½¿æ•°æ®é›†æ›´åŠ è§„å¾‹ï¼Œå¯ä»¥å°†`noise`å‚æ•°è®¾ç½®ä¸ºè¾ƒå°çš„å€¼æˆ–è€…0ã€‚

- è¿™æ®µä»£ç ä½¿ç”¨äº†Scikit-learnåº“ä¸­çš„`make_regression`å‡½æ•°ç”Ÿæˆä¸€ä¸ªåŒ…å«1000ä¸ªæ ·æœ¬çš„å›å½’æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹å¯¹æ•°æ®é›†è¿›è¡Œæ‹Ÿåˆå’Œè¯„ä¼°ã€‚


- å…·ä½“æ¥è¯´ï¼Œè¿™æ®µä»£ç çš„åŠŸèƒ½å¦‚ä¸‹ï¼š

  1. ä»Scikit-learnåº“ä¸­å¯¼å…¥`make_regression`å‡½æ•°ã€`LinearRegression`æ¨¡å‹å’Œ`cross_validate`å‡½æ•°ã€‚
  2. ä½¿ç”¨`make_regression`å‡½æ•°ç”Ÿæˆä¸€ä¸ªåŒ…å«1000ä¸ªæ ·æœ¬çš„å›å½’æ•°æ®é›†ï¼Œå…¶ä¸­`n_samples=1000`è¡¨ç¤ºæ•°æ®é›†ä¸­åŒ…å«1000ä¸ªæ ·æœ¬ï¼Œ`random_state=0`è¡¨ç¤ºä½¿ç”¨ç›¸åŒçš„éšæœºç§å­ç”Ÿæˆæ•°æ®é›†ï¼Œä»¥ç¡®ä¿ç»“æœçš„å¯é‡å¤æ€§ã€‚
  3. åˆ›å»ºä¸€ä¸ªçº¿æ€§å›å½’æ¨¡å‹ï¼Œå¹¶å°†å…¶èµ‹å€¼ç»™å˜é‡`lr`ã€‚
  4. ä½¿ç”¨`cross_validate`å‡½æ•°å¯¹çº¿æ€§å›å½’æ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯ï¼Œå…¶ä¸­`X`å’Œ`y`åˆ†åˆ«è¡¨ç¤ºæ•°æ®é›†çš„è‡ªå˜é‡å’Œå› å˜é‡ï¼Œ`result`ä¿å­˜äº†äº¤å‰éªŒè¯çš„ç»“æœã€‚
  5. è¾“å‡ºäº¤å‰éªŒè¯çš„æµ‹è¯•é›†å¾—åˆ†ï¼Œå…¶ä¸­`result['test_score']`è¡¨ç¤ºæµ‹è¯•é›†å¾—åˆ†ï¼Œå› ä¸ºæ•°æ®é›†æ¯”è¾ƒç®€å•ï¼Œæ‰€ä»¥å¾—åˆ†æ¯”è¾ƒé«˜ï¼Œé€šå¸¸ä½¿ç”¨Rå¹³æ–¹ä½œä¸ºè¯„ä¼°æŒ‡æ ‡ã€‚



## äº¤å‰éªŒè¯

### sklearnä¸­çš„äº¤å‰éªŒè¯

- äº¤å‰éªŒè¯å™¨@cross-validator@cross-validation-iterators

- [ cross-validation-iterators@Cross-validation: evaluating estimator performance â€” scikit-learn documentation](https://scikit-learn.org/stable/modules/cross_validation.html#cross-validation-iterators)

### ç‹¬ç«‹åŒåˆ†å¸ƒå‡è®¾

- Assuming that some data is **Independent and Identically Distributed** (i.i.d.) is making the assumption that all samples stem from the same generative process and that the generative process is assumed to have no memory of past generated samples.

  The following cross-validators can be used in such cases.

- Note

  While i.i.d. data is a common assumption in machine learning theory, it rarely holds in practice. If one knows that the samples have been generated using a time-dependent process, it is safer to use a [time-series aware cross-validation scheme](https://scikit-learn.org/stable/modules/cross_validation.html#timeseries-cv). Similarly, if we know that the generative process has a group structure (samples collected from different subjects, experiments, measurement devices), it is safer to use [group-wise cross-validation](https://scikit-learn.org/stable/modules/cross_validation.html#group-cv).

- å‡è®¾ä¸€äº›æ•°æ®æ˜¯ç‹¬ç«‹åŒåˆ†å¸ƒçš„ï¼ˆi.i.d.ï¼‰ï¼Œå°±æ„å‘³ç€è¿™äº›æ ·æœ¬éƒ½æ¥è‡ªåŒä¸€ä¸ªç”Ÿæˆè¿‡ç¨‹ï¼Œå¹¶ä¸”ç”Ÿæˆè¿‡ç¨‹ä¸ä¼šå—åˆ°ä¹‹å‰ç”Ÿæˆæ ·æœ¬çš„å½±å“ã€‚

  åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå¯ä»¥ä½¿ç”¨ä»¥ä¸‹äº¤å‰éªŒè¯å™¨ã€‚

  éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè™½ç„¶i.i.d.æ•°æ®æ˜¯æœºå™¨å­¦ä¹ ç†è®ºä¸­å¸¸è§çš„å‡è®¾ï¼Œä½†**åœ¨å®è·µä¸­å¾ˆå°‘æˆç«‹**ã€‚

  å¦‚æœçŸ¥é“æ ·æœ¬æ˜¯ä½¿ç”¨æ—¶é—´ç›¸å…³çš„è¿‡ç¨‹ç”Ÿæˆçš„ï¼Œæœ€å¥½ä½¿ç”¨æ—¶é—´åºåˆ—æ„ŸçŸ¥çš„äº¤å‰éªŒè¯æ–¹æ¡ˆã€‚åŒæ ·ï¼Œå¦‚æœæˆ‘ä»¬çŸ¥é“ç”Ÿæˆè¿‡ç¨‹å…·æœ‰åˆ†ç»„ç»“æ„ï¼ˆæ ·æœ¬æ¥è‡ªä¸åŒçš„å—è¯•è€…ã€å®éªŒã€æµ‹é‡è®¾å¤‡ï¼‰ï¼Œåˆ™æœ€å¥½ä½¿ç”¨åŸºäºç»„çš„äº¤å‰éªŒè¯ã€‚

### è¯„ä¼°å®éªŒæ–¹æ³•ğŸˆæµç¨‹

- Learning the parameters of a prediction function and testing it on the same data is a methodological mistake: a model that would just repeat the labels of the samples that it has just seen would have a perfect score but would fail to predict anything useful on yet-unseen data. This situation is called **overfitting**. To avoid it, it is common practice when performing a (supervised) machine learning experiment to hold out part of the available data as a **test set** `X_test, y_test`. Note that the word â€œexperimentâ€ is not intended to denote academic use only, because even in commercial settings machine learning usually starts out experimentally. Here is a flowchart of typical cross validation workflow in model training. 

- The best parameters can be determined by [grid search](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) techniques.

- ä¸‹é¢æ˜¯ä¸€ä¸ªå…¸å‹çš„äº¤å‰éªŒè¯å·¥ä½œæµç¨‹çš„æµç¨‹å›¾ï¼Œç”¨äºæ¨¡å‹è®­ç»ƒã€‚

  - æœ€ä½³å‚æ•°å¯ä»¥é€šè¿‡ç½‘æ ¼æœç´¢æŠ€æœ¯ç¡®å®šã€‚

  - ![åœ¨è¿™é‡Œæ’å…¥å›¾ç‰‡æè¿°](https://img-blog.csdnimg.cn/47bca69a22454e4795b6867754e516c9.png)

- In scikit-learn a random split into training and test sets can be quickly computed with the [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) helper function. Letâ€™s load the iris data set to fit a linear support vector machine on it:

- åœ¨åŒä¸€æ•°æ®ä¸Šå­¦ä¹ é¢„æµ‹å‡½æ•°çš„å‚æ•°å¹¶å¯¹å…¶è¿›è¡Œæµ‹è¯•æ˜¯ä¸€ç§æ–¹æ³•è®ºä¸Šçš„é”™è¯¯ï¼š

  - ä¸€ä¸ªä»…é‡å¤åˆšåˆšçœ‹åˆ°çš„æ ·æœ¬æ ‡ç­¾çš„æ¨¡å‹å°†å…·æœ‰å®Œç¾çš„åˆ†æ•°ï¼Œä½†å°†æ— æ³•é¢„æµ‹åœ¨å°šæœªçœ‹åˆ°çš„æ•°æ®ä¸Šçš„ä»»ä½•æœ‰ç”¨ä¿¡æ¯ã€‚è¿™ç§æƒ…å†µè¢«ç§°ä¸ºè¿‡åº¦æ‹Ÿåˆã€‚
  - ä¸ºäº†é¿å…è¿™ç§æƒ…å†µï¼Œåœ¨è¿›è¡Œï¼ˆç›‘ç£ï¼‰æœºå™¨å­¦ä¹ å®éªŒæ—¶ï¼Œé€šå¸¸ä¼šä¿ç•™éƒ¨åˆ†å¯ç”¨æ•°æ®ä½œä¸ºæµ‹è¯•é›†`X_testï¼Œy_test`ã€‚
  - éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œâ€œå®éªŒâ€è¿™ä¸ªè¯ä¸ä»…ä»…æ˜¯æŒ‡å­¦æœ¯ç”¨é€”ï¼Œå› ä¸ºå³ä½¿åœ¨å•†ä¸šç¯å¢ƒä¸­ï¼Œæœºå™¨å­¦ä¹ é€šå¸¸ä¹Ÿæ˜¯ä»å®éªŒå¼€å§‹çš„ã€‚

- åœ¨scikit-learnä¸­ï¼Œå¯ä»¥ä½¿ç”¨train_test_splitè¾…åŠ©å‡½æ•°å¿«é€Ÿè®¡ç®—è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„éšæœºæ‹†åˆ†ã€‚

- è®©æˆ‘ä»¬åŠ è½½é¸¢å°¾èŠ±æ•°æ®é›†ï¼Œå¯¹å…¶è¿›è¡Œçº¿æ€§æ”¯æŒå‘é‡æœºçš„æ‹Ÿåˆï¼š

  - ```python
    import numpy as np
    from sklearn.model_selection import train_test_split
    from sklearn import datasets
    from sklearn import svm
    
    X, y = datasets.load_iris(return_X_y=True)
    X.shape, y.shape
    print('X.shape, y.shape: ', X.shape, y.shape)
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.4, random_state=0)
    
    X_train.shape, y_train.shape
    print('X_train.shape, y_train.shape: ', X_train.shape, y_train.shape)
    
    X_test.shape, y_test.shape
    print('X_test.shape, y_test.shape: ', X_test.shape, y_test.shape)
    
    
    clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)
    clf.score(X_test, y_test)
    ```

  - ```bash
    X.shape, y.shape:  (150, 4) (150,)
    X_train.shape, y_train.shape:  (90, 4) (90,)
    X_test.shape, y_test.shape:  (60, 4) (60,)
    0.9666666666666667
    ```

### æé«˜æ¨¡å‹è¯„ä¼°çš„å‡†ç¡®æ€§:

- When evaluating different settings ("hyperparameters")for estimators, such as the c setting that must be manually set for an SVMthere is til a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. Thisway, knowledge about the test set can "leak" into the model and evaluation metics no longer report on generalization performance.
- To solve this problem, yet another part of the dataset can be held out as a so-called "validation set : training proceeds on the train-ing set after which evaluation is done on the validation set, and when the experiment seems to be successful final evaluation can bedone on the test set.
- However, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for learn-ing the model and the results can depend on a particular random choice for the pair of (train, validation) sets.
- A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation,but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into ksmaller sets (other approaches are described below, but generally follow the same principles).The following procedure is followedfor each of the k "folds":
  . A model is trained using k - 1 of the folds as training data;
   the resuting model is validated on the remaining part of the data (i.e. it is used as a test set to compute a performance measuresuch as accuracy).
  The performance measure reported by k-fold cross-validation is then the average of the values computed in the loop.This approachcan be computationally expensive, but does not waste too much data (as is the case when fixing an arbitrary validation set, which isa major advantage in problems such as inverse inference where the number of samples is very small.
- åœ¨è¯„ä¼°ä¼°è®¡å™¨çš„ä¸åŒè®¾ç½®ï¼ˆâ€œè¶…å‚æ•°â€ï¼‰æ—¶ï¼Œä»¥SVMä¸ºä¾‹,å¿…é¡»æ‰‹åŠ¨è®¾ç½®çš„SVMä¸­çš„cè®¾ç½®ï¼Œå­˜åœ¨è¿‡åº¦æ‹Ÿåˆæµ‹è¯•é›†çš„é£é™©ï¼Œå› ä¸ºå‚æ•°å¯ä»¥è°ƒæ•´ç›´åˆ°ä¼°è®¡å™¨è¡¨ç°æœ€ä½³ã€‚
- è¿™æ ·ï¼Œå…³äºæµ‹è¯•é›†çš„çŸ¥è¯†å¯ä»¥â€œ<u>**æ³„æ¼**</u>â€åˆ°æ¨¡å‹ä¸­ï¼Œè¯„ä¼°æŒ‡æ ‡ä¸å†æŠ¥å‘Šæ³›åŒ–æ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ•°æ®é›†çš„å¦ä¸€éƒ¨åˆ†å¯ä»¥ä½œä¸ºæ‰€è°“çš„â€œéªŒè¯é›†â€ä¿ç•™ï¼š
  - è®­ç»ƒåœ¨è®­ç»ƒé›†ä¸Šè¿›è¡Œï¼Œä¹‹ååœ¨éªŒè¯é›†ä¸Šè¿›è¡Œè¯„ä¼°
  - å½“å®éªŒä¼¼ä¹æˆåŠŸæ—¶ï¼Œæœ€ç»ˆè¯„ä¼°å¯ä»¥åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œã€‚
- ç„¶è€Œï¼Œé€šè¿‡å°†å¯ç”¨æ•°æ®åˆ†æˆä¸‰éƒ¨åˆ†ï¼Œæˆ‘ä»¬å¤§å¤§å‡å°‘äº†å¯ç”¨äºå­¦ä¹ æ¨¡å‹çš„æ ·æœ¬æ•°é‡ï¼Œå¹¶ä¸”ç»“æœå¯èƒ½å–å†³äºå¯¹ï¼ˆè®­ç»ƒï¼ŒéªŒè¯ï¼‰é›†å¯¹çš„ç‰¹å®šéšæœºé€‰æ‹©ã€‚
- è§£å†³è¿™ä¸ªé—®é¢˜çš„æ–¹æ³•æ˜¯ä¸€ç§ç§°ä¸ºäº¤å‰éªŒè¯ï¼ˆCVï¼‰çš„è¿‡ç¨‹ã€‚åœ¨k-fold CVä¸­ï¼Œè®­ç»ƒé›†è¢«åˆ†æˆkä¸ªå°é›†åˆã€‚æ¨¡å‹åœ¨k-1ä¸ªé›†åˆä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åœ¨å‰©ä½™çš„é›†åˆä¸Šè¿›è¡ŒéªŒè¯ã€‚
- è¿™ä¸ªè¿‡ç¨‹é‡å¤kæ¬¡ï¼Œæ¯ä¸ªé›†åˆéƒ½æ›¾ç»ä½œä¸ºéªŒè¯é›†ã€‚ k-foldäº¤å‰éªŒè¯æŠ¥å‘Šçš„æ€§èƒ½åº¦é‡æ˜¯æ¯æ¬¡å¾ªç¯ä¸­è®¡ç®—çš„å€¼çš„å¹³å‡å€¼ã€‚
- äº¤å‰éªŒè¯å¯èƒ½è®¡ç®—é‡è¾ƒå¤§ï¼Œä½†ä¸ä¼šæµªè´¹å¤ªå¤šæ•°æ®ï¼Œå¹¶ä¸”åœ¨æ ·æœ¬æ•°é‡å¾ˆå°çš„é—®é¢˜ä¸­å…·æœ‰å¾ˆå¤§ä¼˜åŠ¿ï¼Œè¿™ç§ä¼˜åŠ¿ä½“ç°åœ¨ä¿®æ­£ä»»æ„éªŒè¯é›†æ—¶ï¼ˆè¿™ç§æƒ…å†µä¸‹ä¼šæµªè´¹æ•°æ®ï¼‰ã€‚

## å…·ä½“çš„è¯„ä¼°æ–¹æ³•(äº¤å‰éªŒè¯å®éªŒæ–¹æ³•)ğŸˆ

- ä»¥ä¸‹äº¤å‰éªŒè¯å™¨éƒ½éƒ½æ˜¯åŸºäºç´¢å¼•æ¥åˆ’åˆ†çš„,è¿™ç§åšæ³•æœ‰åˆ©äºåˆ’åˆ†æ•°æ®é›†çš„çµæ´»æ€§
- äº¤å‰éªŒè¯å™¨çš„ä¸éœ€è¦ç”¨æˆ·æä¾›æ•°æ®é›†,åªéœ€è¦å‘Šè¯‰ç›¸åº”çš„æ„é€ å‡½æ•°çš„åˆ’åˆ†ä¿¡æ¯(ä¾‹å¦‚,æŠ˜å æ•°,é‡å¤æ•°ç­‰)
- å¯é€šè¿‡è°ƒç”¨äº¤å‰éªŒè¯å™¨å®ä¾‹çš„splitæ–¹æ³•æ¥æŸ¥çœ‹kæ¬¡åˆ’åˆ†çš„(**ç´¢å¼•**åºåˆ—çš„åˆ’åˆ†)
- äº¤å‰éªŒè¯å™¨é€šå¸¸é…åˆ`sklearn.model_selection`æ¨¡å—ä¸­çš„`cross_validate`å’Œ`cross_val_score`ä½¿ç”¨,è€Œè¾ƒå°‘å•ç‹¬ä½¿ç”¨.(äº¤å‰éªŒè¯å™¨ä¹Ÿæ˜¯`sklearn.model_selection`æ¨¡å—ä¸‹çš„)
- ä»¥ä¸‹ä¾‹å­å¤§å¤šå•ç‹¬ä½¿ç”¨,åªæ˜¯ä¸ºä¾‹å±•ç¤ºè¿™äº›äº¤å‰éªŒè¯å™¨æ˜¯æ€ä¹ˆå·¥ä½œçš„

### K-Fold

- [sklearn.model_selection.KFold â€” scikit-learn  documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold)
- [Cross-validation: evaluating estimator performance â€” scikit-learn documentation](https://scikit-learn.org/stable/modules/cross_validation.html#k-fold)
- KæŠ˜äº¤å‰éªŒè¯ï¼ˆK-fold cross-validationï¼‰æ˜¯ä¸€ç§å¸¸ç”¨çš„æ•°æ®é›†åˆ’åˆ†å’Œæ¨¡å‹éªŒè¯æŠ€æœ¯ï¼Œå¯ä»¥ç”¨äºè¯„ä¼°æœºå™¨å­¦ä¹ æ¨¡å‹çš„æ€§èƒ½å’Œè¿›è¡Œæ¨¡å‹çš„é€‰æ‹©å’Œè°ƒä¼˜ã€‚
- KæŠ˜äº¤å‰éªŒè¯çš„åŸºæœ¬æ€æƒ³æ˜¯å°†æ•°æ®é›†åˆ†æˆKä¸ªå­é›†ï¼ˆä¸€èˆ¬æ˜¯å‡ç­‰åˆ’åˆ†ï¼‰ï¼Œç„¶åä½¿ç”¨å…¶ä¸­K-1ä¸ªå­é›†ä½œä¸ºè®­ç»ƒé›†ï¼Œä½™ä¸‹çš„1ä¸ªå­é›†ä½œä¸ºéªŒè¯é›†ï¼Œè¿›è¡Œæ¨¡å‹çš„è®­ç»ƒå’ŒéªŒè¯ï¼Œé‡å¤Kæ¬¡ï¼Œæ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éªŒè¯é›†ï¼Œæœ€ç»ˆå°†Kæ¬¡éªŒè¯çš„ç»“æœè¿›è¡Œå¹³å‡æˆ–åŠ æƒå¹³å‡ï¼Œå¾—åˆ°æœ€ç»ˆçš„æ€§èƒ½æŒ‡æ ‡ã€‚
- KæŠ˜äº¤å‰éªŒè¯çš„ä¼˜ç‚¹åœ¨äºï¼š
  1. å¯ä»¥å……åˆ†åˆ©ç”¨æ•°æ®é›†ä¸­çš„ä¿¡æ¯ï¼Œé¿å…è¿‡æ‹Ÿåˆæˆ–æ¬ æ‹Ÿåˆçš„é—®é¢˜ã€‚
  2. å¯ä»¥å¯¹æ¨¡å‹çš„æ€§èƒ½è¿›è¡Œæ›´å‡†ç¡®çš„è¯„ä¼°ï¼Œå‡å°è¯„ä¼°è¯¯å·®ã€‚
  3. å¯ä»¥åœ¨æœ‰é™çš„æ•°æ®é›†ä¸­ï¼Œæ‰©å¤§è®­ç»ƒé›†çš„è§„æ¨¡ï¼Œæé«˜æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚
- ä»¥ä¸‹ä»£ç æ¼”ç¤ºäº†KFoldæ˜¯æ€ä¹ˆå·¥ä½œçš„

#### eg

- ```python
  import numpy as np
  from sklearn.model_selection import KFold
  X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
  y = np.array([1, 2, 3, 4])
  kf = KFold(n_splits=2)
  n=kf.get_n_splits(X)
  print(n)
  print(kf)
  
  for i, (train_index, test_index) in enumerate(kf.split(X)):
      print(f"Fold {i}:")
      print(f"  Train: index={train_index}")
      print(f"  Test:  index={test_index}")
  ```

  - ```bash
    2
    KFold(n_splits=2, random_state=None, shuffle=False)
    Fold 0:
      Train: index=[2 3]
      Test:  index=[0 1]
    Fold 1:
      Train: index=[0 1]
      Test:  index=[2 3]
    ```

    

- è¿™æ®µä»£ç ä½¿ç”¨äº†Scikit-learnåº“ä¸­çš„`KFold`ç±»è¿›è¡ŒKæŠ˜äº¤å‰éªŒè¯ã€‚å…·ä½“æµç¨‹å¦‚ä¸‹ï¼š

- é¦–å…ˆï¼Œåˆ›å»ºä¸€ä¸ªåŒ…å«4ä¸ªæ ·æœ¬çš„æ•°æ®é›†`X`å’Œå¯¹åº”çš„æ ‡ç­¾`y`ï¼Œå…¶ä¸­`X`æ˜¯ä¸€ä¸ªäºŒç»´æ•°ç»„

  - æ¯è¡Œè¡¨ç¤ºä¸€ä¸ªæ ·æœ¬ï¼Œæ¯åˆ—è¡¨ç¤ºä¸€ä¸ªç‰¹å¾ã€‚
  - ç„¶åï¼Œåˆ›å»ºä¸€ä¸ª`KFold`å¯¹è±¡`kf`ï¼Œå¹¶å°†æ•°æ®é›†`X`ä¼ é€’ç»™å®ƒã€‚

- åœ¨`KFold`å¯¹è±¡ä¸­ï¼Œè®¾ç½®`n_splits=2`ï¼Œè¡¨ç¤ºå°†æ•°æ®é›†åˆ’åˆ†ä¸º2ä¸ªå­é›†ã€‚

  - è°ƒç”¨`get_n_splits`æ–¹æ³•å¯ä»¥è·å–å­é›†çš„æ•°é‡ã€‚

- æ¥ä¸‹æ¥ï¼Œä½¿ç”¨`kf.split(X)`æ–¹æ³•å¯¹æ•°æ®é›†è¿›è¡Œåˆ’åˆ†ï¼Œå¹¶éå†åˆ’åˆ†çš„ç»“æœã€‚

  - åˆ’åˆ†æ“ä½œåªéœ€è¦åˆ’åˆ†å’Œåˆ†ç»„ç´¢å¼•å³å¯,è®¿é—®æ•°æ®çš„æ—¶å€™æ ¹æ®åˆ†å¥½çš„ç´¢å¼•å»è®¿é—®å³å¯
  - åœ¨æ¯ä¸ªæŠ˜å ä¸­ï¼Œ`KFold`ç±»è¿”å›ä¸€ä¸ªå…ƒç»„`(train_index, test_index)`ï¼Œå…¶ä¸­`train_index`è¡¨ç¤ºç”¨äºè®­ç»ƒçš„æ ·æœ¬ç´¢å¼•ï¼Œ`test_index`è¡¨ç¤ºç”¨äºæµ‹è¯•çš„æ ·æœ¬ç´¢å¼•ã€‚
  - ğŸˆå°†kf.split(X)æŠ½å–çš„æ‰€æœ‰`test_index`åˆå¹¶èµ·æ¥(å¹¶æ’åº),å¾—åˆ°çš„åºåˆ—ç›¸å½“äº`range(len(X))`

- åœ¨å¾ªç¯ä¸­ï¼Œä½¿ç”¨`enumerate`å‡½æ•°è·å–å½“å‰æŠ˜å çš„ç´¢å¼•`i`ï¼Œå¹¶è¾“å‡ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç´¢å¼•ã€‚å…·ä½“æ¥è¯´ï¼Œå°†`train_index`å’Œ`test_index`æ‰“å°å‡ºæ¥ï¼Œå…¶ä¸­`train_index`å’Œ`test_index`åˆ†åˆ«è¡¨ç¤ºå½“å‰æŠ˜å ä¸­ç”¨äºè®­ç»ƒå’Œæµ‹è¯•çš„æ ·æœ¬ç´¢å¼•ã€‚

  - ```python
    # æ ¹æ®åˆ†ç»„å¥½çš„ç´¢å¼•,ä½œæ•°æ®åˆ’åˆ†:
    # æ ¹æ®ç´¢å¼•åˆ’åˆ†æ•°æ®é›†
    X_train, X_test = X[train_index], X[test_index]
    # æ ¹æ®ç´¢å¼•åˆ’åˆ†æ ‡ç­¾
    y_train, y_test = y[train_index], y[test_index]
    ```

    - å¾—ç›Šäºnumpyæ•°ç»„çš„å…ƒç´ è®¿é—®æ–¹å¼,ç›¸å…³è¯­å¥ååˆ†ç®€æ´

  - train_indexå’Œtest_indexæ˜¯ç”±æŸç§äº¤å‰éªŒè¯æ–¹æ³•ï¼ˆå¦‚KæŠ˜äº¤å‰éªŒè¯ï¼‰ç”Ÿæˆçš„ç´¢å¼•æ•°ç»„ï¼Œç”¨äºå°†**æ•°æ®é›†X**å’Œ**æ ‡ç­¾é›†y**åˆ’åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚(æ•°æ®é›†å’Œæ ‡ç­¾é›†çš„åˆ’åˆ†ä½¿ç”¨çš„ç´¢å¼•åºåˆ—æ˜¯å¯¹åº”ä¸€è‡´çš„)

  - åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼ŒXå’Œyæ˜¯åŸå§‹æ•°æ®é›†å’Œæ ‡ç­¾é›†ï¼Œtrain_indexå’Œtest_indexæ˜¯ç”±KæŠ˜äº¤å‰éªŒè¯æ–¹æ³•ç”Ÿæˆçš„ç´¢å¼•æ•°ç»„ã€‚

- å¯ä»¥çœ‹åˆ°ï¼Œæ•°æ®é›†è¢«åˆ’åˆ†ä¸ºäº†ä¸¤ä¸ªæŠ˜å ï¼Œæ¯ä¸ªæŠ˜å ä¸­è®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç´¢å¼•æ˜¯ä¸åŒçš„ã€‚ä¹Ÿå¯ä»¥é€šè¿‡`KFold`å¯¹è±¡çš„å…¶ä»–å±æ€§å’Œæ–¹æ³•æ¥æ§åˆ¶äº¤å‰éªŒè¯çš„æ–¹å¼ï¼Œå¦‚è®¾ç½®éšæœºç§å­ã€è¿›è¡Œåˆ†å±‚æŠ½æ ·ç­‰ã€‚

#### eg

- ```python
  X=np.random.randint(5,size=(12,3))
  y=np.random.choice(100,size=len(X))
  X,y
  
  kf2 = KFold(n_splits=3)
  n=kf2.get_n_splits(X)
  print(n)
  print(kf2)
  
  for i, (train_index, test_index) in enumerate(kf2.split(X)):
      print(f"Fold {i}:")
      print(f"  Train: index={train_index}")
      print(f"  Test:  index={test_index}")
      merge=np.concatenate((train_index,test_index))
      merge_sort=merge
      merge_sort.sort()
      print(f'{merge_sort=}')
  ```

  - ```bash
    3
    KFold(n_splits=3, random_state=None, shuffle=False)
    Fold 0:
      Train: index=[ 4  5  6  7  8  9 10 11]
      Test:  index=[0 1 2 3]
    merge_sort=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
    Fold 1:
      Train: index=[ 0  1  2  3  8  9 10 11]
      Test:  index=[4 5 6 7]
    merge_sort=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
    Fold 2:
      Train: index=[0 1 2 3 4 5 6 7]
      Test:  index=[ 8  9 10 11]
    merge_sort=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
    ```

- å†çœ‹ä¸‹shuffleå‚æ•°çš„æ•ˆæœ(éšæœºæ‰“ä¹±é¡ºåºç´¢å¼•,ç„¶ååˆ†ç»„)

  - ```python
    kf2 = KFold(n_splits=3,shuffle=True)
    n=kf2.get_n_splits(X)
    print(n)
    print(kf2)
    
    for i, (train_index, test_index) in enumerate(kf2.split(X)):
        print(f"Fold {i}:")
        print(f"  Train: index={train_index}")
        print(f"  Test:  index={test_index}")
        merge=np.concatenate((train_index,test_index))
        merge_sort=merge
        merge_sort.sort()
        print(f'{merge_sort=}')
    ```

    - ```bash
      3
      KFold(n_splits=3, random_state=None, shuffle=True)
      Fold 0:
        Train: index=[ 3  4  5  6  7  8  9 11]
        Test:  index=[ 0  1  2 10]
      merge_sort=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
      Fold 1:
        Train: index=[ 0  1  2  5  6  8 10 11]
        Test:  index=[3 4 7 9]
      merge_sort=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
      Fold 2:
        Train: index=[ 0  1  2  3  4  7  9 10]
        Test:  index=[ 5  6  8 11]
      merge_sort=array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11])
      ```

      

#### eg

- ä¸‹é¢çš„ä»£ç æ¼”ç¤ºäº†å¦‚ä½•ä½¿ç”¨Scikit-learnåº“ä¸­çš„`KFold`ç±»è¿›è¡ŒKæ¬¡äº¤å‰å®éªŒï¼š

  - ```python
    from sklearn.datasets import make_classification
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import KFold
    from sklearn.metrics import accuracy_score
    
    X, y = make_classification(n_samples=1000, random_state=0)
    kf = KFold(n_splits=5, shuffle=True)
    
    for train_index, test_index in kf.split(X):
        X_train, X_test = X[train_index], X[test_index]
        y_train, y_test = y[train_index], y[test_index]
        lr = LogisticRegression()
        lr.fit(X_train, y_train)
        y_pred = lr.predict(X_test)
        
        acc = accuracy_score(y_test, y_pred)
        print("Accuracy: {:.2f}".format(acc))
    ```
    
    - ```bash
      Accuracy: 0.95
      Accuracy: 0.92
      Accuracy: 0.95
      Accuracy: 0.95
      Accuracy: 0.94
      ```

- è¿™æ®µä»£ç ä½¿ç”¨Scikit-learnåº“ç”Ÿæˆä¸€ä¸ªäºŒåˆ†ç±»æ•°æ®é›†ï¼Œå¹¶ä½¿ç”¨Logisticå›å½’æ¨¡å‹è¿›è¡Œåˆ†ç±»ã€‚ç„¶åä½¿ç”¨KæŠ˜äº¤å‰éªŒè¯æ–¹æ³•æ¥è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ã€‚å…·ä½“è¿‡ç¨‹å¦‚ä¸‹ï¼š

  1. ä½¿ç”¨ `make_classification` å‡½æ•°ç”Ÿæˆä¸€ä¸ªåŒ…å«1000ä¸ªæ ·æœ¬çš„äºŒåˆ†ç±»æ•°æ®é›†ï¼Œå…¶ä¸­ç‰¹å¾æ•°ä¸ºé»˜è®¤å€¼(20)ï¼Œç±»åˆ«æ•°ä¸º2ï¼ŒéšæœºçŠ¶æ€ä¸º0ã€‚
  2. ä½¿ç”¨ `KFold` å‡½æ•°å°†æ•°æ®é›†åˆ†æˆ5ä¸ªäº’æ–¥çš„å­é›†ï¼Œæ¯ä¸ªå­é›†éƒ½å¯ä»¥ä½œä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ä¸€éƒ¨åˆ†ã€‚
  3. å¯¹äºæ¯ä¸ªå­é›†ï¼Œå°†å…¶ä½œä¸ºæµ‹è¯•é›†ï¼Œä½™ä¸‹çš„æ•°æ®ä½œä¸ºè®­ç»ƒé›†ã€‚
  4. åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒä¸€ä¸ªLogisticå›å½’æ¨¡å‹ã€‚
  5. åœ¨æµ‹è¯•é›†ä¸Šé¢„æµ‹æ¨¡å‹çš„è¾“å‡ºï¼Œå¹¶ä½¿ç”¨ `accuracy_score` å‡½æ•°è®¡ç®—é¢„æµ‹çš„å‡†ç¡®ç‡ã€‚
  6. æ‰“å°æ¯æ¬¡äº¤å‰éªŒè¯çš„å‡†ç¡®ç‡ã€‚
  7. æœ€ç»ˆè¾“å‡º5æ¬¡äº¤å‰éªŒè¯çš„å‡†ç¡®ç‡å‡å€¼å’Œæ ‡å‡†å·®ã€‚

  è¿™æ®µä»£ç å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨KæŠ˜äº¤å‰éªŒè¯æ–¹æ³•æ¥è¯„ä¼°Logisticå›å½’æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶è®¡ç®—æ¨¡å‹çš„å‡†ç¡®ç‡ã€‚

- å¯ä»¥æ ¹æ®å…·ä½“æƒ…å†µé€‰æ‹©åˆé€‚çš„Kå€¼å’ŒéªŒè¯æŒ‡æ ‡æ¥è¿›è¡Œæ¨¡å‹è¯„ä¼°ã€‚

### Repeated K-Fold

- [`RepeatedKFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RepeatedKFold.html#sklearn.model_selection.RepeatedKFold) repeats K-Fold n times. It can be used when one requires to run [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) n times, producing different splits in each repetition.

- Repeated K-Fold æ˜¯ä¸€ç§äº¤å‰éªŒè¯æ–¹æ³•ï¼Œå®ƒå¯ä»¥åœ¨ K-Fold çš„åŸºç¡€ä¸Šè¿›ä¸€æ­¥å¢åŠ é‡å¤æ¬¡æ•°ï¼Œä»¥**å‡å°‘ç”±äºéšæœºåˆ’åˆ†å¯¼è‡´çš„æ¨¡å‹æ€§èƒ½ä¸ç¨³å®šçš„é—®é¢˜**ã€‚(å¯ä»¥å‚è€ƒè¥¿ç“œä¹¦)

- åœ¨ Repeated K-Fold ä¸­:ä»¥Ræ¬¡KæŠ˜å ä¸ºä¾‹

  - åœ¨å•æ¬¡KæŠ˜å ä¸­,æ“ä½œæ–¹æ³•å°±æ˜¯æ™®é€šçš„K-Foldå®éªŒ:é¦–å…ˆå°†æ•°æ®é›†åˆ†ä¸º K ä¸ªå­é›†ï¼Œç„¶åè¿›è¡Œ K æ¬¡äº¤å‰éªŒè¯ã€‚åœ¨æ¯ä¸€æ¬¡äº¤å‰éªŒè¯ä¸­ï¼Œå°†å…¶ä¸­ä¸€ä¸ªå­é›†ä½œä¸ºæµ‹è¯•é›†ï¼Œå…¶ä½™å­é›†ä½œä¸ºè®­ç»ƒé›†ã€‚è¿™æ ·å¯ä»¥å¾—åˆ° K ä¸ªæ¨¡å‹çš„æ€§èƒ½è¯„ä¼°ç»“æœï¼Œå¹¶è®¡ç®—å®ƒä»¬çš„å¹³å‡å€¼ä½œä¸ºæœ€ç»ˆæ€§èƒ½è¯„ä¼°ç»“æœã€‚

  - ç„¶åï¼Œä¸ºäº†å¢åŠ é‡å¤æ¬¡æ•°ï¼Œå¯ä»¥é‡å¤ä¸Šè¿°è¿‡ç¨‹ R æ¬¡ï¼Œ**æ¯æ¬¡ä½¿ç”¨ä¸åŒçš„éšæœºåˆ’åˆ†**ï¼Œå¾—åˆ° R ä¸ªä¸åŒçš„æ¨¡å‹æ€§èƒ½è¯„ä¼°ç»“æœã€‚
  - è¿™æ ·å¯ä»¥æ›´å‡†ç¡®åœ°è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶å‡å°‘éšæœºåˆ’åˆ†å¸¦æ¥çš„ä¸ç¡®å®šæ€§ã€‚

- ä¾‹å¦‚ï¼Œå‡è®¾æˆ‘ä»¬ä½¿ç”¨ 5-Fold é‡å¤ 3 æ¬¡ï¼Œæˆ‘ä»¬å°†æ•°æ®é›†åˆ†ä¸º 5 ä¸ªå­é›†ï¼Œè¿›è¡Œ 5 æ¬¡äº¤å‰éªŒè¯(æ¯æ¬¡åˆ’åˆ†çš„æ•°æ®é›†å­é›†äº¬å¯èƒ½äº’ä¸ç›¸åŒ,é€šå¸¸æ˜¯ç‹¬ç«‹çš„éšæœºåˆ’åˆ†;å¦‚æœæ¯æ¬¡åˆ’åˆ†å­é›†éƒ½ä¸€æ ·,å°±æ²¡æœ‰å¿…è¦é‡å¤äº†,éœ€è¦ç†è§£**é‡å¤**è¿™ä¸ªè¯åœ¨è¿™é‡Œçš„æ„æ€,æŒ‡çš„æ˜¯<u>ä»¥ç›¸åŒçš„æ“ä½œåå¤åšå®éªŒ</u>è€Œéé‡åˆæˆ–ç›¸åŒçš„æ„æ€,åŒºåˆ«ä¸åŒæ¬¡å®éªŒçš„å…³é”®åœ¨äºéšæœºåˆ’åˆ†æ¯æ¬¡åˆ’åˆ†çš„Kä¸ªå­é›†æ˜¯ä¸åŒçš„),å¹¶é‡å¤ 3 æ¬¡ä¸Šè¿°è¿‡ç¨‹ä¼šå¾—åˆ° $3\times{5}=15$ ä¸ªä¸åŒçš„æ¨¡å‹æ€§èƒ½è¯„ä¼°ç»“æœã€‚

- ä½¿ç”¨ Repeated K-Fold å¯ä»¥æ›´å‡†ç¡®åœ°ä¼°è®¡æ¨¡å‹çš„æ€§èƒ½ï¼Œå› ä¸ºå®ƒå‡å°‘äº†éšæœºåˆ’åˆ†å¸¦æ¥çš„ä¸ç¡®å®šæ€§ã€‚ä½†æ˜¯ï¼Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œé‡å¤æ¬¡æ•°è¶Šå¤šï¼Œè®¡ç®—æ—¶é—´å’Œè®¡ç®—èµ„æºçš„æ¶ˆè€—ä¹Ÿä¼šéšä¹‹å¢åŠ ã€‚å› æ­¤ï¼Œåœ¨å®é™…åº”ç”¨ä¸­éœ€è¦æƒè¡¡è®¡ç®—æˆæœ¬å’Œæ¨¡å‹æ€§èƒ½ä¹‹é—´çš„å¹³è¡¡ã€‚

- Example of 2-fold K-Fold repeated 2 times:

  - ```python
    import numpy as np
    from sklearn.model_selection import RepeatedKFold
    # X = np.array([[1, 2], [3, 4], [1, 2], [3, 4]])
    #è¿™é‡Œè®¾å®šrandom_stateè¡¨ç¤ºå¯¹è¿™æ®µä»£ç æ‰§è¡Œnæ¬¡,é‚£ä¹ˆnæ¬¡çš„ç»“æœæ˜¯ä¸€æ ·çš„
    random_state = 12883823
    rng=np.random.default_rng(seed=random_state)
    
    X=rng.integers(10,100,size=(6,2))
    rkf = RepeatedKFold(n_splits=3, n_repeats=2, random_state=random_state)
    
    print(X,"@{X}")
    print('split result:')
    #æ³¨æ„
    rkf_splits = rkf.split(X)
    for i,(train, test) in enumerate(rkf_splits):
        print("fold%s:%s %s" % (i,train, test))
    ```

  - ```bash
    [[92 94]
     [43 88]
     [39 44]
     [90 33]
     [62 95]
     [42 64]] @{X}
    split result:
    fold0:[0 3 4 5] [1 2]
    fold1:[0 1 2 4] [3 5]
    fold2:[1 2 3 5] [0 4]
    fold3:[0 1 3 5] [2 4]
    fold4:[0 1 2 4] [3 5]
    fold5:[2 3 4 5] [0 1]
    ```

    

### ShuffleSplit

- [sklearn.model_selection.ShuffleSplit â€” scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html)

- Random permutation cross-validatoréšæœºæ’åˆ—äº¤å‰éªŒè¯å™¨

  Yields indices to split data into training and test sets.

  Note: contrary to other cross-validation strategies, random splits do not guarantee that all folds will be different, although this is still very likely for **sizeable** datasets.

  æ­¤äº¤å‰éªŒè¯å™¨å°†æ•°æ®æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„ç´¢å¼•ã€‚

- æ³¨æ„ï¼šä¸å…¶ä»–äº¤å‰éªŒè¯ç­–ç•¥ä¸åŒï¼Œ**éšæœºæ‹†åˆ†ä¸èƒ½ä¿è¯æ‰€æœ‰çš„foldéƒ½æ˜¯ä¸åŒçš„**ï¼Œå°½ç®¡å¯¹äºå¤§å‹æ•°æ®é›†,è¿™ç§æƒ…å†µä»ç„¶æ˜¯å¾ˆå¯èƒ½å‘ç”Ÿçš„ã€‚

- ä¸è¿‡,å’Œè‡ªä¸¾æ³•é‡‡æ ·ä¸åŒ,shuffleSplitå¯ä»¥ä¿è¯æ¯ä¸€æ¬¡é‡‡æ ·çš„ä¸¤ä¸ªæ•°æ®é›†çš„å¹¶é›†æ˜¯å…ƒæ•°æ®é›†,ä¸”äº¤é›†æ˜¯ç©º,åªæ˜¯ä¸èƒ½ä¿è¯å¤šæ¬¡åˆ’åˆ†ä¹‹é—´äº’ä¸ç›¸åŒ.

- [  Cross-validation: evaluating estimator performance â€” scikit-learn  documentation](https://scikit-learn.org/stable/modules/cross_validation.html#random-permutations-cross-validation-a-k-a-shuffle-split)

#### eg

- ```python
  from sklearn.model_selection import ShuffleSplit
  X = np.arange(8)
  # X = np.arange(12,24)#ç”Ÿæˆ12ä¸ªæ•°,12~23
  ss = ShuffleSplit(n_splits=5, test_size=0.25, random_state=0)
  # ShuffleSplitä»…åˆ’åˆ†ç´¢å¼•,è€Œä¸æ˜¯æ•°æ®æ ·æœ¬æœ¬èº«
  for train_index, test_index in ss.split(X):
      print("%s %s" % (train_index, test_index))
  ```

  - ```bash
    [1 7 3 0 5 4] [6 2]
    [3 7 0 4 2 5] [1 6]
    [3 4 7 0 6 1] [5 2]
    [6 7 3 4 1 0] [2 5]
    [1 6 3 2 0 7] [4 5]
    ```
  
  - è¿™æ®µä»£ç é¦–å…ˆä½¿ç”¨`np.arange`å‡½æ•°ç”Ÿæˆä¸€ä¸ªåŒ…å«8ä¸ªæ•°çš„æ•°ç»„`X`ï¼Œç„¶ååˆ›å»ºä¸€ä¸ª`ShuffleSplit`å¯¹è±¡`ss`ï¼Œå°†æ•°æ®é›†åˆ†æˆ`5`ä¸ªä¸åŒçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œæµ‹è¯•é›†çš„å¤§å°è®¾ç½®ä¸º25%ï¼Œéšæœºç§å­è®¾ç½®ä¸º0ã€‚
  - ç„¶åï¼Œæˆ‘ä»¬ä½¿ç”¨ssçš„`split`æ–¹æ³•å¯¹æ•°æ®é›†è¿›è¡Œéšæœºæ‹†åˆ†ï¼Œå°†æ¯ä¸ªfoldçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç´¢å¼•åˆ†åˆ«å­˜å‚¨åœ¨`train_index`å’Œ`test_index`å˜é‡ä¸­ï¼Œå¹¶è¾“å‡ºè¿™ä¸¤ä¸ªå˜é‡ã€‚
  
- Here is a visualization of the cross-validation behavior. Note that [`ShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit) is not affected by classes or groups.

  [![../_images/sphx_glr_plot_cv_indices_008.png](https://scikit-learn.org/stable/_images/sphx_glr_plot_cv_indices_008.png)](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html)

- [`ShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.ShuffleSplit.html#sklearn.model_selection.ShuffleSplit) is thus a good alternative to [`KFold`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold) cross validation that allows a finer control on the number of iterations and the proportion of samples on each side of the train / test split.

- è¯·æ³¨æ„ï¼ŒShuffleSplitä¸å—ç±»åˆ«æˆ–ç»„çš„å½±å“ã€‚å› æ­¤ï¼ŒShuffleSplitæ˜¯KFoldäº¤å‰éªŒè¯çš„ä¸€ä¸ªå¾ˆå¥½çš„æ›¿ä»£æ–¹æ³•ï¼Œå®ƒå…è®¸å¯¹è¿­ä»£æ¬¡æ•°å’Œè®­ç»ƒ/æµ‹è¯•æ‹†åˆ†çš„æ ·æœ¬æ¯”ä¾‹è¿›è¡Œæ›´ç²¾ç»†çš„æ§åˆ¶ã€‚

- å¯¹æ¯”äºKFold

  - ```python
    from sklearn.model_selection import KFold
    X = np.arange(8)
    kf = KFold(n_splits=5)
    for train_index, test_index in kf.split(X):
        print("%s %s" % (train_index, test_index))
    ```

    - ```bash
      [2 3 4 5 6 7] [0 1]
      [0 1 4 5 6 7] [2 3]
      [0 1 2 3 6 7] [4 5]
      [0 1 2 3 4 5 7] [6]
      [0 1 2 3 4 5 6] [7]
      
      ```

  - æ ¹æ®KFoldçš„å®šä¹‰,å¦‚æœå¸Œæœ›å¯¹nä¸ªæ•°æ®åškæŠ˜å ,é‚£ä¹ˆæ¯ä¸€ä¸ªfoldåŒ…å«çš„æ ·æœ¬æ•°$\frac{n}{k}$

    - åœ¨sklearnä¸­,å¯èƒ½å‘ä¸Šå–æ•´,ä¹Ÿå¯èƒ½å‘ä¸‹å–æ•´

  - å¦‚æœæŠŠ`np.arange(8)`æ”¹ä¸º`np.arange(10)`,æ­¤æ—¶5æŠ˜å å¯ä»¥æ•´é™¤`10/5=2`

    - é‚£ä¹ˆæ¯ä¸ªfoldåŒ…å«2ä¸ªæ•°æ®

    - ```
      [2 3 4 5 6 7 8 9] [0 1]
      [0 1 4 5 6 7 8 9] [2 3]
      [0 1 2 3 6 7 8 9] [4 5]
      [0 1 2 3 4 5 8 9] [6 7]
      [0 1 2 3 4 5 6 7] [8 9]
      ```

  - ä¸Šè¿°ä¾‹å­çš„KFoldæ²¡æœ‰ä½¿ç”¨`shuffle=True`å‚æ•°æ‰“ä¹±é¡ºåºæ˜¯ä¸ºäº†æ”¾ä¾¿è§‚å¯Ÿ

  - é€šå¸¸å»ºè®®ä½¿ç”¨`shuffle=True`,ä¸å®¹æ˜“å—åˆ°æ•°æ®é›†æ ·æœ¬é¡ºåºçš„å½±å“!

### Stratified Shuffle Split

- [sklearn.model_selection.StratifiedShuffleSplit â€” scikit-learn  documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html)
- [  Cross-validation: evaluating estimator performance â€” scikit-learn  documentation](https://scikit-learn.org/stable/modules/cross_validation.html#stratified-shuffle-split)

- [`StratifiedShuffleSplit`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedShuffleSplit.html#sklearn.model_selection.StratifiedShuffleSplit) is a variation of *ShuffleSplit*, which returns stratified splits, *i.e* which creates splits by preserving t**he same percentage for each target class** as in the complete set.
- Stratified ShuffleSplit cross-validator

  Provides train/test indices to split data in train/test sets.

  This cross-validation object is a merge of StratifiedKFold and ShuffleSplit, which returns stratified randomized folds. The folds are made by preserving the percentage of samples for each class.

  Note: like the ShuffleSplit strategy, stratified random splits do not guarantee that all folds will be different, although this is still very likely for sizeable datasets.

  `StratifiedShuffleSplit`æ˜¯ä¸€ç§äº¤å‰éªŒè¯ç”Ÿæˆå™¨ï¼Œå®ƒé€šè¿‡åˆ›å»ºåˆ†å±‚çš„éšæœºæ‹†åˆ†æ¥æä¾›è®­ç»ƒ/æµ‹è¯•ç´¢å¼•ï¼Œç”¨äºå°†æ•°æ®é›†åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚

  è¿™ä¸ªäº¤å‰éªŒè¯å¯¹è±¡æ˜¯`StratifiedKFold`å’Œ`ShuffleSplit`çš„åˆå¹¶ï¼Œå®ƒè¿”å›åˆ†å±‚çš„éšæœºæŠ˜å ã€‚è¿™äº›æŠ˜å æ˜¯é€šè¿‡ä¿ç•™æ¯ä¸ªç±»åˆ«æ ·æœ¬çš„ç™¾åˆ†æ¯”æ¥æ„å»ºçš„ã€‚

  éœ€è¦æ³¨æ„çš„æ˜¯ï¼šä¸`ShuffleSplit`ç­–ç•¥ä¸€æ ·ï¼Œåˆ†å±‚éšæœºæ‹†åˆ†å¹¶ä¸èƒ½ä¿è¯æ‰€æœ‰æŠ˜å éƒ½æ˜¯ä¸åŒçš„ï¼Œå°½ç®¡å¯¹äºè§„æ¨¡è¾ƒå¤§çš„æ•°æ®é›†ï¼Œè¿™ä»ç„¶æ˜¯éå¸¸å¯èƒ½çš„ã€‚
- `StratifiedShuffleSplit` æ˜¯ `ShuffleSplit` çš„ä¸€ç§å˜ä½“ï¼Œå®ƒé€šè¿‡ä¿ç•™ä¸å®Œæ•´æ•°æ®é›†ç›¸åŒçš„æ¯ä¸ªç›®æ ‡ç±»åˆ«çš„ç™¾åˆ†æ¯”æ¥åˆ›å»ºåˆ†å±‚çš„æ‹†åˆ†ã€‚

  `ShuffleSplit` æ˜¯ä¸€ç§ç®€å•çš„äº¤å‰éªŒè¯ç­–ç•¥ï¼Œå®ƒå°†æ•°æ®é›†éšæœºåˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œä¸è€ƒè™‘ç›®æ ‡å˜é‡çš„ç±»åˆ«åˆ†å¸ƒã€‚

  å¦ä¸€æ–¹é¢ï¼Œ`StratifiedShuffleSplit` åœ¨åˆ›å»ºæ‹†åˆ†æ—¶è€ƒè™‘ç›®æ ‡å˜é‡çš„ç±»åˆ«åˆ†å¸ƒã€‚å®ƒç¡®ä¿åœ¨æ¯ä¸ªæ‹†åˆ†ä¸­ä¿ç•™æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬ç™¾åˆ†æ¯”ï¼Œè¿™åœ¨å¤„ç†ä¸å¹³è¡¡æ•°æ®é›†æ—¶éå¸¸é‡è¦ã€‚
- å› æ­¤ï¼Œå½“ä½ å¤„ç†ä¸å¹³è¡¡æ•°æ®é›†å¹¶ä¸”æƒ³è¦ç¡®ä¿æ¯ä¸ªæ‹†åˆ†ä¸­çš„ç›¸åŒç±»åˆ«åˆ†å¸ƒæ—¶ï¼Œ`StratifiedShuffleSplit` æ˜¯ä¸€ç§éå¸¸æœ‰ç”¨çš„äº¤å‰éªŒè¯ç­–ç•¥ã€‚

- `StratifiedShuffleSplit`æ˜¯`scikit-learn`åº“ä¸­çš„ä¸€ä¸ªäº¤å‰éªŒè¯ç”Ÿæˆå™¨ï¼Œå®ƒå¯ä»¥å°†æ•°æ®é›†éšæœºåˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶ä¸”**ä¿æŒæ¯ä¸ªç±»åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„æ¯”ä¾‹ç›¸ç­‰**ã€‚
- è¿™ä¸ªæ–¹æ³•é€‚ç”¨äºåˆ†ç±»é—®é¢˜ä¸­<u>ç±»åˆ«ä¸å¹³è¡¡çš„æ•°æ®é›†</u>ï¼Œå¯ä»¥ç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡éƒ½**å¤§è‡´ç›¸åŒ**ã€‚

`StratifiedShuffleSplit`çš„åˆ›å»ºæ–¹æ³•å¦‚ä¸‹ï¼š



- ```python
  from sklearn.model_selection import StratifiedShuffleSplit
  sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)
  ```

- åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ª`StratifiedShuffleSplit`å¯¹è±¡`sss`ï¼Œå…¶ä¸­`n_splits`å‚æ•°æŒ‡å®šäº†åˆ’åˆ†æŠ˜æ•°ï¼Œ`test_size`å‚æ•°æŒ‡å®šäº†æµ‹è¯•é›†å æ¯”ï¼Œ`random_state`å‚æ•°æŒ‡å®šäº†éšæœºç§å­ï¼Œç”¨äºæ§åˆ¶éšæœºæ€§ã€‚
- ç„¶åï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨`split`æ–¹æ³•å¯¹æ•°æ®é›†è¿›è¡Œåˆ’åˆ†ï¼Œå°†æ¯ä¸ªfoldçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç´¢å¼•åˆ†åˆ«å­˜å‚¨åœ¨`train_index`å’Œ`test_index`å˜é‡ä¸­ã€‚

#### eg

ä»¥ä¸‹æ˜¯ä¸€ä¸ªä½¿ç”¨`StratifiedShuffleSplit`å¯¹æ•°æ®é›†è¿›è¡Œäº¤å‰éªŒè¯çš„ç¤ºä¾‹ä»£ç ï¼š

- ```python
  from sklearn.datasets import load_iris
  from sklearn.model_selection import StratifiedShuffleSplit
  iris = load_iris()
  X, y = iris.data, iris.target
  sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)
  for train_index, test_index in sss.split(X, y):
      print("%s %s" % (train_index, test_index))
  ```


- åœ¨è¿™ä¸ªç¤ºä¾‹ä¸­ï¼Œæˆ‘ä»¬é¦–å…ˆåŠ è½½äº†`iris`æ•°æ®é›†ï¼Œç„¶åå°†æ•°æ®é›†åˆ’åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚æˆ‘ä»¬ä½¿ç”¨`StratifiedShuffleSplit`æ–¹æ³•å°†æ•°æ®é›†åˆ†æˆ5ä¸ªä¸åŒçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå¹¶å°†æ¯ä¸ªfoldçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ç´¢å¼•åˆ†åˆ«å­˜å‚¨åœ¨`train_index`å’Œ`test_index`å˜é‡ä¸­ã€‚ç”±äº`iris`æ•°æ®é›†æ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜ï¼Œå› æ­¤æˆ‘ä»¬ä½¿ç”¨`StratifiedShuffleSplit`ä¿æŒäº†æ¯ä¸ªç±»åˆ«åœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„æ¯”ä¾‹ç›¸ç­‰ã€‚

#### eg

- ä¸‹é¢è¿™ä¸ªä¾‹å­æ›´åŠ è¯¦ç»†çš„æè¿°äº†è¿™ä¸€ç‚¹

  ```python
  
  import numpy as np
  from sklearn.model_selection import StratifiedShuffleSplit
  #ä½¿ç”¨éšæœºç”Ÿæˆæ•°æ®æµ‹è¯•
  rng=np.random.default_rng()
  rng.integers(20,size=(12,2))
  # æ ·æœ¬æ€»æ•°ä¸º12,äºŒåˆ†ç±»,æ ‡ç­¾ä¸º0,1,ä¸¤ç§æ ·æœ¬æ¯”ä¾‹ä¸º1:2
  n=12
  n0,n1=1*n//3,2*n//3
  #éšæœºçš„ä¸ºè¿™äº›æ¨¡æ‹Ÿæ ·æœ¬åˆ†é…æ ‡ç­¾(å› ä¸ºè¿™é‡Œä¸æ¶‰åŠåˆ°è®­ç»ƒ,æ‰€ä»¥éšæœºåˆ†é…æ ‡ç­¾ä¸å½±å“æ•ˆæœ,åœ¨æ•°æ®é›†åˆ’åˆ†çš„é˜¶æ®µ,ä¸ç”¨å…³å¿ƒæ ·æœ¬å’Œæ ‡ç­¾çš„å…³è”è§„å¾‹,å¦‚æœæ˜¯è¦è®­ç»ƒ,é€šå¸¸æ˜¯ä¸èƒ½éšæœºç»™æ ·æœ¬ç‰¹å¾åˆ†é…æ ‡ç­¾)
  
  y=[0]*n0+[1]*n1
  y=np.array(y)
  rng.shuffle(y)
  #ä¸‹é¢ä¸€ç§æ–¹å¼é‡‡ç”¨æ¦‚ç‡çš„æ–¹å¼ç”Ÿæˆæ ‡ç­¾,ä½†æ˜¯å³ä½¿æ ·æœ¬æ€»æ•°nå¯ä»¥è¢«3æ•´é™¤,ç”Ÿæˆçš„æ•°ç»„ä¹Ÿä¸ä¿è¯æ•°é‡æ˜¯1:2
  # y = rng.choice([0, 1], size=12, replace=True, p=[1/3, 2/3])
  # count=np.unique(y,return_counts=True)
  # print(count)
  #ä¸ºä¾‹æ”¾ä¾¿éªŒè¯,è¿™é‡Œå°†æ ‡ç­¾æ•°ç»„å’Œæ ·æœ¬ç´¢å¼•æ‰“å°å‡ºæ¥
  print(np.vstack([y,range(n)]))
  #æ„é€ åˆ†å±‚éšæœºæ‹†åˆ†å¯¹è±¡,æŒ‡å®šåšç‹¬ç«‹çš„5æ¬¡åˆ’åˆ†,æ¯æ¬¡åˆ’åˆ†,æµ‹è¯•é›†çš„æ ·æœ¬æ•°é‡å æ€»æ ·æœ¬æ•°é‡nçš„20%
  #è€ŒStratifiedShuffleSplitä¼šä¿æŒå„ä¸ªç±»åˆ«åœ¨æµ‹è¯•é›†å’Œè®­ç»ƒé›†ä¸Šçš„æ¯”ä¾‹
  # æ˜¯ä¸¤ç§ç‹¬ç«‹çš„çº¦æŸ(ä¾‹å¦‚0ç±»æ ·å’Œ1ç±»æ ·æœ¬æ¯”ä¾‹åœ¨æ•°æ®é›†ä¸­ä¸º1:2,é‚£ä¹ˆåœ¨è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­ä¾ç„¶ä¿æŒ(æˆ–æ¥è¿‘)1:2)
  sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=0)
  # print(sss)
  #æ‰“å°è¿™5æ¬¡
  for i, (train_index, test_index) in enumerate(sss.split(X, y)):
      print(f"Fold {i}:")
      print(f"  Train: index={train_index}")
      print(f"  Test:  index={test_index}")
      print(np.vstack((test_index, y[test_index])))
  ```

  

- ```bash
  [[ 1  1  0  1  1  1  0  0  1  1  0  1]
   [ 0  1  2  3  4  5  6  7  8  9 10 11]]
  Fold 0:
    Train: index=[ 3 10  6  9  5  7  8  1  0]
    Test:  index=[ 2 11  4]
  [[ 2 11  4]
   [ 0  1  1]]
  Fold 1:
    Train: index=[ 4  2  9  0  7 11  5  3  6]
    Test:  index=[10  1  8]
  [[10  1  8]
   [ 0  1  1]]
  Fold 2:
    Train: index=[ 6  9  2 11  7  4  3  8  5]
    Test:  index=[ 1  0 10]
  [[ 1  0 10]
   [ 1  1  0]]
  Fold 3:
    Train: index=[10  8  6  3 11  4  1  7  5]
    Test:  index=[0 2 9]
  [[0 2 9]
   [1 0 1]]
  Fold 4:
    Train: index=[ 7  2  0  6 11  1  5  3  9]
    Test:  index=[ 8  4 10]
  [[ 8  4 10]
   [ 1  1  0]]
  ```

###  å°ç»“

- KFoldã€ShuffleSplit å’Œ StratifiedShuffleSplit éƒ½æ˜¯äº¤å‰éªŒè¯çš„æ–¹æ³•ï¼Œå®ƒä»¬ä¹‹é—´çš„åŒºåˆ«åœ¨äºæ•°æ®é›†çš„åˆ’åˆ†æ–¹å¼å’Œç”¨é€”ã€‚

  1. KFold
     KFold æ˜¯æœ€åŸºæœ¬çš„äº¤å‰éªŒè¯æ–¹æ³•ï¼Œå°†æ•°æ®é›†åˆ†æˆ K ä»½ï¼Œæ¯æ¬¡é€‰å–å…¶ä¸­çš„ä¸€ä»½ä½œä¸ºéªŒè¯é›†ï¼Œå…¶ä½™ K-1 ä»½ä½œä¸ºè®­ç»ƒé›†ã€‚è¿™ä¸ªè¿‡ç¨‹é‡å¤ K æ¬¡ï¼Œæ¯æ¬¡é€‰ä¸åŒçš„ä¸€ä»½ä½œä¸ºéªŒè¯é›†ã€‚KFold é€‚ç”¨äºæ•°æ®é›†æ¯”è¾ƒå‡è¡¡çš„æƒ…å†µï¼Œæ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡å·®ä¸å¤šã€‚
  2. ShuffleSplit
     ShuffleSplit æ˜¯ä¸€ç§éšæœºåˆ’åˆ†æ•°æ®é›†çš„æ–¹æ³•ï¼Œå®ƒå¯ä»¥å¤šæ¬¡éšæœºåˆ’åˆ†å‡ºä¸åŒçš„è®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ä¸ KFold ä¸åŒçš„æ˜¯ï¼ŒShuffleSplit ä¸éœ€è¦äº‹å…ˆå°†æ•°æ®é›†åˆ†æˆå›ºå®šæ•°é‡çš„æŠ˜å ã€‚ShuffleSplit é€‚ç”¨äºæ•°æ®é›†è¾ƒå¤§ï¼Œéœ€è¦éšæœºé‡‡æ ·çš„æƒ…å†µã€‚
  3. StratifiedShuffleSplit
     StratifiedShuffleSplit æ˜¯åœ¨ ShuffleSplit çš„åŸºç¡€ä¸Šå¢åŠ äº†åˆ†å±‚æŠ½æ ·çš„åŠŸèƒ½ï¼Œå®ƒä¼šä¿è¯æ¯ä¸ªæŠ½æ ·ä¸­å„ä¸ªç±»åˆ«çš„æ¯”ä¾‹ä¸åŸæ•°æ®é›†ä¸­ç›¸åŒã€‚StratifiedShuffleSplit é€‚ç”¨äºæ•°æ®é›†ä¸­ä¸åŒç±»åˆ«çš„æ ·æœ¬æ•°é‡ä¸å¹³è¡¡çš„æƒ…å†µã€‚

  æ€»ä¹‹ï¼ŒKFoldã€ShuffleSplit å’Œ StratifiedShuffleSplit éƒ½æ˜¯å¸¸ç”¨çš„äº¤å‰éªŒè¯æ–¹æ³•ï¼Œå…·ä½“ä½¿ç”¨å“ªç§æ–¹æ³•è¦æ ¹æ®æ•°æ®é›†çš„ç‰¹ç‚¹å’Œå®é™…éœ€æ±‚æ¥é€‰æ‹©ã€‚

- ä»ä¸Šé¢çš„ä¾‹å­çš„å¯¹æ¯”ä¸­å¯ä»¥çœ‹å‡º,`ShuffleSplit`å’Œ`StratifiedShuffleSplit`çš„å‚æ•°å¯ä»¥æ¥æ”¶`n_splits`å’Œ`test_set`ä¸¤ä¸ªç›¸å¯¹ç‹¬ç«‹çš„å‚æ•°

  - ä»–ä»¬å¯ä»¥å¯¹åŒä¸€ä¸ªæ•°æ®é›†åš`n_splits`æ¬¡åˆ’åˆ†,åŒæ—¶æ¯æ¬¡åˆ’åˆ†ä¸­`test_size`ä¸å—`n_splits`çš„å½±å“

- è€Œå¯¹äºKFold,`n_splits`å¾€å¾€å°±å†³å®šäº†`test_size`çš„å€¼ä¸º`1/n_splits`

### ç»¼åˆä¾‹

- ç¤ºä¾‹ä»¥å„ç§**äº¤å‰éªŒè¯å™¨**(cross validator)ç»“åˆ`cross_val_score`(cross validation score)æ¥ä½¿ç”¨è¿™äº›äº¤å‰éªŒè¯å™¨å¯¹è®­ç»ƒå‡ºæ¥çš„å„ç§æ¨¡å‹è¿›è¡Œ**ç²¾åº¦**åˆ†æ•°çš„è¯„ä¼°:
  
  ```python
  
  import numpy as np
  from sklearn.datasets import load_iris
  from sklearn.ensemble import RandomForestClassifier
  from sklearn.linear_model import LinearRegression
  from sklearn.model_selection import KFold, cross_val_score
  from sklearn.svm import SVC
  from sklearn.tree import DecisionTreeClassifier
  from sklearn.datasets import load_iris
  from sklearn.model_selection import ShuffleSplit, cross_val_score
  from sklearn.tree import DecisionTreeClassifier
  
  ##
  
  # åŠ è½½iris(é¸¢å°¾èŠ±)æ•°æ®é›†
  X, y = load_iris(return_X_y=True)
  
  #! å®šä¹‰5æŠ˜äº¤å‰éªŒè¯
  kf = KFold(
      n_splits=5,
      shuffle=True,
      random_state=42,
  )
  
  # ä½¿ç”¨çº¿æ€§å›å½’æ¨¡å‹è¿›è¡Œè®­ç»ƒå’Œæµ‹è¯•
  model = LinearRegression()
  # model=RandomForestClassifier()
  
  scores_cv = []
  # è¿™é‡Œsplitå‚æ•°å¯ä»¥æ˜¯Xä¹Ÿå¯ä»¥æ˜¯y,å› ä¸ºåªéœ€è¦åˆ’åˆ†æ ·æœ¬çš„ç´¢å¼•,æ‰€ä»¥ä¸¤è€…éƒ½å¯ä»¥
  for train_index, test_index in kf.split(y):
      X_train, X_test = X[train_index], X[test_index]
      y_train, y_test = y[train_index], y[test_index]
      model.fit(X_train, y_train)
      score = model.score(X_test, y_test)
      scores_cv.append(score)
      print("Score:", score)
  mean_score = np.mean(scores_cv)
  print(f"{mean_score=}")
  ##
  #!ä½¿ç”¨cross_val_score
  #æ„é€ cvå™¨çš„æ—¶å€™ä¸éœ€è¦ä¼ å…¥æ•°æ®é›†
  ss_cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)
  kf_cv=KFold(n_splits=3,shuffle=True,random_state=42)
  
  scores = cross_val_score(
      model,
      X,
      y,
      #cv=5,
      #cv=ss_cv,
      cv=kf_cv,
      verbose=3,
  )
  #cvå–æ•´æ•°æ—¶,é‡‡ç”¨çš„ééšæœºåŒ–çš„kfoldæ–¹æ³•åˆ’åˆ†,ä¸æ˜¯å¾ˆå¯é 
  #cvå»ºè®®é€‰ç”¨éšæœºåŒ–çš„(StratifiedShuffleSplitæœ€ä¸ºé«˜çº§)
  #cvå–kfoldå¯¹è±¡æ—¶,æˆ‘ä»¬å¯ä»¥é€‰æ‹©shuffle=True,ä½¿å¾—æ‰€æœ‰æ ·æœ¬éƒ½èƒ½å¤Ÿå‚ä¸è®­ç»ƒé›†/æµ‹è¯•é›†
  print("Scores:", scores)
  print("Mean score:", scores.mean())
  
  
  ##
  
  # ä½¿ç”¨å†³ç­–æ ‘æ¨¡å‹è¿›è¡Œäº¤å‰éªŒè¯ï¼Œå¹¶å¯¹æ•°æ®é›†è¿›è¡ŒéšæœºåŒ–æ“ä½œ
  model = DecisionTreeClassifier()
  ss_cv = ShuffleSplit(n_splits=3, test_size=0.2, random_state=42)
  
  print("cv: ", ss_cv)
  
  # ssr=ss_cv.split(X,y)
  # for train_index,test_index in ssr:
  #     train_index,test_index=np.array(train_index),np.array(test_index)
  #     print(train_index.shape,test_index.shape)
  
  scores = cross_val_score(model, X, y, cv=ss_cv, verbose=True)
  print("Scores:", scores)
  print("Mean score:", scores.mean())
  ```
  

## sklearn.model_selectionä¸­çš„api

### train_test_split

- [sklearn.model_selection.train_test_split â€” scikit-learn documentation](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)

- Split arrays or matrices into random train and test subsets.

  Quick utility that wraps input validation, `next(ShuffleSplit().split(X, y))`, and application to input data into a single call for splitting (and optionally subsampling) data into a one-liner.

  å°†æ•°ç»„æˆ–çŸ©é˜µéšæœºåˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å¿«é€Ÿå®ç”¨ç¨‹åºã€‚

  è¿™æ˜¯ä¸€ä¸ªå¿«æ·å®ç”¨ç¨‹åºï¼Œå®ƒå°†è¾“å…¥éªŒè¯ã€`next(ShuffleSplit().split(X, y))`å’Œå°†å…¶åº”ç”¨äºè¾“å…¥æ•°æ®çš„æ“ä½œå°è£…æˆä¸€ä¸ªå•ç‹¬çš„å‡½æ•°è°ƒç”¨ï¼Œç”¨äºå°†æ•°æ®æ‹†åˆ†ï¼ˆå’Œå¯é€‰åœ°è¿›è¡Œå­é‡‡æ ·ï¼‰ä¸ºä¸€è¡Œä»£ç ã€‚

- ```python
  In [32]: import numpy as np
      ...: from sklearn.model_selection import train_test_split
      ...: X, y = np.arange(10).reshape((5, 2)), range(5)
      ...:
  
  In [33]: X,y
  Out[33]:
  (array([[0, 1],
          [2, 3],
          [4, 5],
          [6, 7],
          [8, 9]]),
   range(0, 5))
  
  In [36]: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
  
  In [37]: X_train, X_test, y_train, y_test
  Out[37]:
  (array([[4, 5],
          [0, 1],
          [6, 7]]),
   array([[2, 3],
          [8, 9]]),
   [2, 0, 3],
   [1, 4])
  ```

  

### å°ç»“

- æ ¹æ®æ–‡æ¡£å¯çŸ¥,`train_test_split`å€ŸåŠ©äº†`ShuffleSplit`å®ç°.è€Œä¸æ˜¯KFoldå®ç°,å› ä¸º`train_test_split`å¯ä»¥æ¥æ”¶`test_size`å‚æ•°,KFoldæ˜¯ä¸æ”¯æŒè¿™ç±»å‚æ•°çš„

- `train_test_split`æ˜¯ç”¨äºå°†æ•°æ®é›†æ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†çš„å·¥å…·ã€‚å®ƒå¯ä»¥å°†æ•°æ®é›†éšæœºåœ°æ‹†åˆ†ä¸ºä¸¤ä¸ªéƒ¨åˆ†ï¼Œä¸€éƒ¨åˆ†ç”¨äºè®­ç»ƒæ¨¡å‹ï¼Œå¦ä¸€éƒ¨åˆ†ç”¨äºæµ‹è¯•æ¨¡å‹ã€‚

  - `train_test_split`çš„ä¸€ä¸ªä¸»è¦ä¼˜ç‚¹æ˜¯å®ƒéå¸¸å®¹æ˜“ä½¿ç”¨ï¼Œåªéœ€è¦ä¸€è¡Œä»£ç å°±å¯ä»¥å®Œæˆæ•°æ®æ‹†åˆ†ã€‚ä¾‹å¦‚ï¼š

  - ```python
    from sklearn.model_selection import train_test_split
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    ```

  - åœ¨è¿™ä¸ªä¾‹å­ä¸­ï¼Œ`train_test_split`å°†æ•°æ®é›†Xå’Œæ ‡ç­¾yæ‹†åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ï¼Œå…¶ä¸­æµ‹è¯•é›†å æ€»æ•°æ®é›†çš„20%ã€‚`random_state`å‚æ•°ç”¨äºè®¾ç½®éšæœºæ•°ç§å­ï¼Œä»¥ç¡®ä¿åœ¨å¤šæ¬¡è¿è¡Œä»£ç æ—¶ï¼Œå¾—åˆ°çš„æ‹†åˆ†ç»“æœç›¸åŒã€‚

