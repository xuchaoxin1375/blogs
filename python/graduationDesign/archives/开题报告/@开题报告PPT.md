---
marp: true
# header: 'Header content'
footer: '跨库SER系统的设计与实现'
theme: gaia
class: lead

---

# 跨库语音情感识别系统的设计与实现


![bg contain left:45% 98% 在这里插入图片描述](https://img-blog.csdnimg.cn/be61e759517a4f038c3eb69928e097aa.png)


计科1902 徐超信
指导老师：蒋海华

---
<!-- paginate: true -->
## 内容目录
-  背景和意义
- 开发路径
- 实现方案
- 基础情况
---

## 背景&意义

- 语音是人与人之间最重要、便捷的交流方式，不仅包含人类所要传达的语义信息，还包含人们所要表达情感信息，语言种类等各个方面。在20世纪中期，人机交互系统一直停带于语义文本这一类文字信息的理解和表达上，因此，当时所构建的人机交互系统往往只有用户表达出中性语音时才能够有效地识别出用户意图，而对于自然状态下的情感语音理解极为不佳。
- 可见，制约着人机交互系统发展的重要因素之一在于情感智能的缺失。在此背景下，越来越多的研究者们开始着手于对情感信息的探索。语音情感识别在智能车载系统，情感机器人，医疗，服务业等领域都发挥着重要作用。

---


## 开发路径
<!-- _theme:uncover -->

![bg contain right:80% 95% 在这里插入图片描述](https://img-blog.csdnimg.cn/b0fca5b946ea4e20acc513c1ed304c50.png)


---

## 实现方案
---
### 语料库的选用



- EMO-DB : 该数据集是由 10 名演员(分别从5个男性和5个女性说话人的表演语音中获得)模拟 7 种情绪产生的 10 个德语语句, 7 种情绪分别是:中性、愤怒、恐惧、喜悦、悲伤、厌恶和厌倦, 数据库共536 个样本, 该数据库已经成为许多研究的基础。
- SAVEE: 该数据集是一个使用英国英语的多模态情感数据集。 它总共包含了 480 条语音以及 7 种不同的情感: 中性、快乐、悲伤、愤怒、惊讶、恐惧和厌恶。 这些话语由 4 个专业的男性演员产生。 为了保持情感表演的良好质量, 本数据集的所有录音均由 10 位不同的评价者在音频、视觉和视听条件下进行验证这些录音中的脚本选自常规 TIMIT 语料库。
---

- RAVDESS: 该数据集是情感语音和歌曲的多模态语料。 该数据集是性别均衡的, 由 24 名专门演员组成, 他们以中性的北美（英语）发音产生语音和歌曲样本。 对于情感性言语, 它由平静、欢乐、悲伤、愤怒、恐惧、惊讶、厌恶构成。 对于情感性的歌曲, 它由平静、欢乐、悲伤、愤怒、恐惧、惊讶、厌恶和恐惧组成。 每个表情都是在情感强度的两个层次上产生的, 带有一个附加的中性表情。 最后收集的 7 356 份录音在情感有效性、强度和真实性方面分别被评为 10 次。 对于这些收视率, 雇佣了来自北美的 247 名未经培训的研究对象。
---

- 拟选用的上述数据库既可以完成多模态的同语言不同库的跨库识别(SAVEE和RAVDESA)实验,也可以完成跨语言跨库的识别实验（EMO-DB和SAVEE或EMO-DB和RAVDESS)。其中RAVDESS虽然是单模态的语料库库，但是由于其广泛的被采用，可以用来检验SER的基本识别性能，以及和已有的实验进行对比
---

### 语音特征的提取

- 共振峰和MFCC 是语音情感识别中两种常用的特征, 共振峰(音质特征)是音质的决定因素, 可以反映声道的物理特征; MFCC 可以在很大程度上模拟人的听觉感知系统, 从而提高语音情感识别的性能。可以采用传统的特征提取器openSMILE，提取包括 共振峰、MFCC等浅层特征。

- 本系统拟将 VMD（变分模态分解） 算法应用于 GFCC 的提取过程，得到 VGFCC特征。再通过特征级融合（韵律特征、非线性特征、VGFCC特征）得到包含更全面信息的全局特征GF

---

### 分类模型的构建

___

<!-- class: default  -->
![ Schematic diagram of automatic encoder; ](https://img-blog.csdnimg.cn/457d8e29cd074d6a90126238ce5fd73e.png)

本系统拟采用栈式堆叠稀疏自编码器与核函数极限学习机结合的复合网络模型（SSAE-KELM）作为识别模型。
Stack Sparse Automatic Encoders - Kernel Extreme Learning Machine



<!-- class: lead  -->

复合网络SSAE-KELM 的结构图解
![bg contain right:70% ](https://img-blog.csdnimg.cn/63f31dd95c74414dbde9804b71b73811.png)


---

识别的流程
![  在这里插入图片描述](https://img-blog.csdnimg.cn/17fd1086b50043b2aaab511b6a675151.png)

---

基于复合网络 SSAE-KELM 语音情感识别的详细步骤如下： 
1) 多层稀疏自编码器堆叠构成栈式稀疏自编码网络，初始化 SSAE 网络参数； 
2) 选择情感语音库，按照大致 2：1 的比例将其分为训练集与测试集，并提取语音情感全局特征 GF； 
3) 从上到下无监督逐层贪婪训练每一层 SAE，实现局部最优； 
4) 结合标签通过 BP 算法微调整体网络参数，达到全局最优； 
5) 提取经过SSAE 无监督预训练有监督微调后的深度特征用于训练KELM 分类器，得到相应的KELM 参数； 
6) 保存训练好的网络参数，利用测试集对语音情感识别性能进行测试。 

---
### 小结
- 本系统采用一种复合网络栈式稀疏自编码网络——核函数极限学习机，首先通过栈式稀疏自编码网络对原始特征进行无监督预训练。
- 然后结合数据标签利用反向传播算法有监督微调，重构得到更符合大脑稀疏性且更具有区分情感信息的深度特征。
- 最后采用人工蜂群优化算法优化的核函数极限学习机对情感进行识别分类。 

---

### 语音情感识别系统的开发：

- 本系统将在windows上开发，采用python语言和PyQT技术进行图形界面的开发。深度学习框架使用pytorch。
- 系统功能：可视化地展示模型的训练过程和语音情感的识别过程。拟实现一个抑郁症患者情绪跟踪管理系统，比如日常性对病人发送问题，根据患者的回答进行情感分析，辅助医生分析患者病情走势
---

各部分间的关系
![ 在这里插入图片描述](https://img-blog.csdnimg.cn/10f77de059604bd8be125e1dd3c39d55.png)

---

## 基础状况

- 对课题要求掌握的知识总体比较陌生，主要是机器学习和深度学习的基础薄弱
- 对拟采用和实现的算法的认识处于初步认识的状态，有待后续学习和实验
- 本课题的编程环境的搭建相对简单，对python有一定基础，pytorch的使用还在学习中
- 运行环境：windows/linux+pytorch 1.11+cuda11
- 已找到一些数据集
