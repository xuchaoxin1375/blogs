## 现状和意义

### 研究现状

语音情感识别(Speech Emotion Recognition，SER)在人机交互过程中发挥极为重要的作用，近年来该领域的研究越来越受到重视。同时也是目前人机交互等领域的热门研究话题。SER的主要目的是对语音信号按照不同的情感进行分类，比如“生气”、“恐惧”、“厌恶”、“高兴”等。由于语音情感识别在人机交互和情感计算中的重要性，使得其具有十分广泛的应用。在过去的几年里，该领域研究者已经提出了许多有效的方法来解决SER中出现的问题，这些方法大部分是集中在一个单一的语音数据库上进行的。大多数的语音情感识别方法主要在单一语音数据库上进行训练和测试。这些训练数据和测试数据具有相同的声学条件，在这种条件下，现有的语音情感识别技术已经实现了较高的性能。然而，在实际应用中训练和测试集可能来自不同的语音情感数据库。用于训练的语料库与测试语料库之间往往存在非常大的差异，现实世界中的条件会更加复杂，比如含有噪音或回音的声学条件。此外，训练数据库和测试数据库可能来自多种不同的语言、不同的说话人、不同的文化、不同的数据规模等差异。由于这种不同情感数据库间存在的巨大差异性，导致大多数现有的语音情感识别方法取得的跨库识别性能欠佳。无法满足实际应用的需要。 因此，跨数据库(Cross-corpus)的语音情感识别越来越受到重视。

情感特征提取方法的进展:在手工特征提取方面，基础的方法是利用语料库归一化方法，将不同的语料库按照同样的方法进行归一化从而降低两个语料库之间的差异。这种方法虽然在一定程度上缓解了语料库之间的差异，但不同语料库之间的特征分布依然大不相同。之后出现了不同的测量语料库数据分布差异的方法，如MMD准则。许多研究者使用不同的方法将源语料库和目标语料库的样本映射到同一特征空间并在这个特征空间中利用MMD准则测量两个数据库之间的特征分布差异，最后最小化这个差异以得到域不变特征。受MMD准则的启发，一些方法联合考虑边际概率分布和条件分布，使边际分布之间的距离以及条件分布之间的距离最小，从而消除两个数据库特征分布之间的差异。除此之外，一些方法引入正则化约束来缓解两个语料库的分布差异或者利用梯度反转层形成对抗训练得到域不变特征。

为了弥补手工域特征提取方法的不足，研究者们利用深度学习技术进行自动化提取高层次特征，将提取到的深度特征进行类似于特征变换的归一化以缓解不同数据库之间的差异。一些研究者将提取到的深度低维特征运用MMD准则测量不同数据库之间的特征分布差异并最小化这种差异。使用自编码器对输入特征进行编码-解码的方法开始被应用于跨库语音情感识别，来最小化重构损失以减少域间差异。随着对抗学习的出现，一些研究者开始将对抗训练运用于跨库语音情感识别域不变特征，在此基础上有些方法将对抗训练与MMD准则相结合以减少数据库之间的特征分布差异[1]。

跨库语音情感识别是SER 领域的新兴研究方向，相关的具体研究包括：Schuller等[2] 从唤醒程度和效价维度两个方面进行了跨库语音情感识别的研究；Jeon 等[3]初步探讨了跨库SER 的相关内容；Deng 等[4]采用无监督学习的自适应自动编码器处理跨库语音情感识别的问题；Song 等[5]基于对混合因子的分析，进而研究讨论了跨库条件下的语音情感识别；张昕然[6]提出带有无限成分数的t分布混合模型（iSMM）来提高识别跨库SER性能

- Chang等[7]提出了一种多任务深度卷积生成对抗网络(deep convolutional generative adversarial networks,DCGAN),用于从未标记数据上的计算谱图中学习强特征表示,并以情绪效价为主要目标,情绪激活为次要目标进行多任务学习。
- Deng等[8]提出了一种半监督自编码器来提高跨库语音情感识别性能。在监督学习中添加一个除情感类外额外的类,当监督分类器从给定的标记数据中学习时将所有未标记的数据预测为这个额外的类。使模型可以从标记数据和未标记数据的组合中获益。该方法将无监督自编码器与深度前馈网络的监督学习目标连接,构造联合优化目标函数,确保在标记和未标记数据上最小化无监督目标的重建误差以及由监督目标测量的预测误差。提取INTERSPEECH 2009特征集作为输入。实验结果表明,该方法以极少的标记数据获得了最先进的性能。
- Latif等[9]提出了一种基于DBNs的迁移学习技术,使用的DBN由3个RBM层组成,其中前2个RBM包含1 000个隐藏神经元,第3个RBM包含2 000个隐藏神经元。采用包括韵律特征和谱特征等88个特征的e Ge MAPS特征集作为DBNs的输入。结果表明,与稀疏自编码器和SVM相比,DBNs在跨库语音情感识别上表现出更好的性能。
- Gideon等[10]提出了一个对抗鉴别域泛化(adversarial discriminative domain generalization,ADDo G)算法,该算法在特征编码和情感分类的基础上增加了测量不同数据集之间距离的模块,并迭代的将每个数据集学习到的表示移动的更近,采用生成对抗网络(generative adversarial networks,GANs) 的思想,该算法可以充分利用未标记的测试数据在不同数据集上获得域不变特征表示。他们提取40维Mel滤波器组作为算法输入,得到的实验结果表明,该算法表现优于CNNs。
- Latif等[11]提出了一种多任务半监督对抗自编码(adversarial autoencoding,AAE)方法,利用短时傅里叶变换(short time Fourier transform,STFT)得到的谱图作为AAE的输入,在对抗性自编码器中生成潜在表示,之后构建一个使用大量可用数据的多任务学习框架,将情感、说话人和性别识别作为辅助任务,利用一些有限的可用数据最终可以获得比CNN、CNN+LSTM和DBN更好的性能。
- Parthasarathy等[12]提出了一种结合无监督辅助任务的阶梯网络半监督方法,其中首要任务是预测维度情感属性,辅助任务用去噪自编码器产生中间特征表示的重构并以半监督的方式对来自目标域的大量未标记数据进行训练。以INTERSPEECH 2013特征集作为阶梯网络的输入,研究表明,与完全监督单任务学习(single-task learning,STL)和多任务学习基线相比,所提方法取得了优越的性能。
- 刘雨柔[13]基于同库实验，将 VMD算法应用于提取 GFCC 特征的过程中，提出一种情感语音特征（谱特征） VGFCC，以及一种复合网络 SSAE-KELM，提高了情感识别率

从效果上看，目前已知有多种可以提升跨库语音识别的跨库技术，其中最主要的方法是利用自编码器和基于对抗学习等域自适应方法得到域不变特征来提高分类器对目标域数据集的识别精度。

1. 张石清,刘瑞欣,赵小明。跨库语音情感识别研究进展[J]。计算机系统应用,2022,31(11):31-48。DOI:10。15888/j。cnki。csa。008811。
2. Schuller B, Vlasenko B, Eyben F, et al．Cross-corpus acoustic emotion recognition: Variances and 
   strategies[J]。 IEEE Transactions on Affective Computing, 2010, 1(2): 119-131。 
3. Jeon J H, Le D, Xia R, et al．A preliminary study of cross-lingual emotion recognition from 
   speech:Automatic classification versus human perception[C]//Proceedings of Interspeech。 Lyon, 
   France:ISCA, 2013: 2837-2840。 
4. Deng J, Zhang Z, Eyben F, et al． Autoencoder-based unsupervised domain adaptation for speech emotion recognition[J]。 IEEE Signal Processing Letters, 2014, 21(9): 1068-1072。 
5. Song P,  Zheng W。 Feature Selection Based Transfer Subspace Learning for Speech  Emotion Recognition[J]。 Ieee Transactions on Affective Computing, 2020,  11(3): 373-382。  
6. 张昕然。 跨库语音情感识别若干关键技术研究[D]。东南大学,2016。
7. Chang J, Scherer S。 Learning representations of emotional speech with deep convolutional generative adversarial networks。 Proceedings of 2017 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)。 New Orleans: IEEE, 2017。 2746–2750。
8. Deng J,Xu XZ,Zhang ZX,et al。Semisupervised autoencoders for speech emotion recognition。IEEE/ACM Transactions on Audio,Speech,and Language Processing,2018,26(1):31-43。[doi:10。1109/TASLP。2017。2759338]
9. Latif S,Rana R,Younis S,et al。Transfer learning for improving speech emotion classification accuracy。Proceedings of the 19th Annual Conference of the International Speech Communication As sociation。Hyderabad:ISCA,2018。257-261。
10. Gideon J,McInnis MG,Provost EM。Improving crosscorpus speech emotion recognition with adversarial discriminative domain generalization(ADDoG)。IEEE Transactions on Affective Computing,2021,12(4):1055-1068。[doi:10。1109/TAFFC。2019。2916092]
11. Latif S,Rana R,Khalifa S,et al。Multi-task semi-supervised adversarial autoencoding for speech emotion recognition。IEEE Transactions on Affective Computing,2022,13(2):992-1004。[doi:10。1109/TAFFC。2020。2983669]
12. Parthasarathy S,Busso C。Semi-supervised speech emotion recognition with ladder networks。IEEE/ACM Transactions on Audio,Speech,and Language Processing,2020,28:2697-2709。[doi:10。1109/TASLP。2020。3023632]
13. 刘雨柔。 基于VGFCC特征与复合网络的跨库语音情感识别[D]。太原理工大学,2020。DOI:10。27352/d。cnki。gylgu。2020。000190。

### 课题意义

利用计算机从语音信号中自动识别出说话人的情感状态，是实现自然人机交互界面的关键前提。借助语音情感识别系统，可以提升用户操作计算机的体验。由于跨库语音情感识别涉及多个学科，因此对该领域的研究还有助于促进相关学科的共同进步，具有重要的使用价值和理论价值。

语音情感识别相关技术还是情感计算的重要内容，对其理论和应用的研究必然有助于推动情感计算的发展。跨库语音情感识别系统考虑的条件相比于单数据库训练出来的SER系统更加接近实际生活，具有更好的鲁棒性和实用性，更加适应实际生活的识别要求，跨库技术的研究使SER系统在使用的时候更加有效。



跨库语音情感识别的重要意义

语音情感识别是人工智能的一个重要研究方向，它可以让计算机理解和响应人类的情感，从而实现更自然和友好的人机交互。然而，语音情感识别面临着一个挑战，就是不同语料库之间的情感差异性和相似性。不同语料库可能包含不同的语言、文化、场景、说话人等因素，这些因素会影响语音中表达的情感特征和标签。如果只使用单一的语料库进行训练和测试，那么模型可能无法泛化到其他语料库或实际应用中。

为了解决这个问题，跨库语音情感识别就显得非常重要。跨库语音情感识别是指在一个或多个源域的语料库上训练模型，并在一个或多个目标域的语料库上测试模型的性能。跨库语音情感识别可以提高模型的鲁棒性和泛化能力，使其能够适应不同的环境和用户。跨库语音情感识别也可以促进不同语言和文化之间的情感交流和理解，增强人类之间的共情。

跨库语音情感识别还有很多潜在的应用场景，例如：

- 在智能客服系统中，根据用户在不同平台或渠道上表达的情感，提供更合适和满意的服务。
- 在智能教育系统中，根据学生在不同学习环境或任务中表达的情感，提供更个性化和有效的教学策略。
- 在智能医疗系统中，根据患者在不同医疗场景或过程中表达的情感，提供更关怀和支持的医疗服务。
- 在智能娱乐系统中，根据用户在不同游戏或视频中表达的情感，提供更有趣和刺激的娱乐内容。

综上所述，跨库语音情感识别是一项具有重要意义和广阔前景的研究领域。它可以让计算机更好地理解人类多样化和复杂化的情感需求，并为人类带来更多便利和幸福。

## 二、  研究的基本内容，拟解决的主要问题：

### 研究的基本内容

本课题针对跨数据库语音情感识别技术进行相关研究，基于现有的基本理论和方法以设计和实现一个具有较好地进行跨库识别的SER系统。基于已有的多个情感语料库，提取有效的跨语料库情感特征，建立分类模型，然后对新的语音进行情感分类，最后完成语音情感识别系统的开发。

### 拟解决的主要问题

SER的研究涉及特征提取、特征优选、分类器改进、特征融合等多种技术。

跨库识别过程中，影响SER系统性能的因素有多种，包括但不限于:训练数据库和测试数据库可能来自多种不同的语言、不同的说话人、不同的文化等差异;数据库中的语音样本可能存在对上下文依赖的情况，这可能导致情感和提取的声学特征不符;不同数据库的录制过程中，录制设备和背景噪音的差异都可能导致SER系统在跨库识别任务中表现不佳。

为了得到较好的跨库语音识别的效果，采用的跨库技术应该能够较好的处理上述问题，例如：提取具有泛化性的情感特征。选择合适的跨库技术，保证系统的跨库识别效果。



## 三、  研究步骤、方法及措施：

### 研究步骤

1. 查找语音情感识别相关文献并阅读，了解基本的语音情感识别算法，分析基础算法可能导致算法在跨库识别效果不佳的问题。
2. 在网上收集实验数据，同时对查找的数据进行筛选，选出能够用于实现跨库语音识别系统设计的语音数据。
3. 通过代码对论文中的语音情感识别算法进行实现，并通过实验对比和分析现有算法的识别效果和识别性能，确定需要解决的主要问题和具体问题。
4. 根据对已有算法的分析，对实验进行总结，设计本文的跨库SER算法。将本文算法分成以下两个模块:跨库语音情感特征提取(域不变特征)提取、跨库情感分类器的设计和改进。
5. 根据对跨库语音识别相关文献的阅读和分析发现，目前已有的算法主要针对单语料库具有较好的性能和准确率，在跨库识别上性能不足，对跨库语音情感特征的提取和处理是优化跨库识别的关键，自编码器等技术的使用有助于提高识别性能。
6. 使用足量的数据对优化后的跨库SER算法进行测试，根据测试效果对算法参数等细节再调整，进一步提升识别效果。
7. 完成本文算法的调整、算法各模块定型、确定使用的参数。完成代码的集成，撰写毕业论文。
8. 总结学习过程中遇到的问题，分析本文的缺点，并进行下一步的优化与改进的思考。

### 方法和措施

- 借助深度学习的相关算法和技术设计并完成跨库SER系统。

- 分析已有的多种跨库技术，对比实验识别效果，总结各个方案的主要问题，以及可以改进的地方。
- 优化并最终确定系统采用最终算法和方案。

###  四、主要参考文献：🎈

（所列出的参考文献不得少于10篇，其中外文文献不得少于3篇。）   

-  [1] 常莹。 基于神经网络的语音情感识别方法研究[D]。 辽宁科技大学, 2020。

   [2] 陈秀珍。 基于目标适应的跨库语音情感识别研究[D]。 南京信息工程大学, 2020。

   [3] 陈颖。 双子空间迁移学习方法的跨库语音情感识别[D]。 苏州大学, 2019。

   [4] 金赟, 宋鹏, 郑文明, et al。 半监督判别分析的跨库语音情感识别[J]。 声学学报, 2015, 40(01): 20-27。

   [5] 李晓坤, 李洪亮。 基于深度迁移学习的跨库语音情感识别[J]。 通信技术, 2021, 54(04): 848-852。

   [6] 刘雨柔。 基于VGFCC特征与复合网络的跨库语音情感识别[D]。 太原理工大学, 2020。

   [7] 罗德虎, 冉启武, 杨超, et al。 语音情感识别研究综述[J]。 计算机工程与应用, 2022, 58(21): 40-52。

   [8] 牛亚峰。 基于深度学习的语音情感识别研究[D]。 重庆大学, 2018。

   [9] 宋鹏, 李绍凯, 张雯婧, et al。 基于迁移判别回归的跨域语音情感识别[J]。 信号处理: 1-13。

   [10] 宋鹏, 郑文明, 赵力。 基于特征迁移学习方法的跨库语音情感识别[C]。 第十三届全国人机语音通讯学术会议(NCMMSC2015), 2015: 118-121。

   [11] 宋鹏, 郑文明, 赵力。 基于特征迁移学习方法的跨库语音情感识别[J]。 清华大学学报(自然科学版), 2016, 56(11): 1179-1183。

   [12] 汪洋, 傅洪亮, 陶华伟, et al。 基于决策边界优化域自适应的跨库语音情感识别[J]。 计算机应用: 1-7。

   [13] 薛文韬。 语音情感识别综述[J]。 软件导刊, 2016, 15(09): 143-145。

   [14] 薛艳飞, 张建明。 基于对抗训练的跨语料库语音情感识别方法[J]。 微电子学与计算机, 2021, 38(03): 77-83。

   [15] 张石清, 刘瑞欣, 赵小明。 跨库语音情感识别研究进展[J]。 计算机系统应用, 2022, 31(11): 31-48。

   [16] 张昕然。 跨库语音情感识别若干关键技术研究[D]。 东南大学, 2016。

   [17] 张昕然, 巨晓正, 宋鹏, et al。 用于跨库语音情感识别的DBN特征融合方法[J]。 信号处理, 2017, 33(05): 649-660。

   [18] 张昕然, 宋鹏, 查诚, et al。 用于跨库语音情感识别的时频原子听觉注意模型（英文）[J]。 Journal of Southeast University(English Edition), 2016, 32(04): 402-407。

   [19] 钟琪, 冯亚琴, 王蔚。 跨语言语料库的语音情感识别对比研究[J]。 南京大学学报(自然科学), 2019, 55(05): 765-773。

   [20] 庄志豪, 傅洪亮, 陶华伟, et al。 基于深度自编码器子域自适应的跨库语音情感识别[J]。 计算机应用研究, 2021, 38(11): 3279-3282+3348。

   [21] Akcay M B, Oguz K。 Speech emotion recognition: Emotional models, databases, features, preprocessing methods, supporting modalities, and classifiers[J]。 Speech Communication, 2020, 116: 56-76。

   [22] Gideon J, Mcinnis M G, Provost E M。 Improving Cross-Corpus Speech Emotion Recognition with Adversarial Discriminative Domain Generalization (ADDoG)[J]。 Ieee Transactions on Affective Computing, 2021, 12(4): 1055-1068。

   [23] Lalitha S, Gupta D, Zakariah M, et al。 Investigation of multilingual and mixed-lingual emotion recognition using enhanced cues with data augmentation[J]。 Applied Acoustics, 2020, 170。

   [24] Laukka P, Elfenbein H A。 Cross-Cultural Emotion Recognition and In-Group Advantage in Vocal Expression: A Meta-Analysis[J]。 Emotion Review, 2021, 13(1): 3-11。

     [25] Song P,  Zheng W。 Feature Selection Based Transfer Subspace Learning for Speech  Emotion Recognition[J]。 Ieee Transactions on Affective Computing, 2020,  11(3): 373-382。  