[toc]

## 语音情感识别步骤

- 语音情感识别的主要步骤包括**语音情感特征提取**和**情感分类器设计**.
  -  近年来, 研究人员对语音情感特征提取和情感分类器设计方面的研究做出了巨大的努力 

## 跨库语音情感识别🎈

- 类似于普通的语音情感识别, 跨库语音情感识别一般也包括两个步骤: 

- **跨库语音情感特征**提取和**跨库情感分类器**的设计,
-  即对源数据库和目标数据库的语音样本提取**域不变特征**, 然后训练语音情感分类器.

### 高层次自动化特征提取

#### 传统ML算法

- 传统ML算法严重依赖于音频质量

#### DL算法

- DL算法可以从原始语音和声学特征中学习情感表征

- 传统的域不变特征提取方法侧重于手工特征的提取, 然后试图将源数据库和目标数据库映射到**同一个特征空间**, 并采用不同的方法最小化特征空间中两者的分布差异, 从而使在源数据库上训练得到的模型在目标数据库上有较好的效果.
- 但是, 手工提取的特征往往是低层次的, 与高层次的人类“情感”表达存在较大的“情感鸿沟”问题.

- 因此, 研究高层次的自动化特征提取方法用于跨库语音情感识别, 近年来备受关注.

## 语音情感数据库🎈

### 现有语音情感数据库特点

- 依据情感描述不同, 现有情感数据集可分为离散型和维度型两种. 
  - 离散型情感数据集主要包含快乐、愤怒、悲伤、中性等离散情感标签.
  - 维度型情感数据集大多是由注释者根据唤醒、效价和支配三维情感进行打分. 
  - 此外, 为更准确的描述情感, 少量的情感数据集, 如 FAU Aibo, 同时对离散型情感和维度型情感进行标注.
  - 根据数据集的**激发方式**不同, 现有情感数据集又可分为
    - 表演型、诱发型以及自然型 3 种. 
    - 其中, 表演型数据集由专业演员根据给出台词说出符合规定情感的语音并进行采集, 如 DES、SAVEE. 诱发型数据集是利用剧本引导受试者进入情境并表达相应的情感, 如ABC. 
    - 而自然型数据集多为自然环境下进行交流并收集的语音样本, 这种数据集因为环境的噪音而难以采集并注释, 是目前**数据集制作的重点和难点**.
  - 由于**人类表达情感的方式**不仅是语音, 还有<u>面部表情、文本和肢体动作</u>等, 
    - 因此除了只包含语音的**单模态数据集**之外, 还有包含语音、文本或视频的**多模态数据集**, 如 IEMOCAP、MSP-Imporv 等. 
    - 此外, 部分数据集不仅记录了语音情感标签, 而且保留了说话人和**性别相关信息**.
    -  这便于研究者利用这些信息进行与**说话人独立、与性别独立**的语音情感识别
    - 以及<u>说话人识别、性别识别</u>或将两者作为**语音情感识别的辅助任务**进行**多任务学习**.



# 跨库语音情感特征提取

- 对域不变语音情感特征的提取在跨库语音情感识别中极为重要,
- 如何提取有效的域不变特征会直接影响跨库语音情感识别的性能
-  根据使用的**样本类别信息**, 深度学习方法可以分为
  - 监督、半监督、无监督 3 种类型. 
  - 监督学习是用标记的训练数据来训练网络, 使其可以根据输入得到相应的输出[59]. 
- 与监督学习不同的是, 无监督学习是用完全无标记的训练数据训练网络[60]. 
- 半监督学习介于两者之间, 其训练数据包含标记数据和未标记数据, <u>通常假设所有训练数据来自相同或相似分布</u>[61,62]. 
- 结合监督、半监督和无监督思想来阐述**手工域不变特征提取方法**和**深度域不变特征提取方法**的各自研究进展情况.

## 手工域不变特征提取方法

### 面向监督的手工域不变特征提取方法

- Kaya等[67]提出了融合**线性说话人水平**、**非线性值水平**和**特征向量水平**的**归一化方法**,使用z-归一化用作<u>简单的跨语料库适应策略</u>,从而<u>最小化不同语料库之间的差异</u>,同时利用<u>线性核分类器</u>来提高**类分离性**.
  - 提取INTERSPEECH 2013特征集在EMO-DB,DES,e NTERFACE等5个数据集上使用极限学习机(extreme learning machine,ELM)进行情感识别.
- Zhang等[68]提出了**联合迁移子空间学习**与**回归(joint transfer subspace learning and regression,JTSLR)的迁移方法**,通过<u>最大平均差异(maximum mean discrepancy,MMD)作为偏差</u>度量测量**语料库之间特征分布差异**,同时使用**真伪标签**构建基于**监督图**的**差异度量**,可以在测量语料库之间特征分布差异的同时**保持标签上的局部结构一致性**.
  - 提取INTERSPEECH 2010的1 582个声学特征,在EMO-DB,e NTERFAC和BAUM-1数据库上用SVM对语音情感进行分类.
- Zhang等[69]提出了**联合分布自适应回归(joint distribution adaptive regression,JDAR)方法**,<u>联合考虑源语料库和目标语料库之间的边际概率分布和条件概率分布</u>来**学习回归矩阵**,减轻他们之间的**特征分布差异**.
  - 该方法提取了IS09和IS10特征集,在EMO-DB、e NTERFACE和CASIA数据集上进行实验,并<u>与如Da LSR、Do SL等方法进行比较</u>,<u>取得了更好的性能</u>.

#### 小结🎈

- 针对语料库之间的**固有差异**,Kaya等[67]使用了<u>简单的归一化方法进行差异消除</u>.
- 但简单的归一化方法只能在一定程度上**缓解语料库差异**,因此Zhang等[68]提出了用MMD作为偏差度量测量语料库之间的分布差异;
- Zhang等[69]联合考虑源语料库和目标语料库之间的边际概率分布和条件概率分布来减轻他们之间的特征分布差异.
- 以上监督学习是在**已知目标域标签**的基础上学习语料库的差异,但<u>**现有的有标签数据集有限**</u>,因此<u>仅使用监督学习进行跨库语音情感识别是不够的</u>.



### 面向无监督的手工域不变特征提取方法

- Zong等[70]提出了基于域自适应最小二乘回归(domain adaptive least squares regression,Da LSR)模型的跨库语音情感识别方法.先提取包括韵律特征和谱特征等384个特征,然后从目标语料库中选择一组未标记样本,与源语料库中标记样本共同训练最小二乘回归(least squares regression,LSR)模型.同时,在LSR中引入正则化约束来缓解两个语料库的分布差异.使用EMO-DB,e NTERFACE等语料库上进行了实验,最后通过线性SVM对语音情感进行分类.
- Song等[71]提取包含韵律特征、音质特征和谱特征等1 582个声学特征,然后利用非负矩阵分解(nonnegative matrix factorization,NMF)方法获得源语料库和目标语料库的低维情感特征.同时采用MMD进行相似度度量测量两个语料库之间的特征分布差异,最后提出联合优化NMF和MMD的转移非负矩阵分解(transfer non-negative matrix factorization,TNMF)方法以最小化特征分布差异,在FAU Aibo,e NTERFACE和EMO-DB三个数据集上进行实验,获得了优于线性SVM的性能.
- Mao等[72]提出了情感差异性和域不变特征学习(emotion-discriminative and domain-invariant feature learning method,EDFLM)方法.他们提取INTER-SPEECH-2009特征集作为输入,通过情感辨别器将输入分为情感相关和情感无关,随后将情感相关特征输入域鉴别器,同时引入梯度反转层混淆域鉴别器,从而得到领域不变特征.最后在FAU Aibo,ABC和EMO-DB数据集上使用SVM对语音情感进行分类.
- Liu等[73]提取了与文献[70]相同的特征,结合域自适应子空间学习(domain-adaptive subspace learning,Do SL)方法来学习投影矩阵,利用MMD准则测量平均投影源语音特征向量和平均投影目标语音特征向量之间的距离差,随后使用文献[71]中的联合优化方法使源语音信号和目标语音信号在标签空间中的特征分布相似,通过线性SVM对目标语音信号的情绪状态进行准确预测,获得了比最新的跨库语音情感识别方法更有前景的结果.
- Liu等[74]提取INTERSPEECH 2009特征集,通过转移子空间学习方法学习投影矩阵,将源和目标语音信号从原始特征空间转换到标签空间,在此空间中利用MMD准测度量两个语料库之间差异并通过TNMF方法最小化语料库差异,最后,在标记的源语音信号上训练的分类器可以有效地预测未标记目标语音信号的情感状态.
- 针对无标签数据集,最具挑战的方法是使用无监督学习方法在**不访问目标域数据集标签**的前提下提高跨库SER的性能.

#### 小结

- Zong等[70]在LSR中**引入正则化约束**来缓解两个语料库的**分布差异**.
- Song等[71]使用MMD进行**<u>语料库差异的测量</u>**.而语料库之间存在差异的<u>根本原因</u>是两个语料库的<u>特征分布不同</u>,因此学习不同语料库的特征分布并<u>找到不同语料库相似的部分</u>,即**域不变特征**,是非常重要的.
- 为此,Mao等[72]将<u>情感相关特征</u>输入**域鉴别器**,从而得到**领域不变特征**.进一步将**源域和目标域**数据集的语音样本投影到同一**子空间**中,然后使用MMD可以更加准确有效的<u>测量数据集间的差异</u>.
- 因此,Liu等[73]结合Do SL方法来**学习投影矩阵**,
- Liu等[74]通过**转移子空间学习方法**学习**投影矩阵**,并将**语音信号转换至标签空间**.

- 无监督学习在跨库语音情感识别任务上**被证明是有效的**,但由于无监督学习<u>不访问任何目标域数据集标签</u>,因此<u>对跨库语音情感识别性能的提升有限</u>.
- 若在模型训练时<u>可以访问部分目标域标签</u>,这将<u>使模型更容易对目标域进行情感分类.</u>

### 面向半监督的手工域不变特征提取方法

- 金赟等[75]采用半监督判别分析方法来减小不同语料库之间的差异.先对每条语句提取988个特征,包括韵律特征(基频和基音频率包络)、谱特征(MFCC)等26个LLDs及其相应的一阶差分,然后结合线性判别分析的思想,使类间散度矩阵和类内散度矩阵的比值达到最大,寻找有标签样本与目标语料库部分无标签样本之间的最优投影方向得到投影向量,将训练样本向此投影方向投影得到情感分类面,随后将测试样本向投影向量方向投影,由训练样本得到的分类面同样适用于测试样本,从而提高跨库识别率.在EMO-DB和e NTERFACE数据库上进行实验,最后使用SVM作为情感分类器实现跨库语音情感识别.
- 宋鹏等[76]提出一种基于特征迁移学习的跨库语音情感识别方法.利用open SMILE工具对每个语音样本提取出INTERSPEECH 2010竞赛中使用的特征集,共1 582维特征,引入映射函数将源语料库的有标签样本和目标语料库的无标签样本映射到低维空间,然后用MMD判断低维空间中不同数据库情感特征之间的相似度并通过半定规划进行优化从而得到域不变特征.为了更好地保证情感信息的类别区分度,进一步引入半监督判别分析方法用于特征降维.最后,采用传统SVM方法作为情感分类器,在EMO-DB和e NTERFACE数据库上进行了跨库语音情感识别实验.
- Luo等[77]提出了<u>半监督自适应正则化转移非负矩阵分解</u>(semi-supervised adaptive regularization transfer non-negative matrix factorization,SATNMF)方法,将训练数据的标签信息与NMF相结合,寻找一个潜在的**低秩维特征空间**,在这个特征空间中,利用MMD测量两个语料库之间的差异以及两个语料库中每个类的差异,同时最小化这两种差异使两个语料库的**边际和条件分布相似**.他们提取了与文献[67]相同的特征,在CASIA,EMO-DB和e NTERFACE等数据集上使用线性SVM对情感进行识别.
- Luo等[78]提出了基于非负矩阵分解的迁移子空间学习(nonnegative matrix factorization based transfer subspace learning,NMFTSL)方法,为源语料库和目标语料库找到一个共享特征子空间,在子空间中,使边际分布之间的距离以及条件分布之间的距离最小,从而消除两个分布之间的差异.该方法提取包含韵律特征、音质特征和谱特征等1 582个声学特征,在CASIA、SAVEE、IEMOCAP等6个数据集上使用线性SVM对情感进行分类.

#### 小结

- 使用半监督的方法学习<u>源域数据集和部分目标域数据集的公共信息</u>是跨库语音情感识别的另一种方法.
- 在跨库的条件下,影响语音情感识别率的因素<u>不仅有域间差异</u>,还有<u>源域和目标域的**类区分度**</u>.
- 因此,在类区分度上,金赟等[75]结合**线性判别分析的思想**来提升源域和目标域的类区分度.
- 而同时考虑**类区分度和领域对齐**是解决跨库语音情感识别问题的一个有效方法.
- 为此,宋鹏等[76]用MMD判断低维空间中<u>不同数据库情感特征之间的相似度</u>,并引入**半监督判别分析方法**保证情感信息的类别区分度.
- 为了**估计目标语料库的条件分布**,Luo等[78]将<u>目标标签的预测和特征表示</u>的学习<u>整合到一个联合学习模型</u>中,最后提出了一种区分损失来<u>将标签引入共享子空间</u>,从而<u>提高特征表示的区分能力</u>.

### 小结🎈

- 手工域不变语音情感特征提取方法的总结与比较见

  - 重点是**跨库方法**

  - ![image-20230105151906689](D:\repos\blogs\graduationDesign\assets\image-20230105151906689.png)

- 在结合手工特征的域不变语音情感特征提取方法中,基础的方法是利用语料库归一化方法,将<u>不同的语料库按照同样的方法进行归一化</u>从而降低两个语料库之间的差异.

- 这种方法虽然在一定程度上缓解了语料库之间的差异,但<u>不同语料库之间的特征分布依然大不相同</u>.之后出现了不同的测量语料库数据分布差异的方法,如MMD准则.

- 因此许多研究者<u>使用不同的方法将源语料库和目标语料库的样本映射到同一特征空间</u>并在这个特征空间中利用MMD准则测量两个数据库之间的特征分布差异,最后<u>最小化这个差异</u>以得到域不变特征.受MMD准则的启发,一些方法<u>联合考虑边际概率分布和条件分布</u>,使边际分布之间的距离以及条件分布之间的距离最小,从而<u>消除两个数据库特征分布之间的差异</u>.除此之外,一些方法<u>引入正则化约束来缓解两个语料库的分布差异</u>或者利用<u>梯度反转层形成对抗训练得到域不变特征</u>.

- **手工语音情感特征**多为简单的**浅层特征**,只能包含**语音信号的部分信息**.
- 探索使用语音信号中**更深层次的特征**进行跨库语音情感识别是**进一步提升模型对目标域情感识别率**是一个重要研究方向.

## 深度域不变特征提取方法

- 由于手工提取特征**耗资耗时**且**<u>不能完整表示语音信号的特征</u>**,因此研究者尝试**将深度学习技术**应用于跨库语音情感识别,常用方法有CNNs、RNNs、LSTM以及DBNs等.
  - [Convolutional neural network - Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network)
- CNNs首先由Le Cun等[[79](javascript:void(0);)]在1989年首次提出,用于手写邮编识别.CNNs的一个重要特性是可以<u>自动从输入数据中学习特征</u>,并具有一定的**泛化能力**,因此关于<u>解决此问题的应用均可以使用CNNs.</u>
  - 一个基础的CNNs包括**卷积层、激活层和池化层**,有些网络还包含**全连接层**.
  - 在跨库语音情感识别中主要用于**提取语音片段的局部特征**.
- 为了更好地捕捉**深层连接**,很多学者开始将RNNs应用于语音情感识别中.
  - 一个简单的RNNs由输入层、隐藏层和输出层组成,核心为一个全连接的循环单元,采用递归连接来捕获数据的历史信息,使其可以在网络内部循环.
  - 然而RNNs的一个**重要缺陷**是容易出现**梯度消失和爆炸问题**
  - 1997年Hochreiter等[[32](javascript:void(0);)]为了缓解这个问题提出了LSTM.
  - LSTM是RNNs的**扩展**,在其内部加入了
    - **遗忘门**,输入门,候选细胞单元和输出门,
    - 通过**门控状态**来<u>控制传输状态</u>,
      - 记住需要长时间记忆的
      - 忘记不重要的信息.
- DBNs是神经网络的一种,由一系列叠加受限玻尔兹曼机(restricted Boltzmann machine,RBM)组成,
  - RBM由<u>用于输入训练数据的</u>**显层**和<u>用作特征检测器</u>的**隐层**构成.
  - DBNs中的相邻层可以看作是多个独立的RBM的堆积,上一个RBM的隐层的输出即为下一个RBM的输入.
  - DBNs既可以作为自编码器,也可以作为**分类器**.

#### 2.2.1 面向监督的深度域不变特征提取方法

Zhang等[[80](javascript:void(0);)]提出一种基于时频原子的听觉注意特征提取模型,该模型模拟人类听觉系统,首先计算语音声谱图,之后从声谱图中提取多尺度情感对比特征,然后对多尺度情感特征进行有效探测,之后引入Chirplet时频原子,通过形成的过完备原子库提高语谱图特征的信息量.在e NTERFACE、EMO-DB等数据库上的实验结果表明在跨库的情况下具有更好的鲁棒性.

Marczewski等[[81](javascript:void(0);)]提出了一种由2个一维CNN层、1个LSTM层和2个全连接层组成的深度学习网络体系结构进行语音情感识别,其中CNN层获取不同抽象层次的空间特征,LSTM层学习与情绪随时间演化相关的时间信息.该网络从输入音频样本接收54 000维数据点,之后联合利用CNNs提取领域共享特征和LSTMs识别具有领域特定特征的情绪.在6个不同数据库上的实验表明,它们可以学习可转移的特征,使模型能够从多个源域适应.

Parry等[[82](javascript:void(0);)]对CNN、LSTM和CNN-LSTM等深度学习模型的泛化能力进行了比较分析,探索3种模型在跨库语音情感识别方面的性能.其中CNN由一维卷积层和一个max-pooling层组成;LSTMs为双层双向LSTMs;CNN-LSTM包含3个CNN和两个双层双向LSTMs.提取40个Mel滤波器组系数后,他们在IEMOCAP,EMOVO,EMO-DB等6个数据集上进行了实验,结果表明,CNN和CNN-LSTM模型的性能非常接近,但优于LSTM.

Rehman等[[83](javascript:void(0);)]提出了一种由LSTM和分支层组成的RNN网络,该方法以MFCCs为输入,分支层从语音信号的MFCCs中提取信息并对提取的表征进行分类,LSTM处理语音的时序性和时间动态,最后使用Softmax层对目标语料库的语音情感进行预测,并且获得了40%–45%的UAR.

Seo等[[84](javascript:void(0);)]提出了融合视觉注意CNN和视觉词袋的跨语料库语音情感识别方法,使用具有2D CNN的视觉注意卷积神经网络(visual attention convolutional neural network,VACNN)在一个大的语音数据集进行预训练,并对一个小的语音数据集进行微调,以识别话语中的情绪,并使用视觉词包(bag of visual words,BOVW)提取特征向量帮助VACNN学习log-Mel谱图中的全局和局部特征,最后,利用Softmax对小数据集进行情感分类.实验结果表明,与现有最先进的跨语料库SER方法相比,分别提高了7.73%、15.12%和2.34%.

Lee[[85](javascript:void(0);)]提出了一个基于三元网络的计算框架,该网络包括具有共享参数的同一前馈网络的3个特征,利用三元网络进行特征变换,将归一化特征映射到一维欧几里得空间从而减少源和目标语料库之间的内在差异,学习在多个语料库中不变的情感语言的更一般化的特征.实验使用1 582个静态特性,然后使用三重网络对特征进行特征变换,并在IEMOCAP、MSP-IMPROV等数据集上进行实验,最后使用作为分类器的前馈网络对情感进行分类.

庄志豪等[[86](javascript:void(0);)]提出一种基于深度自编码器子域自适应的跨库语音情感识别算法,采用两个深度自编码器分别获取源域和目标域表征性强的低维情感特征,然后,利用基于局部最大均值差异(local maximum mean discrepancy,LMMD)的子域自适应模块,实现源域和目标域在不同低维情感类别空间中的特征分布对齐.在e NTERFACE和EMO-DB数据库上进行了跨库实验,该方法的识别准确率得到了一定程度的提高.

#### 小结

- 深度学习在语音情感识别中已经取得良好的进展,但将其应用到跨库语音情感识别的研究还不够深入.
- Zhang等[[80](javascript:void(0);)]提出一种基于时频原子的听觉注意特征提取模型用于跨库语音情感识别,证明了深度学习可以提高跨库语音情感识别的性能.
- 之后,一些研究者开始对比各种深度模型在跨库语音情感识别任务中的表现.Marczewski等[[81](javascript:void(0);)]提出了一种由2个一维CNN层、1个LSTM层和2个全连接层组成的**深度学习网络**(组合学习网络);
- Parry等[[82](javascript:void(0);)]比较了CNN、LSTM和CNN-LSTM等**深度学习模型**在跨库语音情感识别方面的性能,结果表明,CNN和CNN-LSTM模型的性能优于LSTM.
- Seo等[[84](javascript:void(0);)]将**视觉模型**应用于跨库语音情感识别中.
  - 这是一种新颖的方法,也是未来跨库语音情感识别可以继续探索研究的方向.

- <u>与结合手工特征的方法类似</u>,Lee[[85](javascript:void(0);)]利用**三元网络**进行特征变换得到**语料库归一化特征**.
- 归一化方法只能初步降低语料库差异,但不能解决其根本原因.
- 而**自编码器**因其可以<u>消除语音信号中多余的信息</u>,在跨库语音情感识别中受到广泛应用.
  - 庄志豪等[[86](javascript:void(0);)]用<u>两个深度自编码器分别获取源域和目标域的低维情感特征</u>,然后利用LMMD实现源域和目标域的特征分布对齐.
- 综上所述,深度学习可以显著改善不同语料库条件下的语音情感识别率,进一步设计其他更先进的深度模型以减小不同语料库特征分布差异需要更深层次的探索.

#### 2.2.2 面向无监督的深度域不变特征提取方法

张昕然等[[87](javascript:void(0);)]利用深度学习领域的深度信念模型,提出了基于深度信念网络的特征层融合方法,将语音频谱图中隐含的情感信息作为图像特征,与传统情感特征融合.通过在ABC数据库和多个中文数据库上的实验验证,特征融合后的新特征子集相比传统的语音情感特征,其跨数据库识别结果获得了明显提升.

Deng等[[88](javascript:void(0);)]提出了一种新的端到端域自适应方法,称为Universum自动编码器(Universum autoencoder,U-AE).该方法旨在使无监督学习自编码器具有监督学习能力,从而提高语音情感识别的性能.该方法将未标记样本用作SVM目标函数的惩罚项,并经基于边际的损失引入深度自动编码器中,通过同时从标记和未标记数据中学习公共知识以减少训练数据和测试数据之间的不匹配.实验使用INTERSPEECH 2009特征集作为输入,结果表明,该方法优于其他领域自适应方法,如核均值匹配[[89](javascript:void(0);)]和共享隐藏层自编码[[90](javascript:void(0);)].

Abdelwahab等[[91](javascript:void(0);)]将领域对抗神经网络(domain adversarial neural network,DANN)用于跨语料库语音情感识别中,该网络旨在学习未标记源数据和目标数据之间灵活且具有判别性的特征表示.引入领域鉴别器区分源域和目标域,同时使用梯度反转层混淆领域鉴别器,经过对抗训练得到领域不变特征.提取INTER-SPEECH 2013特征集作为DANN的输入进行实验,结果表明,基于未标记训练数据的对抗训练相对于仅使用源数据的训练,获得了约27.3%的性能提升.

Neumann等[[92](javascript:void(0);)]在未标记数据上训练一个递归的序列到序列自编码器,然后采用它对标记目标数据产生特征表示,这些产生的特征表征随后在使用的注意型CNN的训练过程中被整合为额外的源信息用于情感识别,从而提高了语音情感识别的性能.

Liu等[[93](javascript:void(0);)]提出了一种新的深度域自适应卷积神经网络(deep domain-adaptive convolutional neural network,DDACNN)模型,模型以源语料库的有标记谱图和目标语料库的无标记谱图作为输入,用深度卷积神经网络(deep convolutional neural network,DCNN)进行特征提取并利用MMD准则在DCNN中添加域自适应层以缩小源语料库与目标语料库特征分布的差异,学习语料库不变特征,最后由一个Softmax层执行最终的情感分类任务.实验结果表明DDACNN通过添加一层域自适应在最初的全连接层能有效处理跨库语音情感识别问题.

Su等[[94](javascript:void(0);)]提出了使用条件循环情感生成对抗网络(conditional cycle emotion generative adversarial network,CCEmo GAN)合成源域样本,这些样本是目标域感知的.该网络学习源语料库和目标语料库之间的双向映射函数,此外利用一个情感条件向量约束生成对抗训练,该方法使用目标和源双向数据增强作为一种策略,以情绪一致的方式增加可变性,以改善从源到目标的情绪转移性.以IEMOCAP数据库为源语料库,以MSP-IMPROV和CIT数据库为目标语料库,提取1 582个维度的话语级功能特性进行实验,结果表明,增加源域的目标域感知可变性可以提高跨语料情感识别中的情感可分辨性.

Chang等[[95](javascript:void(0);)]提出了最大回归差异(maximum regression difference,MRD)网络,使用编码器对样本进行编码,用两个回归器对样本标签进行回归预测,最大化两个预测回归器的分布差异,最小化来自编码器的回归器的分布差异形成对抗训练以增强源和目标的语义一致性.该方法提取IS10特征集作为MRD网络的输入,在IEMOCAP、MSP-Podcast、MSP-IMPROV三个数据集上进行跨库实验,并取得了比DANN网络更好的结果.

Ahn等[[96](javascript:void(0);)]提出了一种基于少样本学习和无监督域自适应(few-shot learning and unsupervised domain adaptation,FLUDA)的跨语料库语音情感识别方法,该方法通过训练从源域样本中学习适应于目标域的类相似度,采用少样本学习进行跨语料库的语义搜索,并且使用无监督域自适应提取独立于领域的情感特征.实验使用1 582维声学特征集IS10,以IEMOCAP和CREMA-D数据库作为源语料库,以MSP-IMPROV、EMO-DB数据库作为目标语料库进行实验,最后由最后一层为Softmax激活函数的3个全连接层作为分类器对4种种音情感进行分类,实验结果表明,该算法能够有效地提高交叉语料搜索的性能.

#### 小结

- **语音频谱图**不仅包含类似手工特征的**全局信息**,并且具有**语音信号的时间信息**,
- 张昕然等[[87](javascript:void(0);)]将其与其他**特征进行融合**可以得到**更适用于跨库语音情感识别的输入特征**.
- 由于无监督方法不能访问目标域数据集标签,这会造成模型学习到与情感无关的信息.
- 为了解决这个问题,Deng等[[88](javascript:void(0);)]使用<u>无监督自编码器提取与情感高度相关的特征</u>,并将<u>未标记样本用作SVM目标函数的惩罚项</u>.
- 这种**基于分类器对齐**的方法通过将<u>目标域标签信息迁移到源域</u>,并共同训练分类器以减少对目标域情感分类时产生的错误识别率.
- 与此对应的,将目标域特征分布的知识迁移到源域也是极为重要的.

- Abdelwahab等[[91](javascript:void(0);)]将DANN用于跨语料库语音情感识别中,这种**基于对抗学习的方法**提取域不变特征是如今跨库语音情感识别的一个热点.
- 进一步,Liu等[[93](javascript:void(0);)]<u>将MMD与深度学习模型相结合</u>以缓解域差异;
- Su等[[94](javascript:void(0);)]使用CCEmo GAN合成源域样本来**增强源语料库的可变性**而非学习语料库之间的域不变特征.
- 在面对目标数据集标签稀少的问题,Ahn等[[96](javascript:void(0);)]采用少样本学习进行跨语料库的语义搜索.

#### 2.2.3 面向半监督的深度域不变特征提取方法

- Chang等[[97](javascript:void(0);)]提出了一种**多任务深度卷积生成对抗网络**(deep convolutional generative adversarial networks,DCGAN),用于从未标记数据上的计算谱图中学习强特征表示,并以情绪效价为主要目标,情绪激活为次要目标进行多任务学习.

- Deng等[[98](javascript:void(0);)]提出了一种半监督自编码器来提高跨库语音情感识别性能.在监督学习中添加一个除情感类外额外的类,当监督分类器从给定的标记数据中学习时将所有未标记的数据预测为这个额外的类.使模型可以从标记数据和未标记数据的组合中获益.该方法将无监督自编码器与深度前馈网络的监督学习目标连接,构造联合优化目标函数,确保在标记和未标记数据上最小化无监督目标的重建误差以及由监督目标测量的预测误差.提取INTERSPEECH 2009特征集作为输入.实验结果表明,该方法以极少的标记数据获得了最先进的性能.

- Latif等[[99](javascript:void(0);)]提出了一种基于DBNs的迁移学习技术,使用的DBN由3个RBM层组成,其中前2个RBM包含1 000个隐藏神经元,第3个RBM包含2 000个隐藏神经元.采用包括韵律特征和谱特征等88个特征的e Ge MAPS特征集作为DBNs的输入.结果表明,与稀疏自编码器和SVM相比,DBNs在跨库语音情感识别上表现出更好的性能.

- Gideon等[[100](javascript:void(0);)]提出了一个对抗鉴别域泛化(adversarial discriminative domain generalization,ADDo G)算法,该算法在特征编码和情感分类的基础上增加了测量不同数据集之间距离的模块,并迭代的将每个数据集学习到的表示移动的更近,采用生成对抗网络(generative adversarial networks,GANs)[[101](javascript:void(0);)]的思想,该算法可以充分利用未标记的测试数据在不同数据集上获得域不变特征表示.他们提取40维Mel滤波器组作为算法输入,得到的实验结果表明,该算法表现优于CNNs.

- Latif等[[102](javascript:void(0);)]提出了一种多任务半监督对抗自编码(adversarial autoencoding,AAE)方法,利用短时傅里叶变换(short time Fourier transform,STFT)得到的谱图作为AAE的输入,在对抗性自编码器中生成潜在表示,之后构建一个使用大量可用数据的多任务学习框架,将情感、说话人和性别识别作为辅助任务,利用一些有限的可用数据最终可以获得比CNN、CNN+LSTM和DBN更好的性能.

- Parthasarathy等[[103](javascript:void(0);)]提出了一种结合无监督辅助任务的阶梯网络半监督方法,其中首要任务是预测维度情感属性,辅助任务用去噪自编码器产生中间特征表示的重构并以半监督的方式对来自目标域的大量未标记数据进行训练.以INTERSPEECH 2013特征集作为阶梯网络的输入,研究表明,与完全监督单任务学习(single-task learning,STL)和多任务学习基线相比,所提方法取得了优越的性能.

- 


#### 小结🎈

- 在结合深度特征的域不变特征提取方法中,也可以应用半监督学习来**提升模型的泛化性**.
- 在半监督学习中,常用的是<u>基于对抗学习或者基于自编码器的方法</u>,这两种方法各有其优缺点.
  - 基于自编码器的方法可以得到**与情感高度相关的特征**,但在<u>特征分布对齐上效果不佳</u>.
  - 基于对抗学习的方法可以**有效的对齐特征分布**以**减少域差异**,但**训练所需的时间较多**且**模型复杂**
  - 这是未来跨库语音情感识别要解决的问题.

### 2.2.4 小结

- 深度域不变特征提取方法的总结与比较见附录中的表A3.
  - ![image-20230105152211425](D:\repos\blogs\graduationDesign\assets\image-20230105152211425.png)
- 在跨库语音情感识别任务的初期,许多研究者开始探索<u>不同的深度学习模型在跨库语音情感识别任务上的性能</u>,如CNN,LSTM等.
- 除此之外,一些研究者在针对单数据库语音情感识别时也会研究他们的模型在跨库语音情感识别方面的性能.
- 与结合手工特征的域不变语音情感特征提取方法相似,之后出现了将提取到的<u>深度特征进行类似于特征变换的归一化</u>以缓解不同数据库之间的差异.但这种方法同样没有考虑数据库之间的特征分布差异.
- 随后,一些研究者将提取到的**深度低维特征**运用MMD准则<u>测量不同数据库之间的特征分布差异</u>并最小化这种差异.
- 在跨库语音情感识别任务中另一个常用的方法是使用自编码器对输入特征进行编码-解码,并最小化重构损失以减少域间差异.
- 随着对抗学习的出现,一些研究者开始将对抗训练运用于跨库语音情感识别<u>域不变特征</u>.
- 在此基础上有些方法将对抗训练与MMD准则相结合以减少数据库之间的特征分布差异.
- 除以上方法之外,一些学者还探索了其他适用于跨库语音情感识别任务的方法,比如将<u>目标域未标记样本作为惩罚项</u>或者运用少样本学习的思想进行跨库语音情感识别.

### 3 结论与展望🎈

- 语音情感识别因为其简单、交互直观且在人机交互中的重要性使得其应用十分广泛,现有的语音情感识别技术已经实现了较高的性能,但在跨库语音情感识别方面还存在很多问题.

- 在语音情感识别任务提出以来,已经建立了大量的语音情感数据集,但由于在自然环境下收集语音样本会受嘈杂的环境影响,因此<u>现有的自然型野外数据集稀少</u>.
- 如何在自然环境中<u>收集到干净的语音信号</u>以及<u>对嘈杂的语音信号进行数据增强</u>是在<u>数据集建立方面</u>的一个研究方向.此外因为对数据集<u>进行注释</u>难度较大,如何使用现有的数据集对未知数据集进行情感注释是需要进一步探讨的问题.

- 在跨库语音情感识别任务中,先前的工作是结合手工特征并利用归一化方法、MMD准则等方法消除数据集间的差异,对齐数据集间特征分布.
- 之后,深度学习被证明可以有效提高模型对语音情感的识别精度而被广泛应用.
- 因此,越来越多的利用深度学习模型进行跨库语音情感识别的方法被提出.
  - 其中最主要的方法是利用<u>自编码器、基于对抗学习</u>等**域自适应方法**得到**域不变特征**来提高分类器对目标域数据集的识别精度.
  - 但深度学习主要提取更深层次的情感特征,而**浅层特征同样重要**,应全面考虑.
  - 此外,如<u>对抗训练等深度模型参数量较大,不易训练</u>.

- 综上所述,尽管基于深度学习的跨库语音情感识别近年来取得了很大的进展,但仍存在一些问题与挑战:
  - 1)大部分数据集只由少量的受试者进行录音,并且大多数为未经过训练的非专业演员进行模拟不同情感类型得到的,但**这种模拟情感的真实度不高**.
  - 此外,进行人工标注的数据集,参与者较少,<u>更多的参与者可能会提高数据集的可靠性</u>[[45](javascript:void(0);)];
  - 2)目前的方法集中在识别情绪标签上的差异,但识别除情绪标签外的其他差异也可能会提高跨库语音情感识别的精度[[83](javascript:void(0);)];
  - 3)针对变异性较大的源域,应该使用更多的情感数据库,建立一个庞大的情感库来<u>评估域自适应的效率</u>[[95](javascript:void(0);)];
  - 4)现有深度学习方法主要用于学习高层次的特征进行情感标签预测而忽略了与情绪相关的低级特征,因此,未来的工作可以考<u>虑融**合面向跨库的**低层次特征和高级特征</u>来改善语音情感识别的性能[[84](javascript:void(0);)];
  - 5)尽管如今的深度学习技术日渐成熟,但仍存在一些问题,
    - 如网络的参数较多,计算量大,并且需要大量的样本训练进行训练,因此未来对深度网络进行压缩是一个重要的研究方向;
  - 6)对于现有数据集标签稀疏问题,除少样本学习之外,零样本学习等元学习策略同样可以应用于跨库语音情感识别中.

### 小结🎈



