[toc]



# 摘要

如今,语音情感识别(SER)因其广泛的现实应用,而成为研究人员的一个重要研究领域。SER系统面临着许多挑战，如合适的情感数据库的可用性、相关特征向量的识别以及合适的分类器。本文主要从语音数据库、语音特征、传统机器学习(ML)分类器和 深度学习(DL)方法等对 语音情感识别的相关文献进行分析，并对未来的研究方向进行了展望。近年来,研究者对使用深度学习方法进行语音情感识别越来越兴趣,并且用该方法改善了识别率。本综述的重点是用于语音情感识别的深度学习方法从2000年至2021年，我们共回顾了152篇论文。我们已经确定了常用的语音数据库和使用深度学习方法实现的相关精度。我们同时总结了深度学习方法用于语音情感识别方面的动力和局限性。



# 引言

情感是人类现实生活中的一个重要因素。人类情感可以被诸如手势,面部表情,身体姿态言语交流。许多物理属性也被用于人类情感识别,例如体温,心率,血压,肌肉活动,皮肤电阻[1]。 人类情感也可以通过语音交流被良好的识别。从语音中识别出人类情感的一个基础问题是从给定的说话者的一段语音信号中识别情感状态。语音情感识别有三个重要的因素：“说了什么”，即内容，“怎么说”，即说话的方式/风格，以及“谁在说”（即男性还是女性）。过去的几十年里,从语音中识别情感是研究人员不断增长的研究领域,因为它在许多现实生活中的问题,例如呼叫中心对话自动回复系统,在线辅导,对话系统,疼痛识别,抑郁诊断等。一个传统的语音情感识别系统是通过语音信号识别情绪状态,而没有用到语言知识 [2]。研究人员面对的第一个挑战是确定哪种相关信息(语音特征)能够从语音信号中被提取出来用于识别情感状态[3-4] ,第二个挑战是确定合适的分类器[5]。在过去的十年里,深度学习已经成为一种新的有吸引力的机器学习算法。深度学习算法通常是具有多个层的线性和非线性操作的神经网络的扩展。为了增强计算机的能力,大量地深度学习方法被使用，以便计算机能够理解人类可以做什么，包括从语音中识别情感。在语音情感识别的批判性分析中，有三个主要因素，如语音情感数据库、语音特征和分类器。本文包括2000年至2021关于语音情感数据库、语音特征以及基于传统机器学习和深度学习方法的详细文献。尽管许多论文对语音情感识别的现有研究进行了综述，但它们试图提供现有文献的分析信息和所述期间语音情感识别的结果。对于语音情感识别,手工语音特征能够用于机器学习方法,例如支持向量机(SVM),高斯混合模型(GMM),隐马尔可夫模型(HMM),k近邻,决策树等算法的输入。深度学习算法,例如卷积神经网络(CNN),递归神经网络(RNN),长短时记忆(LSTM),动态贝叶斯网络(DBN),受限玻尔兹曼机(RBM),自编码器等能够从语音中自动学习特征。深度学习算法也能够提取语音的谱图特征,语音情感识别的所有流程如图一所示。

图1展示了语音识别的过程,它被分为三个类别。在第一个类别是应用于机器学习算法的从语音信号中提取手工特征第二个类别中,深度学习方法要么使用手工提取特征,要么使用从语音信号的不同计算层中自动学习到的特征。第三个类别中,语音信号被转化为谱图,并使用了深度学习方法。本研究调查的主要贡献记录表如下。

从语音数据库、语音特征、传统ML方法和DL方法等方面全面分析了SER的文献综述。确定SER系统文献综述的重要研究问题。根据文献综述中研究问题的答案总结研究结果。总结从言语中识别情绪的DL方法的动机和局限性。本文的其余部分组织如下。第2节简要介绍了本文献的研究目标和方法。第3节从三个主要部分（即语音情感数据库、语音特征和分类器）讨论了SER系统文献综述的详细分析。第4节根据研究问题的答案讨论了系统文献综述的调查结果。最后，第5节讨论了结论和未来方向。本文献综述论文的目标是根据情感语音数据库,语音特征,分类器,尤其是深度学习,检查语音情感识别相关研究论文。

# 研究目标与方法

## 研究问题

确定的研究问题如下:

- 研究问题1:用于搜索本文献综述中的研究论文的各种来源是什么？
- 研究问题2:什么类型的语音数据库被用于语音情感识别?
- 研究问题3:哪些语言的有可用的情感语音数据库?
- 研究问题4:哪些语音数据库经常被语音情感识别的研究者使用?
- 研究问题5:什么语音特征经常被用于语音情感识别?
- 研究问题6:常用的语音数据库使用深度学习方法有怎样的准确度?
- 研究问题7:用于语音情感识别的深度学习的方法又怎样的动机和局限性?



## 文献搜索思想

本阶段将根据搜索字符串和资源来解释文献综述中使用的搜索思想。搜索字符串的目标是捕获所有语音情感识别领域相关的研究论文。使用人群、干预、比较和基于结果的标准确定搜索字符串。被选中的搜索字符串如下:

- 情感语音数据库或情感语音语料库
- 语音情感识别或从语音中识别情绪
- 从语音中识别情感的语音特征
- 使用深度学习方法进行语音情感识别

研究论文是从不同的库中选出,例如,Science direct，施普林格，Ieee，谷歌学者等。表1中给出根据资源选中的研究论文的分布。在总量为160篇的论文中,这份研究中包含了其中的139篇。本文献综述受到Kitchenham和Charters提出的SLR的启发[7]。其余的138篇论文是关于语音情感识别系统的。为了纳入研究，使用纳入、排除和质量评估中规定的标准检查了所有文章。



### 纳入标准

创建纳入标准是为了系统的检查选中的论文,只有满足下列标准的论文才被选中:

1. 文章的研究做的很好
2. 文章在科学合理的
3. 文章专注于语音情感识别和语音情感数据库

### 排除标准

我们定义了一些排除标准来排除列表中不相关的文章。如果文章至少满足以下标准之一时判定为不合格。

1. 文章不是用英语写的
2. 文章评估了语音处理但是不包含情感识别
3. 文章已经被列入其他数据库

### 质量评估

所有被选中的文章的指令都被评估了。文章的评估使用设计如下的清单来评估研究的可靠性和合理性:

1. 文章的研究目标是否很好地被明确了?
2. 这个研究是否被其他作者引用了?
3. 这个研究地结论是否有证据支撑?



# 相关的文献综述

## 情感语音数据库

本节介绍了有关语音情感识别的系统文献综述的详细分析。文献被分为三个部分,也即是语音情感数据库,语音特征和分类器,并分析和评述了不同类型的情感语音数据库,如基于演员的、诱导/半自然的和自然的情感数据库,对现有的语音特征如局部特征和全局特征进行了简要回顾。最后,主要评述了语音情感分类器,例如传统的机器学习方法和深度学习方法。详细回顾了2000年至2021年用于语音情感识别的深度学习方法。一个好的情感数据库是SER的先决条件[ 8 ]。为了评估情感数据库的正确性，在设计情感语音数据库时需要考虑很多因素，如数据库的范围、情感的标注、数据库的大小、说话人的年龄和性别类型等。情感语音数据库可以分为三类：基于演员的数据库、诱导或诱发数据库和自然情感语音数据库。



### 基于演员型

基于演员的情感语音数据库也称为模拟情感语音数据库。这些类型的数据库是由训练有素的专业演员创建的，如广播艺术家、戏剧艺术家，或者来自一个可以用不同情感说话的人。录音是由说话人在不同的情绪下讲同一文本所做的。记录可能在早上、下午、晚上和晚上等不同的时段进行，以考虑人类的物理言语和表现力的变化。这是完整情感范围内记录情感语音数据库的可靠方式之一。超过60%的情感语音数据库是模拟数据库。一般来说，模拟的情感数据库比真实的情感数据库更具表现力[ 9 ]。



### 诱导型

由于诱导情感语音数据库更接近自然数据库，因此也被称为半自然情感数据库。这些类型的数据库是在行为人不知情的情况下，在人工情感情境下录制的。在人工情感情境创设之后，演员与说话人一起参与情感转换。这种类型的数据库比模拟数据库更加自然。但如果说话人知情，录音可能不具有表现力，那么这就是一种人为的情感情境。有时，这些类型的数据库可能被记录在与计算机的口头交互中，而计算机可能是由任何不知情的人控制的[ 10 ]

### 自然型

自然情感数据库是真实的数据，有时很难识别情感。这类数据库可以从客服与客户的谈话、电视广播、医患对话、法庭、非正常情况下的驾驶舱录音等方面进行记录。在这些情况下，很难找到完整的情感范围。也存在一些版权和安全问题[ 5 ]，[ 10 ]。各类情感数据库的详细信息总结在表2中。在文献综述中，基于语言、数据库类型、情感数量、数据类型(视频/音频)、说话人数量、样本数量和话语数量对情感数据库进行了批判性分析，并进行了简要描述。

表3给出了情感语音数据库的文献综述。

在文献中，数据库分为以下三类：

1. i )演员/模拟情感语音数据库，
2. ii )诱发/诱导/半自然情感语音数据库，
3. iii )自然情感语音数据库。表2简要讨论了这些数据库的性质。各数据库在情感数量、语言、方法、数据库的目的等方面存在诸多差异。

在所有数据库中，66%的数据库是基于演员的情感数据库。收集到的情感语音数据库数量最多的是英语语言数据库，其次是汉语和德语语言数据库。以印地语和泰卢固语等印度语言收集的数据库很少。大多数数据库包含喜悦、愤怒、悲伤和中性等情绪。相比之下，大多数数据库很少包含诸如赞同、注意、反感、禁止等不常见的情绪。一些数据库从电视节目、电影中收集情感语音信号，然后由专家对情感进行标注。该数据库一般包含7 - 8种情绪。数据库有足够的变化，如说话人的性别，语音的生成，记录的会话等等。

## 语音特征

 语音情感识别中最重要的部分是语音特征。许多特征已被研究者用于语音情感识别的研究。迄今为止，对于语音特征和特定分类器的提取还没有通用的流程。文献[ 33 ]引入判别信息来保护局部信息以达到更好的效果。为语音情感识别提取的语音特征取决于我们的需求。可以从语音信号中提取局部特征或全局特征，也可以提取两种特征。文献[ 34 ]提出了一种新的特征集HHTC用于视频情感识别。文献[ 35 ]基于fisher和相关性分析提出了一种新的特征选择方法并对结果进行了改进。

局部特征由时间动态表示。它也被称为片段特征的短时特征。另一方面，全局特征由最小和最大值、均值和标准差等穷举统计量表示。它也被称为长时特征或超音段特征。

语音情感特征主要有3类:韵律特征、音质特征和谱特征[17-18].韵律特征包括基音频率[19]、短时能量等,一般通过与韵母、语调相关的韵律来表达;音质特征包括共振峰[20]、谐波噪声比(harmonics-to-noise ratio,HNR)等与发声声道的物理性质相关的声学特征;谱特征包括梅尔频率倒谱系数(Mel frequency cepstral coefficient,MFCC)[21]等以及一些高级谱特征,如类级(class-level)谱特征[22]、语谱图等.其中,共振峰和MFCC是语音情感识别中两种常用的特征,共振峰是音质的决定因素,可以反映声道的物理特征;MFCC可以在很大程度上模拟人的听觉感知系统,从而提高语音情感识别的性能[23].

### 谱特征

当任意一个说话人发出一个语音信号时，它对声道进行过滤和控制。声道特征被用来获取频谱特征，并值得将其表示到频域[ 37 ]。谱特征可以通过傅里叶变换获得。傅里叶变换是将频域变换到时域。最先进的谱特征是梅尔频率倒谱系数( MFCC )。根据式( 1 )将频率转换为梅尔频率。
$$
m=2595\log{\left(\frac{f}{700}+1\right)}
$$

语音信号在转换到频域之前被分成不同的帧。通过傅里叶逆变换从语音信号中提取MFCC特征[ 38 ]。第二个重要的谱特征是线性预测倒谱系数( LPCC )。它包含以声道为代表的重要情感信息[ 39 ]。与MFCC类似,Gammatone频率倒谱系数( GFCC )谱特征[ 40 ]可以被类似地计算。针对普通话的语音情感识别 [ 41 ]，[ 42 ]，提出了一种LPCCs，MFCCs，PLP，LFPCs的组合特征向量。LFPCs性能略优于LPCC常规特征[ 43 ]。

### 韵律特征

音高、时长、能量等韵律特征被认为和情绪具有良好的相关[ 44 ] [ 45 ] [ 46 ]。最大值、最小值、音高相似特征、方差、极差、平均值和标准差等作为良好的韵律信息源，用于识别在片段级别提取的情绪[ 47 ]。Koolagudi和Rao [ 48 ]将韵律特征主要分为三类：i )音高，ii )音强和iii )语调。韵律特征取决于声带的气压。韵律特征的统计值携带了情感特有的信息，对于情感的识别是有用的[ 49 ]。音高的统计值包括意义、最小值、最大值、极差、标准差、偏度、中位数、斜率、峰度等。能量、音高、时长等韵律特征是情绪识别的重要特征[ 50 ]。人类能够识别的语调和节奏等特征被称为韵律特征，这些特征可以在单词、句子、音节和表达中被识别[ 51 ]。从语音中提取的韵律特征是长时特征。基频、时长、能量特征等韵律特征被广泛使用的[ 36 ]。

###  Teager能量算子( TEO )特征

Teager和Kaiser [ 45 ] [ 46 ]引入了TEO特征。TEO在认证中附上了能量检测由听觉过程负责的认证。人们已经区分，在有压力的情况下，由于谐波的分布会产生临界频带和频率的变化。无压力情境下，在言语产生过程中对气流进行改变。TEO由语音信号通过式( 1 )给出的非线性方程组产生。
$$
\varphi[f(n)]=f^2(n)-f(n-1)f(n+1)
$$

### 音质特征

音质特征被定义为个体的语音特征。音质特征是许多语音处理、说话人识别、情感识别等的中心。除谱特征外，声门源的质量由副质量特征定义。格式频率、带宽、声门参数、谐波噪声比、抖动和微光等特征被称为音质特征。音质与情感内容之间存在着截然不同的相互关系[ 52 ]。

## SER分类器

对于SER来说，分类器与语音特征同等重要。可分为两类：( i )传统机器学习分类器；( ii )深度学习分类器。混合方法，即传统分类器和深度学习分类器的结合也被一些研究者使用。大量的分类器已经被用于SER的研究，但是到目前为止，很难确定哪个分类器表现最好。

在本节中，对分类器的文献从两个方面进行了讨论：传统的机器学习方法和深度学习方法。在文献中，基于使用的数据库类型、识别的情感、使用的特征、分类器类型和平均准确率对传统/深度学习分类器进行了批判性分析。

### 传统的机器学习方法

传统的用于SER的ML方法是在从语音信号中提取所需特征后应用的。许多分类器已经被研究人员对SER进行了评估，以达到更好的精度。常用的传统分类器有支持向量机、高斯混合模型、隐马尔可夫模型、人工神经网络、k近邻等[ 5 ]。在文献[ 35 ]中，基于fisher和相关性分析提出了一种新的特征选择方法，使用极限学习机、支持向量机、反向传播神经网络和K近邻分类器，并在CASIA数据集上进行评估。平均准确率分别为89.9%、87.20%、82.30%、80.70%。支持向量机和隐马尔可夫模型已经用于语音情感识别并在SUSAS数据库上进行评估[ 53 ]。作者使用K近邻分类器进行情感识别，4种情感的平均准确率为66.4% [ 54 ]。

LPA和梅尔倒频谱系数已被用于[ 56 ]，[ 57 ]中的特征提取，高斯模糊网络和支持向量机分类器被用于语音情感识别系统，并在EMODB数据库上进行评估，准确率分别为98%和82%。作者使用了一种混合方法，并在三个数据库上进行了评估[ 58 ]。利用SVM分类器对愤怒、中性、悲伤和高兴4种情绪进行识别，平均准确率达到73% [ 59 ]。文献[ 60 ]使用了神经网络和支持向量机，并在eNTERFACE和FAU数据库上进行了评估。作者提出利用傅里叶参数进行语音情感识别，并在3个数据库上进行了评估，得到了71%的最佳准确率[ 61 ]。在文献[ 62 ] [ 63 ]中，梅尔倒频谱系数特征提取技术被用于语音情感识别，并分别使用支持向量机和自适应神经模糊推理系统和多层感知机分类器在EMODB上进行评估。本文在例如使用的数据库，识别的情感数量，使用什么样的特征集，使用哪种类型的分类器，以及达到什么平均精度方面对使用传统方法的文献进行分析。传统的SER方法的文献总结在表4中。

从表4给出的文献总结可以得出，54.45%的论文使用SVM作为分类器，在EMODB数据库上使用梅尔倒频谱系数特征取得了98%的最佳准确率。大多数论文都是采用梅尔倒频谱系数或梅尔倒频谱系数与其他特征的组合作为语音特征进行情感识别。在EMODB和eNTERFACE数据库上评估了大多数语音情感识别模型。

### 深度学习方法

深度学习概念被描述为机器学习的子集，它从多个层面进行学习。深度学习在2015年前后对语音情感识别影响较大。近年来，深度学习方法为语音情感识别提供了令人鼓舞的结果。与传统的机器学习方法相比，深度学习方法具有功能灵活、特征自动学习范围广、可扩展性强、识别率高等优点，被认为是最适合情感识别的分类器。另一方面，传统的ML方法需要较少的数据进行训练。研究者们使用了多种深度学习方法进行情感识别。表5简要介绍了用于语音情感识别的深度学习方法的主要特点和局限性。

目前的研究者正在使用深度学习方法进行情绪识别并提高准确率。使用深度学习方法的语音情感识别模型的主要类别是使用自动学习相关特征的方法、使用手工特征和使用语谱图。作者提出了基于卷积神经网络的新的时空和频繁级联网络用于情感识别，并评估了IEMOCAP，EMODB，eNTERFACE和SAVEE数据库，平均准确率分别为71.98%，82。10，75.60%，54.75% [ 69 ]。对话情感修正网络语音情感识别(DECN SER)模型是为了纠正情感识别方法的错误而提出的，并改进了结果[ 70 ]。

作者提出了一个使用长短时记忆分类器的语音情感识别系统，并在RAVDESS数据库上进行评估，在识别方面得到了改进[ 71 ]，[ 76 ]。一维卷积神经网络被提出来识别情感[ 72 ]，[ 73 ]。在文献[ 74 ]，[ 75 ]，[ 78 ]，[ 79 ]，[ 80 ]，[ 81 ]，[ 86 ]中，语音信号被转换为语谱图，并使用卷积神经网络进行情感识别。提取梅尔倒频谱系数和韵律特征并应用深度神经网络，在多个数据库上对提出的模型进行评估，对SAVEE数据库的识别取得的最佳准确率为81.70% [ 77 ]。卷积神经网络与其他分类器已经在文献[ 84 ]，[ 85 ]，[ 86 ]中使用并在平均准确率方面提高了结果。文献[ 88 ]的作者选择GoogleNet进行情感识别，并在多个数据库上进行评估[ 88 ]。文献[ 89 ]，[ 90 ]，[ 91 ]，[ 92 ]，[ 94 ]，[ 103 ]，[ 106 ]的作者使用卷积神经网络和长短时记忆分类器开发了SER方法，并在不同的数据库上进行了评估。

文献[ 119 ]中使用openSMILE提取的特征和使用LSTM分类器的RNN来提高识别率。自动特征已经被CNN层学习来识别情感[ 121 ]。文献[ 122 ]提取MFCC特征并选择RNN分类器进行情感识别，提出的模型在EMODB上进行了评估[ 122 ]。文献[ 123 ]，[ 125 ]的作者提出了使用DBN分类器的SER模型，并在EMODB和IEMOCAP数据库上进行了评估。RNN模型已经被作者使用并提高了识别率[ 127 ]。在文献[ 128 ]中，作者提出了使用DNN分类器和从语谱图中提取特征的SER模型来提高准确率。CNN分类器已经在[ 129 ]，[ 130 ]中用于情感识别，并在IEMOCAP和CAM3D数据库上进行了评估。将语音信号转换为语谱图，然后应用CNN模型进行情感识别[ 132 ]、[ 133 ]。作者在[ 131 ]，[ 134 ]中提出了使用DNN分类器的SER模型。在文献[ 135 ] [ 137 ]中，DBN分类器被用于手工特征的情感识别。在[ 136 ]，[ 138 ]中提取的MFCC特征用于SER和LSTM和DNN分类器以达到更好的精度。ANN分类器已在文献[ 139 ]中用于情感识别，并在EMODB和中文数据库上进行了评估。本文对深度学习方法的详细文献进行了分析，如使用的数据库、识别的情感数量、使用的特征集种类、使用的深度学习分类器类型和达到的平均准确率。对情感识别深度学习方法的文献综述的批判性分析在表6中讨论。

从表6中可以看出，到2013年为止，很少有研究人员使用深度学习方法进行SER，大多数使用DBN分类器[ 135 ]，[ 137 ]。2014年，大多数研究人员已经使用CNN和语谱图[ 132 ]，[ 133 ]。在2015年RECOLA数据库[ 127 ]上使用RNN分类器取得了81%的最佳识别准确率。2016年RNN、DBN、CNN、DNN分类器被研究者使用。2017年，在CASEC数据库上评估的DBN分类器取得了94.60%的最佳准确率[ 113 ]。2018年,深度卷积神经网络(DCNN)被运用在EMOBD数据集上[ 100 ]，取得了92.71%的较好准确率。2019年，在所有2d CNN + LSTM方法中，使用非常多样化和混合的方法取得了最好的准确率，在EMODB数据集上为95.89%，在IEMOCAP数据集上为89.16% [ 92 ]。在2020年，CNN在EMODB数据集上取得的最佳准确率为95% [ 86 ]。

在2021年，研究人员正在进行研究，其中大部分研究是使用CNN和混合方法。从表5中还可以发现，大多数研究者在IEMOCAP ( 48% )上评估了他们提出的SER模型，其次是EMODB ( 38% )、RAVDESS ( 17% )和SAVEE ( 10% )数据库。同样明显的是，大多数论文使用了CNN，其次是LSTM和RNN 深度学习方法。研究人员通过三种方式使用深度学习方法进行情感识别：i )第一种方式，研究人员提取语音特征然后应用深度学习方法；ii )第二种方式，研究人员首先将语音信号转换为语谱图然后应用深度学习方法；iii )第三种方式，研究人员用深度学习方法自动学习的相关的语音特征来识别情感。

文献[ 92 ]中作者使用从语谱图中提取特征的CNN + LSTM方法，在IEMOCAP和EMODB数据库取得了最好的准确率89.16%和95.89%。对于RAVDESS数据库，使用自动学习语音特征的LSTM方法取得了84.30%的最佳准确率[ 76 ]。对于SAVEE数据库，使用从语谱图中提取特征的CNN方法报告了81.05%的最佳准确率[ 95 ]。很少有研究者使用自编码器、DBN和深度玻尔兹曼机(DBM) 深度学习方法。所有入选文献在年代和文献来源方面的分布情况如图3所示。

图3的结果表明，在2013年之后，使用深度学方法进行情绪识别的研究逐渐增多。目前，研究者们提出的SER模型大多采用深度学习方法，并在平均精度和计算成本方面取得了较好的结果。

# 调查结果

本部分的目的是讨论SER的具体研究问题和近期研究结果。这些都是在第二节提到的研究问题中讨论的。本文根据表1给出的详细信息，从不同的资源中共选取了139篇论文。在所有论文中，与语音情感数据库相关的论文有25篇，与语音特征相关的论文有20篇，与分类器相关的论文有93篇，与本SLR论文背景相关的论文有1篇。这项工作的目标是根据研究问题来确定的，并在第3节中提出。下面讨论定义的所有研究问题和调查结果。



RQ1：用于检索本文献综述所包含的研究论文的各种来源。

本研究共纳入139篇研究论文，其中超过65%的论文与SER分类器相关，18%的论文针对情感语音数据库，超过14%的论文针对语音特征，其余的论文与SER系统的背景相关。论文分别从爱思维尔、施普林格、IEEE、Research Gate和其他资源(见表1)收集。论文数量及所占百分比按资源分布见图4。

从图4可以看出，大部分论文都是从其他资源中收集的，其次是IEEE、施普林格、爱思维尔和Google Scholar。

 RQ2：什么类型的语音数据库用于SER。

从语音数据库的文献来看，该数据库分为三类：基于演员、基于半自然、基于自然情感。在所有数据库中，超过66%的数据库为基于行为体的情感数据库，19.05%为半自然情感数据库，14.29%为自然数据库。表7给出了3类数据库的论文分布及所占比例。

RQ3：情感语音数据库可用的语言。

本研究问题的目的是分析不同语言的数据库。表2中收集的情感语音数据库，是英语语言数据库，其次是汉语和德语语言数据库。日语、韩语、印度语和多语种的数据库很少。来自印度的语言数据库只有印地语和泰卢固语。各数据库的语种分布见表8。

RQ 4：研究者常用哪些语音数据库进行SER。

已经被研究者使用的数据库有很多。在本研究中，我们考虑了93篇文献，其中12篇文献使用传统的机器学习方法，69篇文献使用深度学习方法。在IEMOCAP数据库、EMODB数据库和RAVDESS (表4和表6中的SER模型超过15%)数据库上评估了大部分语音情感识别模型。表9给出了常用数据库的详细信息。

RQ 5：SER中常用的语音特征有哪些。

从文献中发现，有很多特征被研究者利用和检验。从用于SER的语音中提取的语音特征分为局部特征或全局特征或两者都有的特征。分别从频谱特征、韵律特征、Teager能量算子和副质量特征四个方面进行研究。语音特征、目的和方法在表10中给出。

RQ 6：使用DL方法的常用语音数据库的准确率。

在这项研究中，我们考虑了68篇使用DL方法的SER论文。从表6可以看出，使用较多的数据库是IEMOCAP，其次是EMODB和RAVDESS。作者用于SER的DL方法有CNN、RNN、LSTM、Auto -encoder、RBN、RMB以及这些方法的组合。以谱图为特征的CNN + LSTM模型在IEMOCAP数据库上取得的最佳准确率为89.16%，在EMODB数据库上取得的最佳准确率为95.89% [ 92 ]。对于RAVDESS数据库，使用自动学习特征的LSTM模型取得了89.16%的最高准确率[ 76 ]。表11总结了不同DL方法和根据用户特征在这些常用数据库上取得的最佳准确率的分析。

RQ 7：深度学习方法用于语音情感识别的动机和限制是什么。

 DL方法在从语音中识别情感的时间和成本方面更有效。尽管如此，深度学习方法仍有许多挑战需要克服。表12列出了动机和限制。

